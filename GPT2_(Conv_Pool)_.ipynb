{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdHVQrqyDB50"
   },
   "source": [
    "# Memory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "E58HaeA6CsM9",
    "outputId": "a7fc34a6-ebc7-4c11-b410-2a6eef4d09c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Memory Information ========================================\n",
      "Total: 25.51GB\n",
      "Available: 24.60GB\n",
      "Used: 590.07MB\n",
      "Percentage: 3.6%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def get_size(bytes, suffix=\"B\"):\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
    "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgVfBlvZDEja"
   },
   "source": [
    "# GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "rxlkxvkrCyin",
    "outputId": "c1e251cf-50ef-45e9-df1e-d259f28fbd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  1 16:48:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "colab_type": "code",
    "id": "v6WR5Uaa6RQJ",
    "outputId": "0bed21a3-1951-4ad9-b56a-6e0cfc5c6aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytreebank\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
      "Collecting loguru\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/4f/baee593c195cd4b56cf008c9473347f3b0795b47d3b946e03706a8b43fca/loguru-0.5.1-py3-none-any.whl (56kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 16.2MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 29.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 47.4MB/s \n",
      "\u001b[?25hCollecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
      "Collecting contextvars==2.4; python_version < \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
      "Collecting immutables>=0.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pytreebank, sacremoses, contextvars\n",
      "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp36-none-any.whl size=37070 sha256=4de217610b0eed6e15169fe03e397645ff1a1ebc7f6592cd145a91c4a0d6d188\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2642101c0bea4432bcd922698afbd89870b8e595a1a02f91e2ede287d45204f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=14a1a01ee0594d87bb678c73b6dbe40d297d4b52e019b9f55d3f4d335faaf474\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
      "Successfully built pytreebank sacremoses contextvars\n",
      "Installing collected packages: pytreebank, sentencepiece, tokenizers, sacremoses, transformers, immutables, contextvars, aiocontextvars, loguru\n",
      "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 immutables-0.14 loguru-0.5.1 pytreebank-0.2.7 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyDODoaWC6KI"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "import torch\n",
    "from dataset import SSTDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import transformer_params\n",
    "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
    "from math import ceil\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZ5IZjSzQNpP"
   },
   "outputs": [],
   "source": [
    "class GPT2ForSequenceClassification(torch.nn.Module):\n",
    "  def __init__(self, num_labels):\n",
    "    super(GPT2ForSequenceClassification, self).__init__()\n",
    "    self.model = GPT2Model.from_pretrained('gpt2',\n",
    "                                       config=GPT2Config.from_pretrained('gpt2'))\n",
    "    self.max_pool = torch.nn.MaxPool1d(3, 2)\n",
    "    self.dropout = torch.nn.Dropout(p=0.1)\n",
    "    self.layer_norm = torch.nn.LayerNorm(768)\n",
    "    self.conv1d_1 = torch.nn.Conv1d(in_channels=768, out_channels=768, kernel_size=1, stride=1)\n",
    "    self.fc_layer = torch.nn.Linear(in_features=768, out_features=768)\n",
    "    self.tanh = torch.nn.Tanh()\n",
    "    self.out_layer = torch.nn.Linear(in_features=768, out_features=num_labels)\n",
    "    self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels):\n",
    "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
    "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
    "\n",
    "    gpt_last_layer = gpt_last_layer.permute(0, 2, 1)\n",
    "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "\n",
    "    max_pool_out = self.max_pool(gpt_last_layer)\n",
    "    #batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "\n",
    "    max_pool_out = self.dropout(max_pool_out)\n",
    "    max_pool_out = max_pool_out.permute(0, 2, 1)\n",
    "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
    "\n",
    "    layer_norm_out = self.layer_norm(max_pool_out)\n",
    "    layer_norm_out = layer_norm_out.permute(0, 2, 1)\n",
    "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "\n",
    "    conv1d_1_out = self.conv1d_1(layer_norm_out)\n",
    "    conv1d_1_out = self.tanh(conv1d_1_out)\n",
    "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "\n",
    "    global_max_pooling_out, _ = torch.max(conv1d_1_out, axis=2)\n",
    "    global_max_pooling_out = self.dropout(global_max_pooling_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "\n",
    "    fc_layer_out = self.fc_layer(global_max_pooling_out)\n",
    "    fc_layer_out = self.tanh(fc_layer_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "\n",
    "    fc_layer_out = self.dropout(fc_layer_out)\n",
    "    logits = self.out_layer(fc_layer_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
    "    \n",
    "    loss = self.criterion(logits, labels)\n",
    "                                   \n",
    "    return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "1b776aff44614d6fb66c8d21ff444811",
      "23ff162607674d638c57e9d23d25c62a",
      "d22f7ca375c94bc3a29d54b1d0744159",
      "d0f28862d5dd488cab8fa39c1629b646",
      "77c516b35e7a480d9702648919f18a16",
      "9c182253fe054c34b562cad54d9fde86",
      "fd0b6807457a419f805cb673a0611075",
      "bb7d3b3fb8984827b290425805179b11",
      "c00da0f8e1914aa5b95c92a92d34e868",
      "4de995f4a7e943609b347ec434906a2d",
      "7d513c8ba9a4460c86c4d2a451ca0712",
      "abed0b01825b482f83fbc0e3297af3f8",
      "4f7ef52f5c3443a488230a5e787fe94f",
      "2b3230592c5d41549ff2958be1c1c54f",
      "3736daa31ca8425a8d76771dea34727b",
      "5197ca12a309439baefa79e1d7c79484"
     ]
    },
    "colab_type": "code",
    "id": "AlMNcjYekVMd",
    "outputId": "5388d0b5-da18-4bfe-c997-5cc8be7b1dcc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b776aff44614d6fb66c8d21ff444811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00da0f8e1914aa5b95c92a92d34e868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_tokenizer.add_special_tokens({'pad_token': '.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4_cQpe_c4BN"
   },
   "outputs": [],
   "source": [
    "def load_transformer(name, binary):\n",
    "  num_classes = 5\n",
    "  if binary:\n",
    "    num_classes = 2\n",
    "  model = GPT2ForSequenceClassification(num_classes)\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "  tokenizer.add_special_tokens({'pad_token': '.'})\n",
    "\n",
    "  return {'model': model,\n",
    "          'tokenizer': tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQFaW79Rdi0R"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcSgyPvydj0s"
   },
   "outputs": [],
   "source": [
    "def train_step(model, inputs, labels, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7984ypaMdixv"
   },
   "outputs": [],
   "source": [
    "def eval_step(model, inputs, labels):\n",
    "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbHHlscCdivT"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, tokenizer, train_dataset, optimizer, batch_size):\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
    "        for text, sentiment in train_loader:\n",
    "            text = tokenizer(text, padding=True, return_tensors='pt').to(device)\n",
    "            sentiment = sentiment.to(device)\n",
    "\n",
    "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
    "\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            correct_count += (preds == sentiment).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPxnxXajditk"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, tokenizer, eval_dataset, batch_size, split):\n",
    "    eval_loader = DataLoader(dataset=eval_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
    "            for text, sentiment in eval_loader:\n",
    "                text = tokenizer(text, padding=True, return_tensors='pt').to(device)\n",
    "                sentiment = sentiment.to(device)\n",
    "\n",
    "                logits, loss = eval_step(model, text, sentiment)\n",
    "\n",
    "                preds = torch.argmax(logits, axis=1)\n",
    "                y_pred += preds.cpu().numpy().tolist()\n",
    "                y_true += sentiment.cpu().numpy().tolist()\n",
    "\n",
    "                correct_count += (preds == sentiment).sum().item()\n",
    "                total_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
    "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JQeDe5FdirO"
   },
   "outputs": [],
   "source": [
    "def train(name, root, binary, epochs=25, patience=3, save=False):\n",
    "\n",
    "    #load model and tokenizer..\n",
    "    try:\n",
    "        transformer_container = load_transformer(name, binary)\n",
    "    except ValueError:\n",
    "        logger.error(\"Invalid transformer name!\")\n",
    "        os._exit(0)\n",
    "    model = transformer_container['model']\n",
    "    model = model.to(device)\n",
    "    tokenizer = transformer_container['tokenizer']\n",
    "\n",
    "    #load batch_size and learning rate..\n",
    "    params_container = transformer_params(name)\n",
    "    batch_size = params_container['batch_size']\n",
    "    learning_rate = params_container['learning_rate']\n",
    "\n",
    "    #load train, dev and test datasets..\n",
    "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
    "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
    "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
    "\n",
    "    #Intialize optimizer..\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Initialize training variables..\n",
    "    best_acc = 0.0\n",
    "    best_loss = np.inf\n",
    "    stopping_step = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    total_train_seconds = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        train_acc, train_loss = train_epoch(model, tokenizer, train_dataset, optimizer, batch_size)\n",
    "        end = time.time()\n",
    "        total_train_seconds += (end - start)\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
    "\n",
    "        dev_acc, dev_loss, _ = eval_epoch(model, tokenizer, dev_dataset, batch_size, 'dev')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
    "\n",
    "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, tokenizer, test_dataset,\n",
    "                                                                  batch_size, 'test')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
    "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
    "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
    "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
    "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
    "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
    "\n",
    "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
    "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
    "\n",
    "        #save best model and delete previous ones...\n",
    "        if save:\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                phrase_type, label = root_and_binary_title(root, binary)\n",
    "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
    "                save_model(model, model_name, best_model_name)\n",
    "\n",
    "\n",
    "        # Implement early stopping here\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step += 1\n",
    "\n",
    "        if stopping_step >= patience:\n",
    "            logger.info(\"EarlyStopping!\")\n",
    "            os._exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "31d6bd019db64faeb651fc489f9902a6",
      "c5fe55158c3246b4b4d8ff828078e34c",
      "26af63eb429f4c209141eae07249063c",
      "b1d81713fc0d469581f8cd07cada33a3",
      "005643cd441e414db4cd301ec1c0fa17",
      "b230b859d20b4cb7840df72ba1298fe2",
      "f64d719b645447d4a876fd33a3235b7e",
      "11143c2b9d5545b09a90d20c957026aa",
      "b33706f3d2af4c78be8879669a6c874f",
      "1073960252484622a6b8a92168ab8ebd",
      "d2a2bd71e318445b9f9242768de1d97e",
      "58e695834983496da2f7518e16667112",
      "aa9aa206d09048689810d38e04982955",
      "1a83b9cf711b44cc9c87e1c24503925f",
      "732f9d3dd6be4739b800cdc1e3f6b9c5",
      "62a8322365724292ae543d0be92d1489"
     ]
    },
    "colab_type": "code",
    "id": "axYwav8wdiou",
    "outputId": "8403b799-1993-43fe-888e-c2841afbfea9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d6bd019db64faeb651fc489f9902a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33706f3d2af4c78be8879669a6c874f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-09-01 16:49:12.310 | INFO     | dataset:__init__:17 - Preparing dataset config root: False, binary: False, split: train!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 16:49:56.800 | INFO     | dataset:__init__:17 - Preparing dataset config root: False, binary: False, split: dev!\n",
      "2020-09-01 16:50:07.127 | INFO     | dataset:__init__:17 - Preparing dataset config root: False, binary: False, split: test!\n",
      "train: 100%|██████████| 9956/9956 [22:15<00:00,  7.45batch/s]\n",
      "2020-09-01 17:12:32.411 | INFO     | __main__:train:39 - epoch: 1, transformer: gpt2, train_loss: 0.0183, train_acc: 77.04\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.36batch/s]\n",
      "2020-09-01 17:13:25.834 | INFO     | __main__:train:42 - epoch: 1, transformer: gpt2, dev_loss: 0.0156, dev_acc: 79.82\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.17batch/s]\n",
      "2020-09-01 17:15:13.087 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_loss: 0.0157, test_acc: 79.67\n",
      "2020-09-01 17:15:13.088 | INFO     | __main__:train:47 - epoch: 1, transformer: gpt2, test_precision: 64.21, test_recall: 58.57, test_f1_score: 60.39, test_accuracy_score: 79.67\n",
      "2020-09-01 17:15:13.090 | INFO     | __main__:train:52 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
      "[[  904   906   158    40     0]\n",
      " [  984  5674  2343   242    12]\n",
      " [  177  2927 51703  1710    31]\n",
      " [   45   466  3978  5989   520]\n",
      " [   23    57   234  1937  1540]]\n",
      "2020-09-01 17:15:13.091 | INFO     | __main__:train:55 - Total training time elapsed: 0:22:15.940522\n",
      "2020-09-01 17:15:13.092 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:15.940522\n",
      "train: 100%|██████████| 9956/9956 [22:23<00:00,  7.41batch/s]\n",
      "2020-09-01 17:37:36.476 | INFO     | __main__:train:39 - epoch: 2, transformer: gpt2, train_loss: 0.0142, train_acc: 81.70\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.39batch/s]\n",
      "2020-09-01 17:38:29.821 | INFO     | __main__:train:42 - epoch: 2, transformer: gpt2, dev_loss: 0.0150, dev_acc: 80.43\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.26batch/s]\n",
      "2020-09-01 17:40:16.666 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_loss: 0.0150, test_acc: 80.67\n",
      "2020-09-01 17:40:16.667 | INFO     | __main__:train:47 - epoch: 2, transformer: gpt2, test_precision: 63.31, test_recall: 65.27, test_f1_score: 64.09, test_accuracy_score: 80.67\n",
      "2020-09-01 17:40:16.668 | INFO     | __main__:train:52 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 1093   697   154    59     5]\n",
      " [ 1264  5259  2277   427    28]\n",
      " [  229  2328 50895  2974   122]\n",
      " [   27   280  2407  7081  1203]\n",
      " [    3    40   114  1332  2302]]\n",
      "2020-09-01 17:40:16.669 | INFO     | __main__:train:55 - Total training time elapsed: 0:44:39.323050\n",
      "2020-09-01 17:40:16.670 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:19.661525\n",
      "train: 100%|██████████| 9956/9956 [22:23<00:00,  7.41batch/s]\n",
      "2020-09-01 18:02:40.592 | INFO     | __main__:train:39 - epoch: 3, transformer: gpt2, train_loss: 0.0127, train_acc: 83.54\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.39batch/s]\n",
      "2020-09-01 18:03:33.942 | INFO     | __main__:train:42 - epoch: 3, transformer: gpt2, dev_loss: 0.0141, dev_acc: 82.03\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.34batch/s]\n",
      "2020-09-01 18:05:20.432 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_loss: 0.0141, test_acc: 82.03\n",
      "2020-09-01 18:05:20.434 | INFO     | __main__:train:47 - epoch: 3, transformer: gpt2, test_precision: 67.95, test_recall: 64.44, test_f1_score: 65.71, test_accuracy_score: 82.03\n",
      "2020-09-01 18:05:20.435 | INFO     | __main__:train:52 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
      "[[  979   837   143    47     2]\n",
      " [  805  5764  2332   343    11]\n",
      " [  152  2237 51447  2671    41]\n",
      " [   22   254  2454  7650   618]\n",
      " [    3    42   118  1708  1920]]\n",
      "2020-09-01 18:05:20.436 | INFO     | __main__:train:55 - Total training time elapsed: 1:07:03.242873\n",
      "2020-09-01 18:05:20.437 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:21.080958\n",
      "train: 100%|██████████| 9956/9956 [22:24<00:00,  7.40batch/s]\n",
      "2020-09-01 18:27:45.249 | INFO     | __main__:train:39 - epoch: 4, transformer: gpt2, train_loss: 0.0117, train_acc: 84.78\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.33batch/s]\n",
      "2020-09-01 18:28:38.727 | INFO     | __main__:train:42 - epoch: 4, transformer: gpt2, dev_loss: 0.0141, dev_acc: 81.81\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.13batch/s]\n",
      "2020-09-01 18:30:26.128 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_loss: 0.0139, test_acc: 82.24\n",
      "2020-09-01 18:30:26.129 | INFO     | __main__:train:47 - epoch: 4, transformer: gpt2, test_precision: 67.77, test_recall: 65.42, test_f1_score: 66.25, test_accuracy_score: 82.24\n",
      "2020-09-01 18:30:26.130 | INFO     | __main__:train:52 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
      "[[  798  1008   148    52     2]\n",
      " [  495  6095  2249   396    20]\n",
      " [   80  2296 51446  2626   100]\n",
      " [    8   256  2369  7084  1281]\n",
      " [    1    32   120  1131  2507]]\n",
      "2020-09-01 18:30:26.131 | INFO     | __main__:train:55 - Total training time elapsed: 1:29:28.054302\n",
      "2020-09-01 18:30:26.133 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:22.013575\n",
      "train: 100%|██████████| 9956/9956 [22:31<00:00,  7.37batch/s]\n",
      "2020-09-01 18:52:57.252 | INFO     | __main__:train:39 - epoch: 5, transformer: gpt2, train_loss: 0.0109, train_acc: 85.84\n",
      "dev: 100%|██████████| 1296/1296 [00:52<00:00, 24.54batch/s]\n",
      "2020-09-01 18:53:50.276 | INFO     | __main__:train:42 - epoch: 5, transformer: gpt2, dev_loss: 0.0137, dev_acc: 82.64\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.21batch/s]\n",
      "2020-09-01 18:55:37.345 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_loss: 0.0137, test_acc: 82.69\n",
      "2020-09-01 18:55:37.346 | INFO     | __main__:train:47 - epoch: 5, transformer: gpt2, test_precision: 70.76, test_recall: 63.71, test_f1_score: 66.40, test_accuracy_score: 82.69\n",
      "2020-09-01 18:55:37.347 | INFO     | __main__:train:52 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
      "[[  877   930   170    31     0]\n",
      " [  534  6092  2376   246     7]\n",
      " [   98  2234 52026  2164    26]\n",
      " [   10   279  2773  7436   500]\n",
      " [    2    48   171  1695  1875]]\n",
      "2020-09-01 18:55:37.348 | INFO     | __main__:train:55 - Total training time elapsed: 1:51:59.172676\n",
      "2020-09-01 18:55:37.350 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:23.834535\n",
      "train: 100%|██████████| 9956/9956 [22:31<00:00,  7.37batch/s]\n",
      "2020-09-01 19:18:08.498 | INFO     | __main__:train:39 - epoch: 6, transformer: gpt2, train_loss: 0.0103, train_acc: 86.57\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.18batch/s]\n",
      "2020-09-01 19:19:02.316 | INFO     | __main__:train:42 - epoch: 6, transformer: gpt2, dev_loss: 0.0144, dev_acc: 82.13\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.28batch/s]\n",
      "2020-09-01 19:20:49.051 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_loss: 0.0142, test_acc: 82.49\n",
      "2020-09-01 19:20:49.052 | INFO     | __main__:train:47 - epoch: 6, transformer: gpt2, test_precision: 68.75, test_recall: 66.34, test_f1_score: 67.30, test_accuracy_score: 82.49\n",
      "2020-09-01 19:20:49.053 | INFO     | __main__:train:52 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
      "[[  882   875   206    41     4]\n",
      " [  498  5944  2497   291    25]\n",
      " [   84  2078 51621  2645   120]\n",
      " [   10   204  2374  7136  1274]\n",
      " [    2    26   140  1068  2555]]\n",
      "2020-09-01 19:20:49.054 | INFO     | __main__:train:55 - Total training time elapsed: 2:14:30.320195\n",
      "2020-09-01 19:20:49.057 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:25.053366\n",
      "train: 100%|██████████| 9956/9956 [22:26<00:00,  7.39batch/s]\n",
      "2020-09-01 19:43:15.798 | INFO     | __main__:train:39 - epoch: 7, transformer: gpt2, train_loss: 0.0096, train_acc: 87.41\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.42batch/s]\n",
      "2020-09-01 19:44:09.071 | INFO     | __main__:train:42 - epoch: 7, transformer: gpt2, dev_loss: 0.0146, dev_acc: 82.03\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.20batch/s]\n",
      "2020-09-01 19:45:56.170 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_loss: 0.0145, test_acc: 82.37\n",
      "2020-09-01 19:45:56.172 | INFO     | __main__:train:47 - epoch: 7, transformer: gpt2, test_precision: 68.39, test_recall: 66.38, test_f1_score: 67.24, test_accuracy_score: 82.37\n",
      "2020-09-01 19:45:56.173 | INFO     | __main__:train:52 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
      "[[  961   812   194    38     3]\n",
      " [  666  5939  2316   319    15]\n",
      " [  123  2221 51241  2892    71]\n",
      " [   12   207  2236  7628   915]\n",
      " [    3    31   132  1354  2271]]\n",
      "2020-09-01 19:45:56.174 | INFO     | __main__:train:55 - Total training time elapsed: 2:36:57.060662\n",
      "2020-09-01 19:45:56.175 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:25.294380\n",
      "train: 100%|██████████| 9956/9956 [22:26<00:00,  7.40batch/s]\n",
      "2020-09-01 20:08:22.401 | INFO     | __main__:train:39 - epoch: 8, transformer: gpt2, train_loss: 0.0091, train_acc: 88.11\n",
      "dev: 100%|██████████| 1296/1296 [00:53<00:00, 24.32batch/s]\n",
      "2020-09-01 20:09:15.903 | INFO     | __main__:train:42 - epoch: 8, transformer: gpt2, dev_loss: 0.0148, dev_acc: 82.19\n",
      "test: 100%|██████████| 2582/2582 [01:46<00:00, 24.15batch/s]\n",
      "2020-09-01 20:11:03.235 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_loss: 0.0148, test_acc: 82.27\n",
      "2020-09-01 20:11:03.236 | INFO     | __main__:train:47 - epoch: 8, transformer: gpt2, test_precision: 68.03, test_recall: 65.55, test_f1_score: 66.63, test_accuracy_score: 82.27\n",
      "2020-09-01 20:11:03.237 | INFO     | __main__:train:52 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
      "[[  997   762   212    37     0]\n",
      " [  761  5759  2430   294    11]\n",
      " [  143  2163 51582  2597    63]\n",
      " [   14   213  2454  7459   858]\n",
      " [    2    22   167  1445  2155]]\n",
      "2020-09-01 20:11:03.238 | INFO     | __main__:train:55 - Total training time elapsed: 2:59:23.285027\n",
      "2020-09-01 20:11:03.239 | INFO     | __main__:train:56 - Mean time per train epoch: 0:22:25.410628\n",
      "train:  78%|███████▊  | 7754/9956 [17:32<04:59,  7.36batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ed5fa0a10f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-6b9a2854405b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(name, root, binary, epochs, patience, save)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtotal_train_seconds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ab0b428daf8b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, tokenizer, train_dataset, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c54f6e7dca1d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, inputs, labels, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train('gpt2', False, False, 100, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJ12BnAei0FS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRZpL_cidimc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iz3muFrUdikk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjd7B--JdiiN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXqhawGkdigP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GPT2 (Conv Pool) .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005643cd441e414db4cd301ec1c0fa17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1073960252484622a6b8a92168ab8ebd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11143c2b9d5545b09a90d20c957026aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a83b9cf711b44cc9c87e1c24503925f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b776aff44614d6fb66c8d21ff444811": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d22f7ca375c94bc3a29d54b1d0744159",
       "IPY_MODEL_d0f28862d5dd488cab8fa39c1629b646"
      ],
      "layout": "IPY_MODEL_23ff162607674d638c57e9d23d25c62a"
     }
    },
    "23ff162607674d638c57e9d23d25c62a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26af63eb429f4c209141eae07249063c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b230b859d20b4cb7840df72ba1298fe2",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_005643cd441e414db4cd301ec1c0fa17",
      "value": 665
     }
    },
    "2b3230592c5d41549ff2958be1c1c54f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d6bd019db64faeb651fc489f9902a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26af63eb429f4c209141eae07249063c",
       "IPY_MODEL_b1d81713fc0d469581f8cd07cada33a3"
      ],
      "layout": "IPY_MODEL_c5fe55158c3246b4b4d8ff828078e34c"
     }
    },
    "3736daa31ca8425a8d76771dea34727b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4de995f4a7e943609b347ec434906a2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f7ef52f5c3443a488230a5e787fe94f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5197ca12a309439baefa79e1d7c79484": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58e695834983496da2f7518e16667112": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62a8322365724292ae543d0be92d1489",
      "placeholder": "​",
      "style": "IPY_MODEL_732f9d3dd6be4739b800cdc1e3f6b9c5",
      "value": " 548M/548M [00:10&lt;00:00, 50.0MB/s]"
     }
    },
    "62a8322365724292ae543d0be92d1489": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "732f9d3dd6be4739b800cdc1e3f6b9c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77c516b35e7a480d9702648919f18a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7d513c8ba9a4460c86c4d2a451ca0712": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b3230592c5d41549ff2958be1c1c54f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f7ef52f5c3443a488230a5e787fe94f",
      "value": 456318
     }
    },
    "9c182253fe054c34b562cad54d9fde86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa9aa206d09048689810d38e04982955": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "abed0b01825b482f83fbc0e3297af3f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5197ca12a309439baefa79e1d7c79484",
      "placeholder": "​",
      "style": "IPY_MODEL_3736daa31ca8425a8d76771dea34727b",
      "value": " 456k/456k [00:00&lt;00:00, 3.70MB/s]"
     }
    },
    "b1d81713fc0d469581f8cd07cada33a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11143c2b9d5545b09a90d20c957026aa",
      "placeholder": "​",
      "style": "IPY_MODEL_f64d719b645447d4a876fd33a3235b7e",
      "value": " 665/665 [00:11&lt;00:00, 59.5B/s]"
     }
    },
    "b230b859d20b4cb7840df72ba1298fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b33706f3d2af4c78be8879669a6c874f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2a2bd71e318445b9f9242768de1d97e",
       "IPY_MODEL_58e695834983496da2f7518e16667112"
      ],
      "layout": "IPY_MODEL_1073960252484622a6b8a92168ab8ebd"
     }
    },
    "bb7d3b3fb8984827b290425805179b11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c00da0f8e1914aa5b95c92a92d34e868": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d513c8ba9a4460c86c4d2a451ca0712",
       "IPY_MODEL_abed0b01825b482f83fbc0e3297af3f8"
      ],
      "layout": "IPY_MODEL_4de995f4a7e943609b347ec434906a2d"
     }
    },
    "c5fe55158c3246b4b4d8ff828078e34c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0f28862d5dd488cab8fa39c1629b646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb7d3b3fb8984827b290425805179b11",
      "placeholder": "​",
      "style": "IPY_MODEL_fd0b6807457a419f805cb673a0611075",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 2.40MB/s]"
     }
    },
    "d22f7ca375c94bc3a29d54b1d0744159": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c182253fe054c34b562cad54d9fde86",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77c516b35e7a480d9702648919f18a16",
      "value": 1042301
     }
    },
    "d2a2bd71e318445b9f9242768de1d97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a83b9cf711b44cc9c87e1c24503925f",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa9aa206d09048689810d38e04982955",
      "value": 548118077
     }
    },
    "f64d719b645447d4a876fd33a3235b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd0b6807457a419f805cb673a0611075": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
