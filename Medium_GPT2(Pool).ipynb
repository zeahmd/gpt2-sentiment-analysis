{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdHVQrqyDB50"
   },
   "source": [
    "# Memory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "E58HaeA6CsM9",
    "outputId": "23c45fb5-8607-4105-b84e-043eb85ee14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Memory Information ========================================\n",
      "Total: 25.51GB\n",
      "Available: 24.55GB\n",
      "Used: 618.59MB\n",
      "Percentage: 3.8%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def get_size(bytes, suffix=\"B\"):\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
    "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgVfBlvZDEja"
   },
   "source": [
    "# GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "rxlkxvkrCyin",
    "outputId": "8911da80-df05-4271-fafe-01e1ea6975b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  1 07:11:27 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "id": "v6WR5Uaa6RQJ",
    "outputId": "609d308c-25b9-4dba-fdc9-c23e9f7d3d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytreebank in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
      "Requirement already satisfied: loguru in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.1.91)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.0.43)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.8.1rc1)\n",
      "Requirement already satisfied: aiocontextvars>=0.2.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from loguru->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: contextvars==2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiocontextvars>=0.2.0; python_version < \"3.7\"->loguru->-r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars==2.4; python_version < \"3.7\"->aiocontextvars>=0.2.0; python_version < \"3.7\"->loguru->-r requirements.txt (line 5)) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyDODoaWC6KI"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "import torch\n",
    "from dataset import SSTDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import transformer_params\n",
    "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
    "from math import ceil\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZ5IZjSzQNpP"
   },
   "outputs": [],
   "source": [
    "class GPT2ForSequenceClassification(torch.nn.Module):\n",
    "  def __init__(self, num_labels):\n",
    "    super(GPT2ForSequenceClassification, self).__init__()\n",
    "    self.model = GPT2Model.from_pretrained('gpt2-medium',\n",
    "                                       config=GPT2Config.from_pretrained('gpt2-medium'))\n",
    "    self.dropout = torch.nn.Dropout(p=0.1)\n",
    "    self.fc_layer = torch.nn.Linear(in_features=1024, out_features=1024)\n",
    "    self.tanh = torch.nn.Tanh()\n",
    "    self.out_layer = torch.nn.Linear(in_features=1024, out_features=num_labels)\n",
    "    self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels):\n",
    "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
    "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
    "\n",
    "    gpt_last_layer = gpt_last_layer.permute(0, 2, 1)\n",
    "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "\n",
    "    global_max_pooling_out, _ = torch.max(gpt_last_layer, axis=2)\n",
    "    global_max_pooling_out = self.dropout(global_max_pooling_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "\n",
    "    fc_layer_out = self.fc_layer(global_max_pooling_out)\n",
    "    fc_layer_out = self.tanh(fc_layer_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "\n",
    "    fc_layer_out = self.dropout(fc_layer_out)\n",
    "    logits = self.out_layer(fc_layer_out)\n",
    "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
    "    \n",
    "    loss = self.criterion(logits, labels)\n",
    "                                   \n",
    "    return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4_cQpe_c4BN"
   },
   "outputs": [],
   "source": [
    "def load_transformer(name, binary):\n",
    "  num_classes = 5\n",
    "  if binary:\n",
    "    num_classes = 2\n",
    "  model = GPT2ForSequenceClassification(num_classes)\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "  tokenizer.add_special_tokens({'pad_token': '.'})\n",
    "\n",
    "  return {'model': model,\n",
    "          'tokenizer': tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq-C2k3kcylS"
   },
   "outputs": [],
   "source": [
    "def add_special_tokens(text):\n",
    "  text = list(text)\n",
    "  for i in range(len(text)):\n",
    "    text[i] = '<|endoftext|> ' + text[i] + ' <|endoftext|>'\n",
    "  return tuple(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQFaW79Rdi0R"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcSgyPvydj0s"
   },
   "outputs": [],
   "source": [
    "def train_step(model, inputs, labels, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7984ypaMdixv"
   },
   "outputs": [],
   "source": [
    "def eval_step(model, inputs, labels):\n",
    "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbHHlscCdivT"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, tokenizer, train_dataset, optimizer, batch_size):\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
    "        for text, sentiment in train_loader:\n",
    "            text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
    "            sentiment = sentiment.to(device)\n",
    "\n",
    "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
    "\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            correct_count += (preds == sentiment).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPxnxXajditk"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, tokenizer, eval_dataset, batch_size, split):\n",
    "    eval_loader = DataLoader(dataset=eval_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
    "            for text, sentiment in eval_loader:\n",
    "                text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
    "                sentiment = sentiment.to(device)\n",
    "\n",
    "                logits, loss = eval_step(model, text, sentiment)\n",
    "\n",
    "                preds = torch.argmax(logits, axis=1)\n",
    "                y_pred += preds.cpu().numpy().tolist()\n",
    "                y_true += sentiment.cpu().numpy().tolist()\n",
    "\n",
    "                correct_count += (preds == sentiment).sum().item()\n",
    "                total_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
    "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JQeDe5FdirO"
   },
   "outputs": [],
   "source": [
    "def train(name, root, binary, epochs=25, patience=3, save=False):\n",
    "\n",
    "    #load model and tokenizer..\n",
    "    try:\n",
    "        transformer_container = load_transformer(name, binary)\n",
    "    except ValueError:\n",
    "        logger.error(\"Invalid transformer name!\")\n",
    "        os._exit(0)\n",
    "    model = transformer_container['model']\n",
    "    model = model.to(device)\n",
    "    tokenizer = transformer_container['tokenizer']\n",
    "\n",
    "    #load batch_size and learning rate..\n",
    "    params_container = transformer_params(name)\n",
    "    batch_size = params_container['batch_size']\n",
    "    learning_rate = params_container['learning_rate']\n",
    "\n",
    "    #load train, dev and test datasets..\n",
    "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
    "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
    "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
    "\n",
    "    #Intialize optimizer..\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Initialize training variables..\n",
    "    best_acc = 0.0\n",
    "    best_loss = np.inf\n",
    "    stopping_step = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    total_train_seconds = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        train_acc, train_loss = train_epoch(model, tokenizer, train_dataset, optimizer, batch_size)\n",
    "        end = time.time()\n",
    "        total_train_seconds += (end - start)\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
    "\n",
    "        dev_acc, dev_loss, _ = eval_epoch(model, tokenizer, dev_dataset, batch_size, 'dev')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
    "\n",
    "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, tokenizer, test_dataset,\n",
    "                                                                  batch_size, 'test')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
    "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
    "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
    "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
    "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
    "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
    "\n",
    "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
    "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
    "\n",
    "        #save best model and delete previous ones...\n",
    "        if save:\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                phrase_type, label = root_and_binary_title(root, binary)\n",
    "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
    "                save_model(model, model_name, best_model_name)\n",
    "\n",
    "\n",
    "        # Implement early stopping here\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step += 1\n",
    "\n",
    "        if stopping_step >= patience:\n",
    "            logger.info(\"EarlyStopping!\")\n",
    "            os._exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "axYwav8wdiou",
    "outputId": "5ab424b0-2b75-4466-ffc5-0d81003324f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-09-01 07:11:49.675 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
      "2020-09-01 07:11:57.255 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
      "2020-09-01 07:12:02.233 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
      "train: 100%|██████████| 267/267 [02:37<00:00,  1.69batch/s]\n",
      "2020-09-01 07:14:40.671 | INFO     | __main__:train:39 - epoch: 1, transformer: gpt2, train_loss: 0.0496, train_acc: 26.16\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 07:14:46.887 | INFO     | __main__:train:42 - epoch: 1, transformer: gpt2, dev_loss: 0.0494, dev_acc: 28.52\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 07:14:59.727 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_loss: 0.0491, test_acc: 30.14\n",
      "2020-09-01 07:14:59.727 | INFO     | __main__:train:47 - epoch: 1, transformer: gpt2, test_precision: 23.08, test_recall: 23.42, test_f1_score: 17.41, test_accuracy_score: 30.14\n",
      "2020-09-01 07:14:59.728 | INFO     | __main__:train:52 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
      "[[  1 180   0  89   9]\n",
      " [  0 386   0 219  28]\n",
      " [  2 236   0 141  10]\n",
      " [  0 228   0 260  22]\n",
      " [  0 172   1 207  19]]\n",
      "2020-09-01 07:14:59.729 | INFO     | __main__:train:55 - Total training time elapsed: 0:02:37.876215\n",
      "2020-09-01 07:14:59.730 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:37.876215\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.70batch/s]\n",
      "2020-09-01 07:17:36.372 | INFO     | __main__:train:39 - epoch: 2, transformer: gpt2, train_loss: 0.0433, train_acc: 39.30\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.61batch/s]\n",
      "2020-09-01 07:17:42.620 | INFO     | __main__:train:42 - epoch: 2, transformer: gpt2, dev_loss: 0.0381, dev_acc: 45.23\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.40batch/s]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2020-09-01 07:17:55.596 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_loss: 0.0365, test_acc: 46.56\n",
      "2020-09-01 07:17:55.597 | INFO     | __main__:train:47 - epoch: 2, transformer: gpt2, test_precision: 35.11, test_recall: 37.05, test_f1_score: 27.99, test_accuracy_score: 46.56\n",
      "2020-09-01 07:17:55.597 | INFO     | __main__:train:52 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 25 235   5  14   0]\n",
      " [ 12 550  12  59   0]\n",
      " [  2 234   6 147   0]\n",
      " [  0  53   9 448   0]\n",
      " [  0   7   1 391   0]]\n",
      "2020-09-01 07:17:55.598 | INFO     | __main__:train:55 - Total training time elapsed: 0:05:14.517208\n",
      "2020-09-01 07:17:55.599 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:37.258604\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:20:31.746 | INFO     | __main__:train:39 - epoch: 3, transformer: gpt2, train_loss: 0.0360, train_acc: 48.44\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.58batch/s]\n",
      "2020-09-01 07:20:38.037 | INFO     | __main__:train:42 - epoch: 3, transformer: gpt2, dev_loss: 0.0368, dev_acc: 46.59\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.50batch/s]\n",
      "2020-09-01 07:20:50.779 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_loss: 0.0351, test_acc: 48.33\n",
      "2020-09-01 07:20:50.779 | INFO     | __main__:train:47 - epoch: 3, transformer: gpt2, test_precision: 50.34, test_recall: 46.91, test_f1_score: 45.07, test_accuracy_score: 48.33\n",
      "2020-09-01 07:20:50.780 | INFO     | __main__:train:52 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
      "[[171  91  12   4   1]\n",
      " [208 349  47  29   0]\n",
      " [ 33 185  79  91   1]\n",
      " [  0  45  70 362  33]\n",
      " [  0   7  15 270 107]]\n",
      "2020-09-01 07:20:50.781 | INFO     | __main__:train:55 - Total training time elapsed: 0:07:50.662982\n",
      "2020-09-01 07:20:50.782 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.887661\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.71batch/s]\n",
      "2020-09-01 07:23:26.576 | INFO     | __main__:train:39 - epoch: 4, transformer: gpt2, train_loss: 0.0323, train_acc: 55.16\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.61batch/s]\n",
      "2020-09-01 07:23:32.834 | INFO     | __main__:train:42 - epoch: 4, transformer: gpt2, dev_loss: 0.0360, dev_acc: 51.86\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 07:23:45.660 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_loss: 0.0331, test_acc: 55.11\n",
      "2020-09-01 07:23:45.661 | INFO     | __main__:train:47 - epoch: 4, transformer: gpt2, test_precision: 54.43, test_recall: 51.24, test_f1_score: 51.16, test_accuracy_score: 55.11\n",
      "2020-09-01 07:23:45.662 | INFO     | __main__:train:52 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
      "[[116 147   9   6   1]\n",
      " [ 80 472  43  35   3]\n",
      " [  6 198  68 110   7]\n",
      " [  1  34  46 335  94]\n",
      " [  0   6   5 161 227]]\n",
      "2020-09-01 07:23:45.662 | INFO     | __main__:train:55 - Total training time elapsed: 0:10:26.456351\n",
      "2020-09-01 07:23:45.663 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.614088\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.70batch/s]\n",
      "2020-09-01 07:26:22.623 | INFO     | __main__:train:39 - epoch: 5, transformer: gpt2, train_loss: 0.0296, train_acc: 58.39\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.63batch/s]\n",
      "2020-09-01 07:26:28.858 | INFO     | __main__:train:42 - epoch: 5, transformer: gpt2, dev_loss: 0.0345, dev_acc: 52.13\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 07:26:41.690 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_loss: 0.0325, test_acc: 56.92\n",
      "2020-09-01 07:26:41.690 | INFO     | __main__:train:47 - epoch: 5, transformer: gpt2, test_precision: 57.18, test_recall: 53.72, test_f1_score: 54.45, test_accuracy_score: 56.92\n",
      "2020-09-01 07:26:41.691 | INFO     | __main__:train:52 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
      "[[128 133  14   3   1]\n",
      " [ 85 459  58  29   2]\n",
      " [  9 160 126  89   5]\n",
      " [  1  21  72 344  72]\n",
      " [  0   3  11 184 201]]\n",
      "2020-09-01 07:26:41.692 | INFO     | __main__:train:55 - Total training time elapsed: 0:13:03.415890\n",
      "2020-09-01 07:26:41.693 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.683178\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:29:18.230 | INFO     | __main__:train:39 - epoch: 6, transformer: gpt2, train_loss: 0.0270, train_acc: 62.93\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.63batch/s]\n",
      "2020-09-01 07:29:24.456 | INFO     | __main__:train:42 - epoch: 6, transformer: gpt2, dev_loss: 0.0356, dev_acc: 53.13\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.52batch/s]\n",
      "2020-09-01 07:29:37.161 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_loss: 0.0333, test_acc: 55.07\n",
      "2020-09-01 07:29:37.161 | INFO     | __main__:train:47 - epoch: 6, transformer: gpt2, test_precision: 56.84, test_recall: 52.29, test_f1_score: 53.32, test_accuracy_score: 55.07\n",
      "2020-09-01 07:29:37.162 | INFO     | __main__:train:52 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
      "[[117 134  22   4   2]\n",
      " [ 63 407 116  43   4]\n",
      " [  5 120 149 108   7]\n",
      " [  0  11  78 356  65]\n",
      " [  0   0  10 201 188]]\n",
      "2020-09-01 07:29:37.163 | INFO     | __main__:train:55 - Total training time elapsed: 0:15:39.951930\n",
      "2020-09-01 07:29:37.164 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.658655\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:32:13.185 | INFO     | __main__:train:39 - epoch: 7, transformer: gpt2, train_loss: 0.0242, train_acc: 67.90\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 07:32:19.409 | INFO     | __main__:train:42 - epoch: 7, transformer: gpt2, dev_loss: 0.0370, dev_acc: 51.41\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.53batch/s]\n",
      "2020-09-01 07:32:32.093 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_loss: 0.0345, test_acc: 55.38\n",
      "2020-09-01 07:32:32.093 | INFO     | __main__:train:47 - epoch: 7, transformer: gpt2, test_precision: 57.39, test_recall: 53.01, test_f1_score: 53.97, test_accuracy_score: 55.38\n",
      "2020-09-01 07:32:32.094 | INFO     | __main__:train:52 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
      "[[136 125  15   2   1]\n",
      " [ 80 431 103  17   2]\n",
      " [  9 140 168  68   4]\n",
      " [  1  18 122 321  48]\n",
      " [  0   0  29 202 168]]\n",
      "2020-09-01 07:32:32.095 | INFO     | __main__:train:55 - Total training time elapsed: 0:18:15.971927\n",
      "2020-09-01 07:32:32.096 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.567418\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.71batch/s]\n",
      "2020-09-01 07:35:07.837 | INFO     | __main__:train:39 - epoch: 8, transformer: gpt2, train_loss: 0.0219, train_acc: 70.93\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.60batch/s]\n",
      "2020-09-01 07:35:14.105 | INFO     | __main__:train:42 - epoch: 8, transformer: gpt2, dev_loss: 0.0380, dev_acc: 52.77\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.49batch/s]\n",
      "2020-09-01 07:35:26.866 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_loss: 0.0353, test_acc: 54.84\n",
      "2020-09-01 07:35:26.867 | INFO     | __main__:train:47 - epoch: 8, transformer: gpt2, test_precision: 55.87, test_recall: 53.06, test_f1_score: 53.42, test_accuracy_score: 54.84\n",
      "2020-09-01 07:35:26.867 | INFO     | __main__:train:52 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
      "[[149 108  17   4   1]\n",
      " [115 397  96  22   3]\n",
      " [ 18 131 152  83   5]\n",
      " [  1  17  99 343  50]\n",
      " [  0   2  19 207 171]]\n",
      "2020-09-01 07:35:26.868 | INFO     | __main__:train:55 - Total training time elapsed: 0:20:51.712481\n",
      "2020-09-01 07:35:26.869 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.464060\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:38:03.032 | INFO     | __main__:train:39 - epoch: 9, transformer: gpt2, train_loss: 0.0199, train_acc: 74.52\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.62batch/s]\n",
      "2020-09-01 07:38:09.273 | INFO     | __main__:train:42 - epoch: 9, transformer: gpt2, dev_loss: 0.0393, dev_acc: 51.50\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.47batch/s]\n",
      "2020-09-01 07:38:22.079 | INFO     | __main__:train:46 - epoch: 9, transformer: gpt2, test_loss: 0.0357, test_acc: 56.29\n",
      "2020-09-01 07:38:22.080 | INFO     | __main__:train:47 - epoch: 9, transformer: gpt2, test_precision: 56.40, test_recall: 54.47, test_f1_score: 55.00, test_accuracy_score: 56.29\n",
      "2020-09-01 07:38:22.080 | INFO     | __main__:train:52 - epoch: 9, transformer: gpt2, test_confusion_matrix: \n",
      "[[150 113  13   1   2]\n",
      " [104 420  83  21   5]\n",
      " [ 13 149 148  73   6]\n",
      " [  1  25  87 323  74]\n",
      " [  0   2  17 177 203]]\n",
      "2020-09-01 07:38:22.081 | INFO     | __main__:train:55 - Total training time elapsed: 0:23:27.874153\n",
      "2020-09-01 07:38:22.082 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.430461\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.72batch/s]\n",
      "2020-09-01 07:40:57.712 | INFO     | __main__:train:39 - epoch: 10, transformer: gpt2, train_loss: 0.0176, train_acc: 78.46\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.57batch/s]\n",
      "2020-09-01 07:41:04.007 | INFO     | __main__:train:42 - epoch: 10, transformer: gpt2, dev_loss: 0.0417, dev_acc: 52.68\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 07:41:16.836 | INFO     | __main__:train:46 - epoch: 10, transformer: gpt2, test_loss: 0.0378, test_acc: 54.03\n",
      "2020-09-01 07:41:16.836 | INFO     | __main__:train:47 - epoch: 10, transformer: gpt2, test_precision: 54.59, test_recall: 52.49, test_f1_score: 53.09, test_accuracy_score: 54.03\n",
      "2020-09-01 07:41:16.837 | INFO     | __main__:train:52 - epoch: 10, transformer: gpt2, test_confusion_matrix: \n",
      "[[141 116  20   0   2]\n",
      " [109 394 105  22   3]\n",
      " [ 12 132 163  77   5]\n",
      " [  1  18 113 303  75]\n",
      " [  0   1  22 183 193]]\n",
      "2020-09-01 07:41:16.838 | INFO     | __main__:train:55 - Total training time elapsed: 0:26:03.503045\n",
      "2020-09-01 07:41:16.839 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.350304\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:43:53.248 | INFO     | __main__:train:39 - epoch: 11, transformer: gpt2, train_loss: 0.0152, train_acc: 81.76\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 07:43:59.473 | INFO     | __main__:train:42 - epoch: 11, transformer: gpt2, dev_loss: 0.0440, dev_acc: 52.59\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.49batch/s]\n",
      "2020-09-01 07:44:12.242 | INFO     | __main__:train:46 - epoch: 11, transformer: gpt2, test_loss: 0.0389, test_acc: 55.84\n",
      "2020-09-01 07:44:12.242 | INFO     | __main__:train:47 - epoch: 11, transformer: gpt2, test_precision: 55.29, test_recall: 55.20, test_f1_score: 55.22, test_accuracy_score: 55.84\n",
      "2020-09-01 07:44:12.243 | INFO     | __main__:train:52 - epoch: 11, transformer: gpt2, test_confusion_matrix: \n",
      "[[152 105  20   0   2]\n",
      " [121 374 111  22   5]\n",
      " [ 16 119 163  84   7]\n",
      " [  2  15  91 294 108]\n",
      " [  0   2  18 128 251]]\n",
      "2020-09-01 07:44:12.244 | INFO     | __main__:train:55 - Total training time elapsed: 0:28:39.911462\n",
      "2020-09-01 07:44:12.245 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.355587\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.72batch/s]\n",
      "2020-09-01 07:46:47.481 | INFO     | __main__:train:39 - epoch: 12, transformer: gpt2, train_loss: 0.0132, train_acc: 84.78\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 07:46:53.696 | INFO     | __main__:train:42 - epoch: 12, transformer: gpt2, dev_loss: 0.0454, dev_acc: 51.95\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.48batch/s]\n",
      "2020-09-01 07:47:06.476 | INFO     | __main__:train:46 - epoch: 12, transformer: gpt2, test_loss: 0.0429, test_acc: 55.29\n",
      "2020-09-01 07:47:06.477 | INFO     | __main__:train:47 - epoch: 12, transformer: gpt2, test_precision: 56.06, test_recall: 53.57, test_f1_score: 54.41, test_accuracy_score: 55.29\n",
      "2020-09-01 07:47:06.478 | INFO     | __main__:train:52 - epoch: 12, transformer: gpt2, test_confusion_matrix: \n",
      "[[125 133  17   3   1]\n",
      " [ 84 395 129  22   3]\n",
      " [  8 121 180  74   6]\n",
      " [  1  17 105 302  85]\n",
      " [  0   2  17 160 220]]\n",
      "2020-09-01 07:47:06.479 | INFO     | __main__:train:55 - Total training time elapsed: 0:31:15.147099\n",
      "2020-09-01 07:47:06.480 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.262258\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:49:42.616 | INFO     | __main__:train:39 - epoch: 13, transformer: gpt2, train_loss: 0.0111, train_acc: 87.62\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.50batch/s]\n",
      "2020-09-01 07:49:48.993 | INFO     | __main__:train:42 - epoch: 13, transformer: gpt2, dev_loss: 0.0488, dev_acc: 51.68\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.48batch/s]\n",
      "2020-09-01 07:50:01.783 | INFO     | __main__:train:46 - epoch: 13, transformer: gpt2, test_loss: 0.0442, test_acc: 54.30\n",
      "2020-09-01 07:50:01.784 | INFO     | __main__:train:47 - epoch: 13, transformer: gpt2, test_precision: 54.55, test_recall: 52.84, test_f1_score: 53.33, test_accuracy_score: 54.30\n",
      "2020-09-01 07:50:01.785 | INFO     | __main__:train:52 - epoch: 13, transformer: gpt2, test_confusion_matrix: \n",
      "[[131 119  25   2   2]\n",
      " [102 364 126  38   3]\n",
      " [ 10 101 156 117   5]\n",
      " [  1   9  77 329  94]\n",
      " [  0   0  11 168 220]]\n",
      "2020-09-01 07:50:01.785 | INFO     | __main__:train:55 - Total training time elapsed: 0:33:51.282324\n",
      "2020-09-01 07:50:01.786 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.252486\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:52:37.851 | INFO     | __main__:train:39 - epoch: 14, transformer: gpt2, train_loss: 0.0098, train_acc: 88.97\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.69batch/s]\n",
      "2020-09-01 07:52:44.012 | INFO     | __main__:train:42 - epoch: 14, transformer: gpt2, dev_loss: 0.0500, dev_acc: 52.41\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.44batch/s]\n",
      "2020-09-01 07:52:56.901 | INFO     | __main__:train:46 - epoch: 14, transformer: gpt2, test_loss: 0.0472, test_acc: 54.80\n",
      "2020-09-01 07:52:56.902 | INFO     | __main__:train:47 - epoch: 14, transformer: gpt2, test_precision: 56.13, test_recall: 52.44, test_f1_score: 53.37, test_accuracy_score: 54.80\n",
      "2020-09-01 07:52:56.903 | INFO     | __main__:train:52 - epoch: 14, transformer: gpt2, test_confusion_matrix: \n",
      "[[126 133  17   2   1]\n",
      " [ 81 415 115  19   3]\n",
      " [ 11 127 169  77   5]\n",
      " [  1  17 110 321  61]\n",
      " [  0   2  24 193 180]]\n",
      "2020-09-01 07:52:56.903 | INFO     | __main__:train:55 - Total training time elapsed: 0:36:27.346610\n",
      "2020-09-01 07:52:56.904 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.239044\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 07:55:33.326 | INFO     | __main__:train:39 - epoch: 15, transformer: gpt2, train_loss: 0.0086, train_acc: 90.61\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 07:55:39.544 | INFO     | __main__:train:42 - epoch: 15, transformer: gpt2, dev_loss: 0.0526, dev_acc: 50.86\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.48batch/s]\n",
      "2020-09-01 07:55:52.330 | INFO     | __main__:train:46 - epoch: 15, transformer: gpt2, test_loss: 0.0471, test_acc: 53.21\n",
      "2020-09-01 07:55:52.330 | INFO     | __main__:train:47 - epoch: 15, transformer: gpt2, test_precision: 53.91, test_recall: 52.59, test_f1_score: 52.80, test_accuracy_score: 53.21\n",
      "2020-09-01 07:55:52.331 | INFO     | __main__:train:52 - epoch: 15, transformer: gpt2, test_confusion_matrix: \n",
      "[[146 111  20   1   1]\n",
      " [133 356 124  17   3]\n",
      " [ 21 108 181  75   4]\n",
      " [  3  12 130 288  77]\n",
      " [  1   1  27 165 205]]\n",
      "2020-09-01 07:55:52.332 | INFO     | __main__:train:55 - Total training time elapsed: 0:39:03.767611\n",
      "2020-09-01 07:55:52.333 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.251174\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.72batch/s]\n",
      "2020-09-01 07:58:27.944 | INFO     | __main__:train:39 - epoch: 16, transformer: gpt2, train_loss: 0.0071, train_acc: 92.79\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.66batch/s]\n",
      "2020-09-01 07:58:34.147 | INFO     | __main__:train:42 - epoch: 16, transformer: gpt2, dev_loss: 0.0555, dev_acc: 49.50\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 07:58:46.992 | INFO     | __main__:train:46 - epoch: 16, transformer: gpt2, test_loss: 0.0517, test_acc: 52.76\n",
      "2020-09-01 07:58:46.993 | INFO     | __main__:train:47 - epoch: 16, transformer: gpt2, test_precision: 54.78, test_recall: 51.11, test_f1_score: 51.54, test_accuracy_score: 52.76\n",
      "2020-09-01 07:58:46.994 | INFO     | __main__:train:52 - epoch: 16, transformer: gpt2, test_confusion_matrix: \n",
      "[[142 120  14   2   1]\n",
      " [107 401 108  15   2]\n",
      " [ 16 122 184  64   3]\n",
      " [  0  21 147 294  48]\n",
      " [  1   1  34 218 145]]\n",
      "2020-09-01 07:58:46.995 | INFO     | __main__:train:55 - Total training time elapsed: 0:41:39.377774\n",
      "2020-09-01 07:58:46.996 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.211111\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.71batch/s]\n",
      "2020-09-01 08:01:22.913 | INFO     | __main__:train:39 - epoch: 17, transformer: gpt2, train_loss: 0.0066, train_acc: 93.33\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 08:01:29.133 | INFO     | __main__:train:42 - epoch: 17, transformer: gpt2, dev_loss: 0.0576, dev_acc: 50.95\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.47batch/s]\n",
      "2020-09-01 08:01:41.943 | INFO     | __main__:train:46 - epoch: 17, transformer: gpt2, test_loss: 0.0527, test_acc: 54.84\n",
      "2020-09-01 08:01:41.944 | INFO     | __main__:train:47 - epoch: 17, transformer: gpt2, test_precision: 55.87, test_recall: 52.96, test_f1_score: 53.78, test_accuracy_score: 54.84\n",
      "2020-09-01 08:01:41.945 | INFO     | __main__:train:52 - epoch: 17, transformer: gpt2, test_confusion_matrix: \n",
      "[[119 138  19   1   2]\n",
      " [ 82 375 149  24   3]\n",
      " [  5 103 177 100   4]\n",
      " [  0  11  83 333  83]\n",
      " [  0   1  20 170 208]]\n",
      "2020-09-01 08:01:41.946 | INFO     | __main__:train:55 - Total training time elapsed: 0:44:15.293391\n",
      "2020-09-01 08:01:41.947 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.193729\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.71batch/s]\n",
      "2020-09-01 08:04:17.763 | INFO     | __main__:train:39 - epoch: 18, transformer: gpt2, train_loss: 0.0056, train_acc: 94.65\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.71batch/s]\n",
      "2020-09-01 08:04:23.909 | INFO     | __main__:train:42 - epoch: 18, transformer: gpt2, dev_loss: 0.0599, dev_acc: 50.95\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.52batch/s]\n",
      "2020-09-01 08:04:36.597 | INFO     | __main__:train:46 - epoch: 18, transformer: gpt2, test_loss: 0.0540, test_acc: 53.44\n",
      "2020-09-01 08:04:36.597 | INFO     | __main__:train:47 - epoch: 18, transformer: gpt2, test_precision: 55.71, test_recall: 51.77, test_f1_score: 52.40, test_accuracy_score: 53.44\n",
      "2020-09-01 08:04:36.598 | INFO     | __main__:train:52 - epoch: 18, transformer: gpt2, test_confusion_matrix: \n",
      "[[122 134  20   2   1]\n",
      " [ 91 371 150  19   2]\n",
      " [ 10  99 208  69   3]\n",
      " [  0  14 126 316  54]\n",
      " [  0   2  23 210 164]]\n",
      "2020-09-01 08:04:36.599 | INFO     | __main__:train:55 - Total training time elapsed: 0:46:51.108892\n",
      "2020-09-01 08:04:36.600 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.172716\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:07:13.198 | INFO     | __main__:train:39 - epoch: 19, transformer: gpt2, train_loss: 0.0051, train_acc: 95.10\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.73batch/s]\n",
      "2020-09-01 08:07:19.326 | INFO     | __main__:train:42 - epoch: 19, transformer: gpt2, dev_loss: 0.0627, dev_acc: 49.95\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.51batch/s]\n",
      "2020-09-01 08:07:32.048 | INFO     | __main__:train:46 - epoch: 19, transformer: gpt2, test_loss: 0.0559, test_acc: 54.07\n",
      "2020-09-01 08:07:32.048 | INFO     | __main__:train:47 - epoch: 19, transformer: gpt2, test_precision: 55.36, test_recall: 52.96, test_f1_score: 53.55, test_accuracy_score: 54.07\n",
      "2020-09-01 08:07:32.049 | INFO     | __main__:train:52 - epoch: 19, transformer: gpt2, test_confusion_matrix: \n",
      "[[134 120  23   0   2]\n",
      " [100 366 143  21   3]\n",
      " [ 14 100 194  77   4]\n",
      " [  1  10 125 302  72]\n",
      " [  0   1  22 177 199]]\n",
      "2020-09-01 08:07:32.050 | INFO     | __main__:train:55 - Total training time elapsed: 0:49:27.706717\n",
      "2020-09-01 08:07:32.051 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.195090\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:10:08.375 | INFO     | __main__:train:39 - epoch: 20, transformer: gpt2, train_loss: 0.0049, train_acc: 95.17\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.63batch/s]\n",
      "2020-09-01 08:10:14.603 | INFO     | __main__:train:42 - epoch: 20, transformer: gpt2, dev_loss: 0.0616, dev_acc: 50.32\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.46batch/s]\n",
      "2020-09-01 08:10:27.448 | INFO     | __main__:train:46 - epoch: 20, transformer: gpt2, test_loss: 0.0547, test_acc: 53.57\n",
      "2020-09-01 08:10:27.448 | INFO     | __main__:train:47 - epoch: 20, transformer: gpt2, test_precision: 54.56, test_recall: 52.16, test_f1_score: 52.71, test_accuracy_score: 53.57\n",
      "2020-09-01 08:10:27.449 | INFO     | __main__:train:52 - epoch: 20, transformer: gpt2, test_confusion_matrix: \n",
      "[[134 121  21   2   1]\n",
      " [109 368 135  18   3]\n",
      " [ 14 110 175  86   4]\n",
      " [  2  11 109 319  69]\n",
      " [  0   1  18 192 188]]\n",
      "2020-09-01 08:10:27.450 | INFO     | __main__:train:55 - Total training time elapsed: 0:52:04.030280\n",
      "2020-09-01 08:10:27.450 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.201514\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.70batch/s]\n",
      "2020-09-01 08:13:04.067 | INFO     | __main__:train:39 - epoch: 21, transformer: gpt2, train_loss: 0.0042, train_acc: 95.95\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.58batch/s]\n",
      "2020-09-01 08:13:10.352 | INFO     | __main__:train:42 - epoch: 21, transformer: gpt2, dev_loss: 0.0641, dev_acc: 51.32\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.44batch/s]\n",
      "2020-09-01 08:13:23.248 | INFO     | __main__:train:46 - epoch: 21, transformer: gpt2, test_loss: 0.0577, test_acc: 53.21\n",
      "2020-09-01 08:13:23.248 | INFO     | __main__:train:47 - epoch: 21, transformer: gpt2, test_precision: 54.45, test_recall: 52.19, test_f1_score: 52.69, test_accuracy_score: 53.21\n",
      "2020-09-01 08:13:23.249 | INFO     | __main__:train:52 - epoch: 21, transformer: gpt2, test_confusion_matrix: \n",
      "[[139 116  21   1   2]\n",
      " [104 357 152  17   3]\n",
      " [ 13 107 183  82   4]\n",
      " [  2   7 116 309  76]\n",
      " [  0   1  20 190 188]]\n",
      "2020-09-01 08:13:23.250 | INFO     | __main__:train:55 - Total training time elapsed: 0:54:40.646661\n",
      "2020-09-01 08:13:23.251 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.221270\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:15:59.844 | INFO     | __main__:train:39 - epoch: 22, transformer: gpt2, train_loss: 0.0040, train_acc: 95.88\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.62batch/s]\n",
      "2020-09-01 08:16:06.079 | INFO     | __main__:train:42 - epoch: 22, transformer: gpt2, dev_loss: 0.0637, dev_acc: 51.86\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.47batch/s]\n",
      "2020-09-01 08:16:18.890 | INFO     | __main__:train:46 - epoch: 22, transformer: gpt2, test_loss: 0.0552, test_acc: 54.75\n",
      "2020-09-01 08:16:18.891 | INFO     | __main__:train:47 - epoch: 22, transformer: gpt2, test_precision: 54.27, test_recall: 54.23, test_f1_score: 54.19, test_accuracy_score: 54.75\n",
      "2020-09-01 08:16:18.892 | INFO     | __main__:train:52 - epoch: 22, transformer: gpt2, test_confusion_matrix: \n",
      "[[149 100  27   1   2]\n",
      " [128 362 119  19   5]\n",
      " [ 15 109 167  92   6]\n",
      " [  2  13  92 288 115]\n",
      " [  0   2  17 136 244]]\n",
      "2020-09-01 08:16:18.893 | INFO     | __main__:train:55 - Total training time elapsed: 0:57:17.238230\n",
      "2020-09-01 08:16:18.894 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.238101\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.70batch/s]\n",
      "2020-09-01 08:18:55.670 | INFO     | __main__:train:39 - epoch: 23, transformer: gpt2, train_loss: 0.0037, train_acc: 96.50\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.62batch/s]\n",
      "2020-09-01 08:19:01.916 | INFO     | __main__:train:42 - epoch: 23, transformer: gpt2, dev_loss: 0.0670, dev_acc: 50.50\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.52batch/s]\n",
      "2020-09-01 08:19:14.609 | INFO     | __main__:train:46 - epoch: 23, transformer: gpt2, test_loss: 0.0592, test_acc: 54.03\n",
      "2020-09-01 08:19:14.610 | INFO     | __main__:train:47 - epoch: 23, transformer: gpt2, test_precision: 54.00, test_recall: 51.87, test_f1_score: 52.57, test_accuracy_score: 54.03\n",
      "2020-09-01 08:19:14.611 | INFO     | __main__:train:52 - epoch: 23, transformer: gpt2, test_confusion_matrix: \n",
      "[[112 139  25   1   2]\n",
      " [ 84 389 127  30   3]\n",
      " [ 10 111 155 107   6]\n",
      " [  0  13  82 310 105]\n",
      " [  0   3  12 156 228]]\n",
      "2020-09-01 08:19:14.612 | INFO     | __main__:train:55 - Total training time elapsed: 0:59:54.013640\n",
      "2020-09-01 08:19:14.612 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.261463\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:21:51.084 | INFO     | __main__:train:39 - epoch: 24, transformer: gpt2, train_loss: 0.0036, train_acc: 96.47\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.67batch/s]\n",
      "2020-09-01 08:21:57.270 | INFO     | __main__:train:42 - epoch: 24, transformer: gpt2, dev_loss: 0.0668, dev_acc: 49.77\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.43batch/s]\n",
      "2020-09-01 08:22:10.178 | INFO     | __main__:train:46 - epoch: 24, transformer: gpt2, test_loss: 0.0599, test_acc: 52.08\n",
      "2020-09-01 08:22:10.178 | INFO     | __main__:train:47 - epoch: 24, transformer: gpt2, test_precision: 54.36, test_recall: 49.87, test_f1_score: 50.83, test_accuracy_score: 52.08\n",
      "2020-09-01 08:22:10.179 | INFO     | __main__:train:52 - epoch: 24, transformer: gpt2, test_confusion_matrix: \n",
      "[[104 143  29   1   2]\n",
      " [ 67 388 159  16   3]\n",
      " [  7 113 198  67   4]\n",
      " [  0  12 138 287  73]\n",
      " [  0   2  21 202 174]]\n",
      "2020-09-01 08:22:10.180 | INFO     | __main__:train:55 - Total training time elapsed: 1:02:30.484404\n",
      "2020-09-01 08:22:10.181 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.270183\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:24:46.631 | INFO     | __main__:train:39 - epoch: 25, transformer: gpt2, train_loss: 0.0033, train_acc: 96.88\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.70batch/s]\n",
      "2020-09-01 08:24:52.786 | INFO     | __main__:train:42 - epoch: 25, transformer: gpt2, dev_loss: 0.0699, dev_acc: 50.77\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.43batch/s]\n",
      "2020-09-01 08:25:05.685 | INFO     | __main__:train:46 - epoch: 25, transformer: gpt2, test_loss: 0.0615, test_acc: 54.57\n",
      "2020-09-01 08:25:05.686 | INFO     | __main__:train:47 - epoch: 25, transformer: gpt2, test_precision: 55.27, test_recall: 53.11, test_f1_score: 53.77, test_accuracy_score: 54.57\n",
      "2020-09-01 08:25:05.687 | INFO     | __main__:train:52 - epoch: 25, transformer: gpt2, test_confusion_matrix: \n",
      "[[119 124  32   2   2]\n",
      " [ 82 364 155  27   5]\n",
      " [  9  96 180  98   6]\n",
      " [  0   9  92 311  98]\n",
      " [  0   1  15 151 232]]\n",
      "2020-09-01 08:25:05.687 | INFO     | __main__:train:55 - Total training time elapsed: 1:05:06.933450\n",
      "2020-09-01 08:25:05.688 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.277338\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.70batch/s]\n",
      "2020-09-01 08:27:42.678 | INFO     | __main__:train:39 - epoch: 26, transformer: gpt2, train_loss: 0.0031, train_acc: 96.78\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.69batch/s]\n",
      "2020-09-01 08:27:48.839 | INFO     | __main__:train:42 - epoch: 26, transformer: gpt2, dev_loss: 0.0704, dev_acc: 50.95\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.49batch/s]\n",
      "2020-09-01 08:28:01.610 | INFO     | __main__:train:46 - epoch: 26, transformer: gpt2, test_loss: 0.0644, test_acc: 53.03\n",
      "2020-09-01 08:28:01.610 | INFO     | __main__:train:47 - epoch: 26, transformer: gpt2, test_precision: 54.55, test_recall: 50.84, test_f1_score: 51.53, test_accuracy_score: 53.03\n",
      "2020-09-01 08:28:01.611 | INFO     | __main__:train:52 - epoch: 26, transformer: gpt2, test_confusion_matrix: \n",
      "[[115 143  18   1   2]\n",
      " [ 89 391 136  15   2]\n",
      " [ 11 110 193  71   4]\n",
      " [  1  12 125 311  61]\n",
      " [  0   1  21 215 162]]\n",
      "2020-09-01 08:28:01.612 | INFO     | __main__:train:55 - Total training time elapsed: 1:07:43.922482\n",
      "2020-09-01 08:28:01.613 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.304711\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:30:38.156 | INFO     | __main__:train:39 - epoch: 27, transformer: gpt2, train_loss: 0.0029, train_acc: 97.25\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.65batch/s]\n",
      "2020-09-01 08:30:44.362 | INFO     | __main__:train:42 - epoch: 27, transformer: gpt2, dev_loss: 0.0721, dev_acc: 51.41\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.53batch/s]\n",
      "2020-09-01 08:30:57.029 | INFO     | __main__:train:46 - epoch: 27, transformer: gpt2, test_loss: 0.0640, test_acc: 52.99\n",
      "2020-09-01 08:30:57.030 | INFO     | __main__:train:47 - epoch: 27, transformer: gpt2, test_precision: 54.06, test_recall: 51.66, test_f1_score: 52.23, test_accuracy_score: 52.99\n",
      "2020-09-01 08:30:57.030 | INFO     | __main__:train:52 - epoch: 27, transformer: gpt2, test_confusion_matrix: \n",
      "[[125 125  26   2   1]\n",
      " [ 93 348 166  23   3]\n",
      " [ 12  97 182  94   4]\n",
      " [  2   7  93 322  86]\n",
      " [  0   2  16 187 194]]\n",
      "2020-09-01 08:30:57.031 | INFO     | __main__:train:55 - Total training time elapsed: 1:10:20.464619\n",
      "2020-09-01 08:30:57.032 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.313504\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:33:33.479 | INFO     | __main__:train:39 - epoch: 28, transformer: gpt2, train_loss: 0.0024, train_acc: 97.68\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.64batch/s]\n",
      "2020-09-01 08:33:39.703 | INFO     | __main__:train:42 - epoch: 28, transformer: gpt2, dev_loss: 0.0722, dev_acc: 50.86\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.48batch/s]\n",
      "2020-09-01 08:33:52.495 | INFO     | __main__:train:46 - epoch: 28, transformer: gpt2, test_loss: 0.0646, test_acc: 54.25\n",
      "2020-09-01 08:33:52.496 | INFO     | __main__:train:47 - epoch: 28, transformer: gpt2, test_precision: 54.29, test_recall: 53.14, test_f1_score: 53.46, test_accuracy_score: 54.25\n",
      "2020-09-01 08:33:52.497 | INFO     | __main__:train:52 - epoch: 28, transformer: gpt2, test_confusion_matrix: \n",
      "[[124 124  24   5   2]\n",
      " [ 96 346 153  33   5]\n",
      " [ 11  88 172 111   7]\n",
      " [  0   8  71 316 115]\n",
      " [  0   2  12 144 241]]\n",
      "2020-09-01 08:33:52.497 | INFO     | __main__:train:55 - Total training time elapsed: 1:12:56.911174\n",
      "2020-09-01 08:33:52.498 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.318256\n",
      "train: 100%|██████████| 267/267 [02:36<00:00,  1.71batch/s]\n",
      "2020-09-01 08:36:28.920 | INFO     | __main__:train:39 - epoch: 29, transformer: gpt2, train_loss: 0.0026, train_acc: 97.57\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.59batch/s]\n",
      "2020-09-01 08:36:35.191 | INFO     | __main__:train:42 - epoch: 29, transformer: gpt2, dev_loss: 0.0738, dev_acc: 50.86\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.45batch/s]\n",
      "2020-09-01 08:36:48.055 | INFO     | __main__:train:46 - epoch: 29, transformer: gpt2, test_loss: 0.0658, test_acc: 54.12\n",
      "2020-09-01 08:36:48.056 | INFO     | __main__:train:47 - epoch: 29, transformer: gpt2, test_precision: 54.77, test_recall: 52.44, test_f1_score: 53.05, test_accuracy_score: 54.12\n",
      "2020-09-01 08:36:48.056 | INFO     | __main__:train:52 - epoch: 29, transformer: gpt2, test_confusion_matrix: \n",
      "[[120 132  24   1   2]\n",
      " [ 95 359 151  25   3]\n",
      " [  9  97 175 104   4]\n",
      " [  0   9  80 336  85]\n",
      " [  0   0  15 178 206]]\n",
      "2020-09-01 08:36:48.057 | INFO     | __main__:train:55 - Total training time elapsed: 1:15:33.331518\n",
      "2020-09-01 08:36:48.058 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.321776\n",
      "train: 100%|██████████| 267/267 [02:35<00:00,  1.71batch/s]\n",
      "2020-09-01 08:39:23.764 | INFO     | __main__:train:39 - epoch: 30, transformer: gpt2, train_loss: 0.0027, train_acc: 97.33\n",
      "dev: 100%|██████████| 35/35 [00:06<00:00,  5.63batch/s]\n",
      "2020-09-01 08:39:29.995 | INFO     | __main__:train:42 - epoch: 30, transformer: gpt2, dev_loss: 0.0767, dev_acc: 49.50\n",
      "test: 100%|██████████| 70/70 [00:12<00:00,  5.44batch/s]\n",
      "2020-09-01 08:39:42.890 | INFO     | __main__:train:46 - epoch: 30, transformer: gpt2, test_loss: 0.0684, test_acc: 51.99\n",
      "2020-09-01 08:39:42.891 | INFO     | __main__:train:47 - epoch: 30, transformer: gpt2, test_precision: 54.27, test_recall: 50.34, test_f1_score: 50.87, test_accuracy_score: 51.99\n",
      "2020-09-01 08:39:42.892 | INFO     | __main__:train:52 - epoch: 30, transformer: gpt2, test_confusion_matrix: \n",
      "[[117 133  27   1   1]\n",
      " [ 93 360 165  12   3]\n",
      " [ 11  98 208  68   4]\n",
      " [  1   9 135 309  56]\n",
      " [  0   1  26 217 155]]\n",
      "2020-09-01 08:39:42.892 | INFO     | __main__:train:55 - Total training time elapsed: 1:18:09.036727\n",
      "2020-09-01 08:39:42.893 | INFO     | __main__:train:56 - Mean time per train epoch: 0:02:36.301224\n"
     ]
    }
   ],
   "source": [
    "train('gpt2', True, False, 30, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJ12BnAei0FS"
   },
   "outputs": [],
   "source": [
    "a = (\"dfs\", 'dfd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "bRZpL_cidimc",
    "outputId": "1adbff70-a4fc-4f34-98c3-33c1d5d215f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dfs', 'dfd')"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Iz3muFrUdikk",
    "outputId": "106c15f7-d126-429d-b151-68b1b17cdaad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dfs', 'dfd']"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "kjd7B--JdiiN",
    "outputId": "79a99036-2403-4328-a643-d0679e9a4522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dfs', 'dfd')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tuple(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXqhawGkdigP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Medium GPT2(Pool).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
