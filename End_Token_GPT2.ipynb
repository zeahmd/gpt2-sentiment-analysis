{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End Token GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b13701d78dd646a5b3b13cb2a1abb36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d72818de48554d39b2377d0a112f3269",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bb717a93f78429cb39b131444a3f75a",
              "IPY_MODEL_7bdf156fa7df4f149d8b1aa716b36587"
            ]
          }
        },
        "d72818de48554d39b2377d0a112f3269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bb717a93f78429cb39b131444a3f75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39bae5fc5e4241c6b0153927318f6504",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6716fed235f4e3d987a932c7284e8a6"
          }
        },
        "7bdf156fa7df4f149d8b1aa716b36587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e03eab6ce4c4d9183d6da695fdfc193",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.54MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e8393bc35284ef29a70889ef2324af3"
          }
        },
        "39bae5fc5e4241c6b0153927318f6504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6716fed235f4e3d987a932c7284e8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e03eab6ce4c4d9183d6da695fdfc193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e8393bc35284ef29a70889ef2324af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff795ce6004b4495b2340cc19cc6a1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6114813f06894b36acad6c76a13ac791",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c3f0746068e416284b6cd4fb2cf6af2",
              "IPY_MODEL_3fd683952d4643738a050088789920b2"
            ]
          }
        },
        "6114813f06894b36acad6c76a13ac791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c3f0746068e416284b6cd4fb2cf6af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04aad504c1ce4ebba7bf65599c2a0442",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f9429376e6d42b993f176b92a8757f6"
          }
        },
        "3fd683952d4643738a050088789920b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1c522cd6a50492481473fea9cc77ec7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 3.60MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_945ca15f280a48d3a383ca63b21516d4"
          }
        },
        "04aad504c1ce4ebba7bf65599c2a0442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f9429376e6d42b993f176b92a8757f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1c522cd6a50492481473fea9cc77ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "945ca15f280a48d3a383ca63b21516d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cba6e503f5bc41b4a51ff5940ba3b060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_521ea0ee0db848728f6696d4cfbbf529",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c086b3e36b4474a9355cfe8467865e0",
              "IPY_MODEL_1ebe445c61074c3ab02689e65a62878c"
            ]
          }
        },
        "521ea0ee0db848728f6696d4cfbbf529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c086b3e36b4474a9355cfe8467865e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7622ed476e6d44189ae48f3664c2fa6c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea6c55659b0045d28fa2ec06966f3dad"
          }
        },
        "1ebe445c61074c3ab02689e65a62878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f397323e16c14d079f0c3643df668df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:39&lt;00:00, 16.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64f93e4de8b046ceae59f7f5157cf041"
          }
        },
        "7622ed476e6d44189ae48f3664c2fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea6c55659b0045d28fa2ec06966f3dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f397323e16c14d079f0c3643df668df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64f93e4de8b046ceae59f7f5157cf041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b44e843c47548ba974c1764cadf22c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32c402d337f54436a1a40445c8ddf3a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4201d2aa1c634cfca2fdcbffcd18fa54",
              "IPY_MODEL_97271f17d4234cedb4968709527a2b4f"
            ]
          }
        },
        "32c402d337f54436a1a40445c8ddf3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4201d2aa1c634cfca2fdcbffcd18fa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5a5432521eb4344a6ee0dc800e6c2c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d8fc4db3b1a48ec8a9e3475d88ff017"
          }
        },
        "97271f17d4234cedb4968709527a2b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6fb43568d5c4d3583bfb8d552f7472c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:39&lt;00:00, 13.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01f39fd9b7f941b49e2f9f7782ea4b92"
          }
        },
        "d5a5432521eb4344a6ee0dc800e6c2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d8fc4db3b1a48ec8a9e3475d88ff017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6fb43568d5c4d3583bfb8d552f7472c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01f39fd9b7f941b49e2f9f7782ea4b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdHVQrqyDB50"
      },
      "source": [
        "# Memory Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58HaeA6CsM9",
        "outputId": "c69b30cd-e4ac-4724-fa39-99830c9e9fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================== Memory Information ========================================\n",
            "Total: 25.51GB\n",
            "Available: 24.59GB\n",
            "Used: 591.92MB\n",
            "Percentage: 3.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgVfBlvZDEja"
      },
      "source": [
        "# GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxlkxvkrCyin",
        "outputId": "27967374-7807-46a8-89fb-7402c79dc619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Sep 25 19:39:28 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6WR5Uaa6RQJ",
        "outputId": "c9524d16-2de2-4341-cd1d-b0ba41b837a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
            "Collecting loguru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/48/0a7d5847e3de329f1d0134baf707b689700b53bd3066a5a8cfd94b3c9fc8/loguru-0.5.3-py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 39.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 47.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
            "Collecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
            "Collecting contextvars==2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 9.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pytreebank, sacremoses, contextvars\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp36-none-any.whl size=37070 sha256=8a3600335072dcc8939cf7f2252f05346f4a6e3f01a79d33a99fa1e73f6232df\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=34427775dfff2fae2d04b7b03207ae950f44cf1cd5b02064dacc46e149bbc0fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=698f6cf4a5af5d7b14ae67d12f344a776c5bae69e40a4d131f16af51b2ac5819\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built pytreebank sacremoses contextvars\n",
            "Installing collected packages: pytreebank, sentencepiece, tokenizers, sacremoses, transformers, immutables, contextvars, aiocontextvars, loguru\n",
            "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 immutables-0.14 loguru-0.5.3 pytreebank-0.2.7 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDODoaWC6KI"
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
        "import torch\n",
        "from dataset import SSTDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import transformer_params\n",
        "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
        "from math import ceil\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5IZjSzQNpP"
      },
      "source": [
        "class GPT2ForSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, tokenizer, num_labels):\n",
        "    super(GPT2ForSequenceClassification, self).__init__()\n",
        "    self.model = GPT2Model.from_pretrained('gpt2',\n",
        "                                       config=GPT2Config.from_pretrained('gpt2'))\n",
        "    self.tokenizer = tokenizer\n",
        "    self.dropout = torch.nn.Dropout(p=0.1)\n",
        "    self.fc_layer = torch.nn.Linear(in_features=768, out_features=768)\n",
        "    self.tanh = torch.nn.GELU()\n",
        "    self.out_layer = torch.nn.Linear(in_features=768, out_features=num_labels)\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
        "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
        "\n",
        "    sep_mask = input_ids.eq(self.tokenizer.sep_token_id)\n",
        "    if len(torch.unique(sep_mask.sum(1))) > 1:\n",
        "      raise ValueError(\"All examples must have the same number of <e> tokens.\")\n",
        "\n",
        "    gpt_e_token = gpt_last_layer[sep_mask, :]\n",
        "    #gpt_first_token = gpt_last_layer[:, 0] #experiment failed for first token\n",
        "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
        "\n",
        "    fc_layer_out = self.fc_layer(gpt_e_token)\n",
        "    fc_layer_out = self.tanh(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
        "\n",
        "    fc_layer_out = self.dropout(fc_layer_out)\n",
        "    logits = self.out_layer(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
        "    \n",
        "    loss = self.criterion(logits, labels)\n",
        "                                   \n",
        "    return logits, loss\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp2KwIxuzy2V"
      },
      "source": [
        "class GPT2ForSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, tokenizer, num_labels):\n",
        "    super(GPT2ForSequenceClassification, self).__init__()\n",
        "    self.model = GPT2Model.from_pretrained('gpt2',\n",
        "                                       config=GPT2Config.from_pretrained('gpt2'))\n",
        "    self.tokenizer = tokenizer\n",
        "    self.dropout = torch.nn.Dropout(p=0.1)\n",
        "    self.out_layer = torch.nn.Linear(in_features=768, out_features=num_labels)\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
        "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
        "\n",
        "    sep_mask = input_ids.eq(self.tokenizer.sep_token_id)\n",
        "    if len(torch.unique(sep_mask.sum(1))) > 1:\n",
        "      raise ValueError(\"All examples must have the same number of <e> tokens.\")\n",
        "\n",
        "    gpt_e_token = gpt_last_layer[sep_mask, :]\n",
        "    #gpt_first_token = gpt_last_layer[:, 0] #experiment failed for first token\n",
        "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
        "\n",
        "    fc_layer_out = self.dropout(gpt_e_token)\n",
        "    logits = self.out_layer(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
        "    \n",
        "    loss = self.criterion(logits, labels)\n",
        "                                   \n",
        "    return logits, loss\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4_cQpe_c4BN"
      },
      "source": [
        "def load_transformer(name, binary):\n",
        "  num_classes = 5\n",
        "  if binary:\n",
        "    num_classes = 2\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]',\n",
        "                              'cls_token': '<s>',\n",
        "                              'sep_token': '<e>'})\n",
        "  model = GPT2ForSequenceClassification(tokenizer, num_classes)\n",
        "  model.model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "  return {'model': model,\n",
        "          'tokenizer': tokenizer}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq-C2k3kcylS"
      },
      "source": [
        "def add_special_tokens(text):\n",
        "  text = list(text)\n",
        "  for i in range(len(text)):\n",
        "    text[i] = '<s> ' + text[i] + ' <e>'\n",
        "  return tuple(text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFaW79Rdi0R"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSgyPvydj0s"
      },
      "source": [
        "def train_step(model, inputs, labels, optimizer):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7984ypaMdixv"
      },
      "source": [
        "def eval_step(model, inputs, labels):\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHHlscCdivT"
      },
      "source": [
        "def train_epoch(model, tokenizer, train_dataset, optimizer, batch_size):\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
        "        for text, sentiment in train_loader:\n",
        "            text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
        "            sentiment = sentiment.to(device)\n",
        "\n",
        "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
        "\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "            correct_count += (preds == sentiment).sum().item()\n",
        "            total_loss += loss.item()\n",
        "            pbar.update(1)\n",
        "\n",
        "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPxnxXajditk"
      },
      "source": [
        "def eval_epoch(model, tokenizer, eval_dataset, batch_size, split):\n",
        "    eval_loader = DataLoader(dataset=eval_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "    y_pred = list()\n",
        "    y_true = list()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
        "            for text, sentiment in eval_loader:\n",
        "                text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
        "                sentiment = sentiment.to(device)\n",
        "\n",
        "                logits, loss = eval_step(model, text, sentiment)\n",
        "\n",
        "                preds = torch.argmax(logits, axis=1)\n",
        "                y_pred += preds.cpu().numpy().tolist()\n",
        "                y_true += sentiment.cpu().numpy().tolist()\n",
        "\n",
        "                correct_count += (preds == sentiment).sum().item()\n",
        "                total_loss += loss.item()\n",
        "                pbar.update(1)\n",
        "\n",
        "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
        "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JQeDe5FdirO"
      },
      "source": [
        "def train(name, root, binary, epochs=25, patience=3, save=False):\n",
        "\n",
        "    #load model and tokenizer..\n",
        "    try:\n",
        "        transformer_container = load_transformer(name, binary)\n",
        "    except ValueError:\n",
        "        logger.error(\"Invalid transformer name!\")\n",
        "        os._exit(0)\n",
        "    model = transformer_container['model']\n",
        "    model = model.to(device)\n",
        "    tokenizer = transformer_container['tokenizer']\n",
        "\n",
        "    #load batch_size and learning rate..\n",
        "    params_container = transformer_params(name)\n",
        "    batch_size = params_container['batch_size']\n",
        "    learning_rate = params_container['learning_rate']\n",
        "\n",
        "    #load train, dev and test datasets..\n",
        "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
        "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
        "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
        "\n",
        "    #Intialize optimizer..\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    #Initialize training variables..\n",
        "    best_acc = 0.0\n",
        "    best_loss = np.inf\n",
        "    stopping_step = 0\n",
        "    best_model_name = None\n",
        "\n",
        "    total_train_seconds = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        start = time.time()\n",
        "        train_acc, train_loss = train_epoch(model, tokenizer, train_dataset, optimizer, batch_size)\n",
        "        end = time.time()\n",
        "        total_train_seconds += (end - start)\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
        "\n",
        "        dev_acc, dev_loss, _ = eval_epoch(model, tokenizer, dev_dataset, batch_size, 'dev')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
        "\n",
        "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, tokenizer, test_dataset,\n",
        "                                                                  batch_size, 'test')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
        "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
        "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
        "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
        "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
        "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
        "\n",
        "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
        "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
        "\n",
        "        #save best model and delete previous ones...\n",
        "        if save:\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                phrase_type, label = root_and_binary_title(root, binary)\n",
        "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
        "                save_model(model, model_name, best_model_name)\n",
        "\n",
        "\n",
        "        # Implement early stopping here\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            stopping_step = 0\n",
        "        else:\n",
        "            stopping_step += 1\n",
        "\n",
        "        if stopping_step >= patience:\n",
        "            logger.info(\"EarlyStopping!\")\n",
        "            os._exit(1)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYwav8wdiou",
        "outputId": "8dc829b6-2542-4226-f2f3-35aefd380066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b13701d78dd646a5b3b13cb2a1abb36b",
            "d72818de48554d39b2377d0a112f3269",
            "0bb717a93f78429cb39b131444a3f75a",
            "7bdf156fa7df4f149d8b1aa716b36587",
            "39bae5fc5e4241c6b0153927318f6504",
            "b6716fed235f4e3d987a932c7284e8a6",
            "8e03eab6ce4c4d9183d6da695fdfc193",
            "4e8393bc35284ef29a70889ef2324af3",
            "ff795ce6004b4495b2340cc19cc6a1da",
            "6114813f06894b36acad6c76a13ac791",
            "7c3f0746068e416284b6cd4fb2cf6af2",
            "3fd683952d4643738a050088789920b2",
            "04aad504c1ce4ebba7bf65599c2a0442",
            "3f9429376e6d42b993f176b92a8757f6",
            "f1c522cd6a50492481473fea9cc77ec7",
            "945ca15f280a48d3a383ca63b21516d4",
            "cba6e503f5bc41b4a51ff5940ba3b060",
            "521ea0ee0db848728f6696d4cfbbf529",
            "7c086b3e36b4474a9355cfe8467865e0",
            "1ebe445c61074c3ab02689e65a62878c",
            "7622ed476e6d44189ae48f3664c2fa6c",
            "ea6c55659b0045d28fa2ec06966f3dad",
            "f397323e16c14d079f0c3643df668df6",
            "64f93e4de8b046ceae59f7f5157cf041",
            "0b44e843c47548ba974c1764cadf22c2",
            "32c402d337f54436a1a40445c8ddf3a3",
            "4201d2aa1c634cfca2fdcbffcd18fa54",
            "97271f17d4234cedb4968709527a2b4f",
            "d5a5432521eb4344a6ee0dc800e6c2c2",
            "6d8fc4db3b1a48ec8a9e3475d88ff017",
            "d6fb43568d5c4d3583bfb8d552f7472c",
            "01f39fd9b7f941b49e2f9f7782ea4b92"
          ]
        }
      },
      "source": [
        "#with one hidden layer\n",
        "train('gpt2', True, False, 30, 300, False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13701d78dd646a5b3b13cb2a1abb36b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff795ce6004b4495b2340cc19cc6a1da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba6e503f5bc41b4a51ff5940ba3b060",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b44e843c47548ba974c1764cadf22c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-25 19:45:47.338 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-09-25 19:45:59.098 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-25 19:46:05.048 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:55<00:00,  4.85batch/s]\n",
            "2020-09-25 19:47:00.787 | INFO     | __main__:train:39 - epoch: 1, transformer: gpt2, train_loss: 0.0513, train_acc: 26.32\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.19batch/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "2020-09-25 19:47:03.124 | INFO     | __main__:train:42 - epoch: 1, transformer: gpt2, dev_loss: 0.0492, dev_acc: 27.97\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 14.81batch/s]\n",
            "2020-09-25 19:47:07.869 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_loss: 0.0492, test_acc: 26.56\n",
            "2020-09-25 19:47:07.870 | INFO     | __main__:train:47 - epoch: 1, transformer: gpt2, test_precision: 13.54, test_recall: 22.23, test_f1_score: 12.55, test_accuracy_score: 26.56\n",
            "2020-09-25 19:47:07.872 | INFO     | __main__:train:52 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  54   0 225   0]\n",
            " [  0 104   0 529   0]\n",
            " [  0  48   0 341   0]\n",
            " [  0  27   0 483   0]\n",
            " [  0   8   0 391   0]]\n",
            "2020-09-25 19:47:07.873 | INFO     | __main__:train:55 - Total training time elapsed: 0:00:55.006262\n",
            "2020-09-25 19:47:07.873 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:55.006262\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  4.96batch/s]\n",
            "2020-09-25 19:48:01.708 | INFO     | __main__:train:39 - epoch: 2, transformer: gpt2, train_loss: 0.0446, train_acc: 36.86\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.62batch/s]\n",
            "2020-09-25 19:48:03.964 | INFO     | __main__:train:42 - epoch: 2, transformer: gpt2, dev_loss: 0.0384, dev_acc: 45.69\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.35batch/s]\n",
            "2020-09-25 19:48:08.543 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_loss: 0.0368, test_acc: 49.77\n",
            "2020-09-25 19:48:08.544 | INFO     | __main__:train:47 - epoch: 2, transformer: gpt2, test_precision: 52.35, test_recall: 42.61, test_f1_score: 39.45, test_accuracy_score: 49.77\n",
            "2020-09-25 19:48:08.545 | INFO     | __main__:train:52 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 26 230   3  20   0]\n",
            " [ 18 528  14  70   3]\n",
            " [  0 245  19 116   9]\n",
            " [  0  96   4 305 105]\n",
            " [  0  18   3 156 222]]\n",
            "2020-09-25 19:48:08.546 | INFO     | __main__:train:55 - Total training time elapsed: 0:01:48.839681\n",
            "2020-09-25 19:48:08.547 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:54.419840\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  4.99batch/s]\n",
            "2020-09-25 19:49:02.101 | INFO     | __main__:train:39 - epoch: 3, transformer: gpt2, train_loss: 0.0382, train_acc: 45.53\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.69batch/s]\n",
            "2020-09-25 19:49:04.348 | INFO     | __main__:train:42 - epoch: 3, transformer: gpt2, dev_loss: 0.0387, dev_acc: 47.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.32batch/s]\n",
            "2020-09-25 19:49:08.937 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_loss: 0.0362, test_acc: 50.77\n",
            "2020-09-25 19:49:08.938 | INFO     | __main__:train:47 - epoch: 3, transformer: gpt2, test_precision: 52.14, test_recall: 45.59, test_f1_score: 44.43, test_accuracy_score: 50.77\n",
            "2020-09-25 19:49:08.939 | INFO     | __main__:train:52 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 56 177  11  35   0]\n",
            " [ 36 426  40 129   2]\n",
            " [  2 158  44 174  11]\n",
            " [  0  23  16 369 102]\n",
            " [  0   2   4 166 227]]\n",
            "2020-09-25 19:49:08.940 | INFO     | __main__:train:55 - Total training time elapsed: 0:02:42.391439\n",
            "2020-09-25 19:49:08.941 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:54.130480\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.00batch/s]\n",
            "2020-09-25 19:50:02.342 | INFO     | __main__:train:39 - epoch: 4, transformer: gpt2, train_loss: 0.0352, train_acc: 49.99\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.65batch/s]\n",
            "2020-09-25 19:50:04.594 | INFO     | __main__:train:42 - epoch: 4, transformer: gpt2, dev_loss: 0.0357, dev_acc: 49.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.40batch/s]\n",
            "2020-09-25 19:50:09.159 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_loss: 0.0340, test_acc: 52.44\n",
            "2020-09-25 19:50:09.159 | INFO     | __main__:train:47 - epoch: 4, transformer: gpt2, test_precision: 52.76, test_recall: 46.82, test_f1_score: 46.51, test_accuracy_score: 52.44\n",
            "2020-09-25 19:50:09.160 | INFO     | __main__:train:52 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 62 192  15  10   0]\n",
            " [ 41 469  61  60   2]\n",
            " [  8 183  65 127   6]\n",
            " [  1  42  31 367  69]\n",
            " [  0   6  14 183 196]]\n",
            "2020-09-25 19:50:09.161 | INFO     | __main__:train:55 - Total training time elapsed: 0:03:35.791061\n",
            "2020-09-25 19:50:09.162 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.947765\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 19:51:02.204 | INFO     | __main__:train:39 - epoch: 5, transformer: gpt2, train_loss: 0.0334, train_acc: 53.14\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.73batch/s]\n",
            "2020-09-25 19:51:04.445 | INFO     | __main__:train:42 - epoch: 5, transformer: gpt2, dev_loss: 0.0376, dev_acc: 48.68\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.38batch/s]\n",
            "2020-09-25 19:51:09.016 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_loss: 0.0345, test_acc: 52.85\n",
            "2020-09-25 19:51:09.017 | INFO     | __main__:train:47 - epoch: 5, transformer: gpt2, test_precision: 51.57, test_recall: 50.73, test_f1_score: 49.74, test_accuracy_score: 52.85\n",
            "2020-09-25 19:51:09.018 | INFO     | __main__:train:52 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
            "[[138 112   9  20   0]\n",
            " [113 385  48  81   6]\n",
            " [ 19 158  59 140  13]\n",
            " [  2  26  27 342 113]\n",
            " [  0   2   9 144 244]]\n",
            "2020-09-25 19:51:09.019 | INFO     | __main__:train:55 - Total training time elapsed: 0:04:28.832091\n",
            "2020-09-25 19:51:09.020 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.766418\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.04batch/s]\n",
            "2020-09-25 19:52:02.004 | INFO     | __main__:train:39 - epoch: 6, transformer: gpt2, train_loss: 0.0316, train_acc: 55.95\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.45batch/s]\n",
            "2020-09-25 19:52:04.285 | INFO     | __main__:train:42 - epoch: 6, transformer: gpt2, dev_loss: 0.0359, dev_acc: 50.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.31batch/s]\n",
            "2020-09-25 19:52:08.877 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_loss: 0.0339, test_acc: 53.80\n",
            "2020-09-25 19:52:08.878 | INFO     | __main__:train:47 - epoch: 6, transformer: gpt2, test_precision: 54.19, test_recall: 49.77, test_f1_score: 50.16, test_accuracy_score: 53.80\n",
            "2020-09-25 19:52:08.879 | INFO     | __main__:train:52 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
            "[[119 148  10   2   0]\n",
            " [ 78 477  49  26   3]\n",
            " [ 20 207  82  75   5]\n",
            " [  2  51  68 336  53]\n",
            " [  1  20  19 184 175]]\n",
            "2020-09-25 19:52:08.881 | INFO     | __main__:train:55 - Total training time elapsed: 0:05:21.813388\n",
            "2020-09-25 19:52:08.882 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.635565\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.02batch/s]\n",
            "2020-09-25 19:53:02.109 | INFO     | __main__:train:39 - epoch: 7, transformer: gpt2, train_loss: 0.0301, train_acc: 58.22\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.76batch/s]\n",
            "2020-09-25 19:53:04.345 | INFO     | __main__:train:42 - epoch: 7, transformer: gpt2, dev_loss: 0.0357, dev_acc: 50.86\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.50batch/s]\n",
            "2020-09-25 19:53:08.880 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_loss: 0.0340, test_acc: 54.80\n",
            "2020-09-25 19:53:08.880 | INFO     | __main__:train:47 - epoch: 7, transformer: gpt2, test_precision: 53.94, test_recall: 52.81, test_f1_score: 52.61, test_accuracy_score: 54.80\n",
            "2020-09-25 19:53:08.882 | INFO     | __main__:train:52 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
            "[[147 108  12  11   1]\n",
            " [116 400  68  45   4]\n",
            " [ 23 153  97 108   8]\n",
            " [  3  31  43 346  87]\n",
            " [  2   6  18 152 221]]\n",
            "2020-09-25 19:53:08.883 | INFO     | __main__:train:55 - Total training time elapsed: 0:06:15.039671\n",
            "2020-09-25 19:53:08.884 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.577096\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.01batch/s]\n",
            "2020-09-25 19:54:02.215 | INFO     | __main__:train:39 - epoch: 8, transformer: gpt2, train_loss: 0.0282, train_acc: 60.57\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.72batch/s]\n",
            "2020-09-25 19:54:04.460 | INFO     | __main__:train:42 - epoch: 8, transformer: gpt2, dev_loss: 0.0364, dev_acc: 50.77\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.39batch/s]\n",
            "2020-09-25 19:54:09.028 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_loss: 0.0342, test_acc: 54.66\n",
            "2020-09-25 19:54:09.029 | INFO     | __main__:train:47 - epoch: 8, transformer: gpt2, test_precision: 53.71, test_recall: 51.96, test_f1_score: 52.15, test_accuracy_score: 54.66\n",
            "2020-09-25 19:54:09.030 | INFO     | __main__:train:52 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
            "[[125 130  13  10   1]\n",
            " [ 88 414  75  52   4]\n",
            " [ 19 157  98 107   8]\n",
            " [  3  25  45 343  94]\n",
            " [  2   2  23 144 228]]\n",
            "2020-09-25 19:54:09.032 | INFO     | __main__:train:55 - Total training time elapsed: 0:07:08.369452\n",
            "2020-09-25 19:54:09.033 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.546182\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  4.98batch/s]\n",
            "2020-09-25 19:55:02.615 | INFO     | __main__:train:39 - epoch: 9, transformer: gpt2, train_loss: 0.0268, train_acc: 62.29\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.68batch/s]\n",
            "2020-09-25 19:55:04.864 | INFO     | __main__:train:42 - epoch: 9, transformer: gpt2, dev_loss: 0.0388, dev_acc: 51.14\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.42batch/s]\n",
            "2020-09-25 19:55:09.425 | INFO     | __main__:train:46 - epoch: 9, transformer: gpt2, test_loss: 0.0351, test_acc: 54.66\n",
            "2020-09-25 19:55:09.426 | INFO     | __main__:train:47 - epoch: 9, transformer: gpt2, test_precision: 53.90, test_recall: 52.07, test_f1_score: 52.36, test_accuracy_score: 54.66\n",
            "2020-09-25 19:55:09.427 | INFO     | __main__:train:52 - epoch: 9, transformer: gpt2, test_confusion_matrix: \n",
            "[[123 132  14   8   2]\n",
            " [ 82 418  71  58   4]\n",
            " [ 17 153 104 106   9]\n",
            " [  1  23  53 323 110]\n",
            " [  0   7  15 137 240]]\n",
            "2020-09-25 19:55:09.428 | INFO     | __main__:train:55 - Total training time elapsed: 0:08:01.950417\n",
            "2020-09-25 19:55:09.429 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.550046\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.01batch/s]\n",
            "2020-09-25 19:56:02.713 | INFO     | __main__:train:39 - epoch: 10, transformer: gpt2, train_loss: 0.0255, train_acc: 64.21\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.75batch/s]\n",
            "2020-09-25 19:56:04.952 | INFO     | __main__:train:42 - epoch: 10, transformer: gpt2, dev_loss: 0.0378, dev_acc: 51.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.47batch/s]\n",
            "2020-09-25 19:56:09.496 | INFO     | __main__:train:46 - epoch: 10, transformer: gpt2, test_loss: 0.0358, test_acc: 54.16\n",
            "2020-09-25 19:56:09.497 | INFO     | __main__:train:47 - epoch: 10, transformer: gpt2, test_precision: 54.60, test_recall: 51.19, test_f1_score: 51.41, test_accuracy_score: 54.16\n",
            "2020-09-25 19:56:09.498 | INFO     | __main__:train:52 - epoch: 10, transformer: gpt2, test_confusion_matrix: \n",
            "[[132 127  12   7   1]\n",
            " [ 98 417  71  44   3]\n",
            " [ 22 161 100 101   5]\n",
            " [  1  32  54 372  51]\n",
            " [  1   9  23 190 176]]\n",
            "2020-09-25 19:56:09.499 | INFO     | __main__:train:55 - Total training time elapsed: 0:08:55.232265\n",
            "2020-09-25 19:56:09.500 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.523227\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 19:57:02.544 | INFO     | __main__:train:39 - epoch: 11, transformer: gpt2, train_loss: 0.0240, train_acc: 67.10\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.60batch/s]\n",
            "2020-09-25 19:57:04.803 | INFO     | __main__:train:42 - epoch: 11, transformer: gpt2, dev_loss: 0.0407, dev_acc: 50.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.40batch/s]\n",
            "2020-09-25 19:57:09.368 | INFO     | __main__:train:46 - epoch: 11, transformer: gpt2, test_loss: 0.0368, test_acc: 54.07\n",
            "2020-09-25 19:57:09.369 | INFO     | __main__:train:47 - epoch: 11, transformer: gpt2, test_precision: 53.07, test_recall: 52.47, test_f1_score: 52.44, test_accuracy_score: 54.07\n",
            "2020-09-25 19:57:09.370 | INFO     | __main__:train:52 - epoch: 11, transformer: gpt2, test_confusion_matrix: \n",
            "[[142 110  11  14   2]\n",
            " [105 383  88  51   6]\n",
            " [ 21 149 108 100  11]\n",
            " [  2  19  58 324 107]\n",
            " [  0   6  17 138 238]]\n",
            "2020-09-25 19:57:09.371 | INFO     | __main__:train:55 - Total training time elapsed: 0:09:48.275041\n",
            "2020-09-25 19:57:09.372 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.479549\n",
            "train:  19%|â–ˆâ–‰        | 51/267 [00:10<00:44,  4.90batch/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d48248c16131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-6b9a2854405b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(name, root, binary, epochs, patience, save)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtotal_train_seconds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-55af4a5f1322>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, tokenizer, train_dataset, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c54f6e7dca1d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, inputs, labels, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJveOtox3-6e",
        "outputId": "b4cbe50a-4d99-4454-f8d5-8004c00aa3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#no hidden layer\n",
        "train('gpt2', True, False, 30, 300, False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-25 19:57:50.682 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
            "2020-09-25 19:57:58.620 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-25 19:58:04.651 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  4.95batch/s]\n",
            "2020-09-25 19:58:59.261 | INFO     | __main__:train:39 - epoch: 1, transformer: gpt2, train_loss: 0.0537, train_acc: 26.39\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.15batch/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "2020-09-25 19:59:01.587 | INFO     | __main__:train:42 - epoch: 1, transformer: gpt2, dev_loss: 0.0480, dev_acc: 33.15\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 14.93batch/s]\n",
            "2020-09-25 19:59:06.294 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_loss: 0.0475, test_acc: 32.44\n",
            "2020-09-25 19:59:06.295 | INFO     | __main__:train:47 - epoch: 1, transformer: gpt2, test_precision: 27.72, test_recall: 26.74, test_f1_score: 22.15, test_accuracy_score: 32.44\n",
            "2020-09-25 19:59:06.296 | INFO     | __main__:train:52 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 134  37 108   0]\n",
            " [  0 289  88 252   4]\n",
            " [  0 170  37 179   3]\n",
            " [  0 111  16 357  26]\n",
            " [  0  65   4 296  34]]\n",
            "2020-09-25 19:59:06.297 | INFO     | __main__:train:55 - Total training time elapsed: 0:00:53.911759\n",
            "2020-09-25 19:59:06.298 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.911759\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.05batch/s]\n",
            "2020-09-25 19:59:59.209 | INFO     | __main__:train:39 - epoch: 2, transformer: gpt2, train_loss: 0.0447, train_acc: 35.81\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.93batch/s]\n",
            "2020-09-25 20:00:01.420 | INFO     | __main__:train:42 - epoch: 2, transformer: gpt2, dev_loss: 0.0394, dev_acc: 44.69\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.41batch/s]\n",
            "2020-09-25 20:00:05.983 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_loss: 0.0382, test_acc: 46.29\n",
            "2020-09-25 20:00:05.984 | INFO     | __main__:train:47 - epoch: 2, transformer: gpt2, test_precision: 39.26, test_recall: 39.61, test_f1_score: 36.88, test_accuracy_score: 46.29\n",
            "2020-09-25 20:00:05.985 | INFO     | __main__:train:52 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 215  38  26   0]\n",
            " [  0 414 126  91   2]\n",
            " [  0 157 100 128   4]\n",
            " [  0  45  43 378  44]\n",
            " [  0   8  15 245 131]]\n",
            "2020-09-25 20:00:05.986 | INFO     | __main__:train:55 - Total training time elapsed: 0:01:46.821417\n",
            "2020-09-25 20:00:05.987 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.410708\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.05batch/s]\n",
            "2020-09-25 20:00:58.886 | INFO     | __main__:train:39 - epoch: 3, transformer: gpt2, train_loss: 0.0386, train_acc: 45.11\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.74batch/s]\n",
            "2020-09-25 20:01:01.125 | INFO     | __main__:train:42 - epoch: 3, transformer: gpt2, dev_loss: 0.0371, dev_acc: 49.50\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.45batch/s]\n",
            "2020-09-25 20:01:05.674 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_loss: 0.0362, test_acc: 50.36\n",
            "2020-09-25 20:01:05.675 | INFO     | __main__:train:47 - epoch: 3, transformer: gpt2, test_precision: 52.08, test_recall: 46.76, test_f1_score: 47.33, test_accuracy_score: 50.36\n",
            "2020-09-25 20:01:05.676 | INFO     | __main__:train:52 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 75 153  32  19   0]\n",
            " [ 66 361 125  80   1]\n",
            " [  7 131 123 124   4]\n",
            " [  0  26  48 377  59]\n",
            " [  0   3  16 203 177]]\n",
            "2020-09-25 20:01:05.677 | INFO     | __main__:train:55 - Total training time elapsed: 0:02:39.719418\n",
            "2020-09-25 20:01:05.677 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.239806\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.01batch/s]\n",
            "2020-09-25 20:01:59.012 | INFO     | __main__:train:39 - epoch: 4, transformer: gpt2, train_loss: 0.0360, train_acc: 49.40\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.86batch/s]\n",
            "2020-09-25 20:02:01.234 | INFO     | __main__:train:42 - epoch: 4, transformer: gpt2, dev_loss: 0.0384, dev_acc: 48.50\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.33batch/s]\n",
            "2020-09-25 20:02:05.821 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_loss: 0.0354, test_acc: 51.63\n",
            "2020-09-25 20:02:05.822 | INFO     | __main__:train:47 - epoch: 4, transformer: gpt2, test_precision: 58.23, test_recall: 44.76, test_f1_score: 42.43, test_accuracy_score: 51.63\n",
            "2020-09-25 20:02:05.823 | INFO     | __main__:train:52 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 42 200   5  32   0]\n",
            " [ 18 481  13 119   2]\n",
            " [  2 183  29 171   4]\n",
            " [  1  32   4 409  64]\n",
            " [  0   6   1 212 180]]\n",
            "2020-09-25 20:02:05.824 | INFO     | __main__:train:55 - Total training time elapsed: 0:03:33.052365\n",
            "2020-09-25 20:02:05.825 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.263091\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 20:02:58.869 | INFO     | __main__:train:39 - epoch: 5, transformer: gpt2, train_loss: 0.0339, train_acc: 52.63\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.93batch/s]\n",
            "2020-09-25 20:03:01.084 | INFO     | __main__:train:42 - epoch: 5, transformer: gpt2, dev_loss: 0.0368, dev_acc: 50.32\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.39batch/s]\n",
            "2020-09-25 20:03:05.653 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_loss: 0.0342, test_acc: 53.12\n",
            "2020-09-25 20:03:05.654 | INFO     | __main__:train:47 - epoch: 5, transformer: gpt2, test_precision: 53.98, test_recall: 49.66, test_f1_score: 50.11, test_accuracy_score: 53.12\n",
            "2020-09-25 20:03:05.656 | INFO     | __main__:train:52 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 94 145  20  20   0]\n",
            " [ 62 392  88  87   4]\n",
            " [ 10 131 100 142   6]\n",
            " [  0  23  27 374  86]\n",
            " [  0   2  11 172 214]]\n",
            "2020-09-25 20:03:05.657 | INFO     | __main__:train:55 - Total training time elapsed: 0:04:26.094692\n",
            "2020-09-25 20:03:05.658 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.218938\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 20:03:58.772 | INFO     | __main__:train:39 - epoch: 6, transformer: gpt2, train_loss: 0.0322, train_acc: 55.35\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.91batch/s]\n",
            "2020-09-25 20:04:00.990 | INFO     | __main__:train:42 - epoch: 6, transformer: gpt2, dev_loss: 0.0375, dev_acc: 50.14\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.54batch/s]\n",
            "2020-09-25 20:04:05.513 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_loss: 0.0342, test_acc: 53.80\n",
            "2020-09-25 20:04:05.513 | INFO     | __main__:train:47 - epoch: 6, transformer: gpt2, test_precision: 52.77, test_recall: 51.80, test_f1_score: 51.34, test_accuracy_score: 53.80\n",
            "2020-09-25 20:04:05.515 | INFO     | __main__:train:52 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
            "[[137 115  12  14   1]\n",
            " [106 390  64  69   4]\n",
            " [ 27 149  84 118  11]\n",
            " [  1  32  25 333 119]\n",
            " [  0   6  11 137 245]]\n",
            "2020-09-25 20:04:05.516 | INFO     | __main__:train:55 - Total training time elapsed: 0:05:19.207483\n",
            "2020-09-25 20:04:05.517 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.201247\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 20:04:58.571 | INFO     | __main__:train:39 - epoch: 7, transformer: gpt2, train_loss: 0.0308, train_acc: 57.13\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.68batch/s]\n",
            "2020-09-25 20:05:00.821 | INFO     | __main__:train:42 - epoch: 7, transformer: gpt2, dev_loss: 0.0397, dev_acc: 49.23\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.50batch/s]\n",
            "2020-09-25 20:05:05.357 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_loss: 0.0354, test_acc: 52.08\n",
            "2020-09-25 20:05:05.358 | INFO     | __main__:train:47 - epoch: 7, transformer: gpt2, test_precision: 52.25, test_recall: 50.28, test_f1_score: 50.40, test_accuracy_score: 52.08\n",
            "2020-09-25 20:05:05.359 | INFO     | __main__:train:52 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
            "[[121 112  20  24   2]\n",
            " [ 83 344 102  97   7]\n",
            " [ 18 105 103 151  12]\n",
            " [  0  17  33 347 113]\n",
            " [  0   2   8 153 236]]\n",
            "2020-09-25 20:05:05.360 | INFO     | __main__:train:55 - Total training time elapsed: 0:06:12.260405\n",
            "2020-09-25 20:05:05.361 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.180058\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.05batch/s]\n",
            "2020-09-25 20:05:58.284 | INFO     | __main__:train:39 - epoch: 8, transformer: gpt2, train_loss: 0.0291, train_acc: 59.70\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.77batch/s]\n",
            "2020-09-25 20:06:00.519 | INFO     | __main__:train:42 - epoch: 8, transformer: gpt2, dev_loss: 0.0393, dev_acc: 49.23\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.62batch/s]\n",
            "2020-09-25 20:06:05.020 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_loss: 0.0351, test_acc: 53.39\n",
            "2020-09-25 20:06:05.021 | INFO     | __main__:train:47 - epoch: 8, transformer: gpt2, test_precision: 53.18, test_recall: 51.02, test_f1_score: 50.99, test_accuracy_score: 53.39\n",
            "2020-09-25 20:06:05.022 | INFO     | __main__:train:52 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
            "[[123 122  16  16   2]\n",
            " [ 90 378  78  82   5]\n",
            " [ 21 127  93 139   9]\n",
            " [  1  25  23 357 104]\n",
            " [  1   1   6 162 229]]\n",
            "2020-09-25 20:06:05.023 | INFO     | __main__:train:55 - Total training time elapsed: 0:07:05.181906\n",
            "2020-09-25 20:06:05.024 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.147738\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.05batch/s]\n",
            "2020-09-25 20:06:57.902 | INFO     | __main__:train:39 - epoch: 9, transformer: gpt2, train_loss: 0.0275, train_acc: 61.73\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.70batch/s]\n",
            "2020-09-25 20:07:00.147 | INFO     | __main__:train:42 - epoch: 9, transformer: gpt2, dev_loss: 0.0383, dev_acc: 49.95\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.40batch/s]\n",
            "2020-09-25 20:07:04.713 | INFO     | __main__:train:46 - epoch: 9, transformer: gpt2, test_loss: 0.0345, test_acc: 54.07\n",
            "2020-09-25 20:07:04.714 | INFO     | __main__:train:47 - epoch: 9, transformer: gpt2, test_precision: 55.01, test_recall: 49.78, test_f1_score: 50.39, test_accuracy_score: 54.07\n",
            "2020-09-25 20:07:04.715 | INFO     | __main__:train:52 - epoch: 9, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 82 168  18  11   0]\n",
            " [ 50 431  86  61   5]\n",
            " [ 11 147 112 112   7]\n",
            " [  0  26  45 371  68]\n",
            " [  1   4  13 182 199]]\n",
            "2020-09-25 20:07:04.716 | INFO     | __main__:train:55 - Total training time elapsed: 0:07:58.057896\n",
            "2020-09-25 20:07:04.717 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.117544\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:53<00:00,  5.03batch/s]\n",
            "2020-09-25 20:07:57.793 | INFO     | __main__:train:39 - epoch: 10, transformer: gpt2, train_loss: 0.0256, train_acc: 64.37\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.87batch/s]\n",
            "2020-09-25 20:08:00.014 | INFO     | __main__:train:42 - epoch: 10, transformer: gpt2, dev_loss: 0.0418, dev_acc: 48.23\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.45batch/s]\n",
            "2020-09-25 20:08:04.565 | INFO     | __main__:train:46 - epoch: 10, transformer: gpt2, test_loss: 0.0363, test_acc: 53.71\n",
            "2020-09-25 20:08:04.565 | INFO     | __main__:train:47 - epoch: 10, transformer: gpt2, test_precision: 52.76, test_recall: 50.51, test_f1_score: 50.53, test_accuracy_score: 53.71\n",
            "2020-09-25 20:08:04.566 | INFO     | __main__:train:52 - epoch: 10, transformer: gpt2, test_confusion_matrix: \n",
            "[[111 141  16   9   2]\n",
            " [ 74 430  62  60   7]\n",
            " [ 14 168  83 112  12]\n",
            " [  3  32  36 323 116]\n",
            " [  1   8  10 140 240]]\n",
            "2020-09-25 20:08:04.567 | INFO     | __main__:train:55 - Total training time elapsed: 0:08:51.131711\n",
            "2020-09-25 20:08:04.568 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.113171\n",
            "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:52<00:00,  5.05batch/s]\n",
            "2020-09-25 20:08:57.460 | INFO     | __main__:train:39 - epoch: 11, transformer: gpt2, train_loss: 0.0244, train_acc: 66.48\n",
            "dev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 15.53batch/s]\n",
            "2020-09-25 20:08:59.728 | INFO     | __main__:train:42 - epoch: 11, transformer: gpt2, dev_loss: 0.0416, dev_acc: 48.05\n",
            "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:04<00:00, 15.54batch/s]\n",
            "2020-09-25 20:09:04.252 | INFO     | __main__:train:46 - epoch: 11, transformer: gpt2, test_loss: 0.0368, test_acc: 53.26\n",
            "2020-09-25 20:09:04.252 | INFO     | __main__:train:47 - epoch: 11, transformer: gpt2, test_precision: 53.76, test_recall: 50.74, test_f1_score: 51.30, test_accuracy_score: 53.26\n",
            "2020-09-25 20:09:04.253 | INFO     | __main__:train:52 - epoch: 11, transformer: gpt2, test_confusion_matrix: \n",
            "[[114 130  21  12   2]\n",
            " [ 74 374 108  69   8]\n",
            " [ 13 125 119 122  10]\n",
            " [  1  20  45 361  83]\n",
            " [  0   6   9 175 209]]\n",
            "2020-09-25 20:09:04.254 | INFO     | __main__:train:55 - Total training time elapsed: 0:09:44.022170\n",
            "2020-09-25 20:09:04.255 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:53.092925\n",
            "train:  21%|â–ˆâ–ˆ        | 55/267 [00:11<00:43,  4.90batch/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e87d6aaa9549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#no hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-6b9a2854405b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(name, root, binary, epochs, patience, save)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtotal_train_seconds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-55af4a5f1322>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, tokenizer, train_dataset, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c54f6e7dca1d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, inputs, labels, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMfA9mkm8dfQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lEHpwIL8dcf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-vTLCGL8daN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW8pv5w08dYY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5uq4_AO8dVt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtfwRrO8dSo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}