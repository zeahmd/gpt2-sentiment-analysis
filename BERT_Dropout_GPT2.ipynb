{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdHVQrqyDB50"
   },
   "source": [
    "# Memory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "E58HaeA6CsM9",
    "outputId": "879d7923-90ff-4bc7-fa8d-34e6610db0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Memory Information ========================================\n",
      "Total: 25.51GB\n",
      "Available: 22.45GB\n",
      "Used: 5.39GB\n",
      "Percentage: 12.0%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def get_size(bytes, suffix=\"B\"):\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
    "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgVfBlvZDEja"
   },
   "source": [
    "# GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "rxlkxvkrCyin",
    "outputId": "69e335ca-6581-4cf4-e50f-cba127720544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep  2 11:24:34 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    34W / 250W |  14641MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "id": "v6WR5Uaa6RQJ",
    "outputId": "52138358-07bc-422b-886b-958d204954e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytreebank in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
      "Requirement already satisfied: loguru in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.8.1rc2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: aiocontextvars>=0.2.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from loguru->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: contextvars==2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiocontextvars>=0.2.0; python_version < \"3.7\"->loguru->-r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars==2.4; python_version < \"3.7\"->aiocontextvars>=0.2.0; python_version < \"3.7\"->loguru->-r requirements.txt (line 5)) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyDODoaWC6KI"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import torch\n",
    "from dataset import SSTDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import transformer_params\n",
    "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
    "from math import ceil\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l520gFDqbh_L"
   },
   "outputs": [],
   "source": [
    "def add_special_tokens(text):\n",
    "  text = list(text)\n",
    "  for i in range(len(text)):\n",
    "    text[i] = '<|endoftext|> ' + text[i] + ' <|endoftext|>'\n",
    "  return tuple(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZ5IZjSzQNpP"
   },
   "outputs": [],
   "source": [
    "class GPT2ForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(GPT2ForSequenceClassification, self).__init__()\n",
    "        self.model = GPT2Model.from_pretrained('gpt2',\n",
    "                                           config=GPT2Config.from_pretrained('gpt2'))\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.fc_layer = torch.nn.Linear(in_features=768, out_features=768)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
    "        #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
    "    \n",
    "        gpt_last_layer = gpt_last_layer.permute(0, 2, 1)\n",
    "        #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
    "    \n",
    "        global_max_pooling_out, _ = torch.max(gpt_last_layer, axis=2)\n",
    "        global_max_pooling_out = self.dropout(global_max_pooling_out)\n",
    "        #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "    \n",
    "        fc_layer_out = self.fc_layer(global_max_pooling_out)\n",
    "        fc_layer_out = self.tanh(fc_layer_out)\n",
    "        #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "    \n",
    "        return fc_layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9xLAppdYlex"
   },
   "outputs": [],
   "source": [
    "class BERTGPT2ForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTGPT2ForSequenceClassification, self).__init__()\n",
    "        self.gpt2_model = GPT2ForSequenceClassification(num_labels)\n",
    "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.gpt2_tokenizer.add_special_tokens({'pad_token': '.'})\n",
    "    \n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        self.fc_layer = torch.nn.Linear(in_features=768, out_features=1152)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.out_layer = torch.nn.Linear(in_features=1152, out_features=num_labels)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, text, labels):\n",
    "        gpt_encoding = self.gpt2_tokenizer(add_special_tokens(text), padding=True, return_tensors='pt')\n",
    "        gpt_encoding = gpt_encoding.to(device)\n",
    "        gpt2_out = self.gpt2_model(gpt_encoding['input_ids'], gpt_encoding['attention_mask'])\n",
    "        #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "        del gpt_encoding\n",
    "    \n",
    "        bert_encoding = self.bert_tokenizer(text, padding=True, return_tensors='pt')\n",
    "        bert_encoding = bert_encoding.to(device)\n",
    "        bert_out = self.bert_model(bert_encoding['input_ids'], bert_encoding['attention_mask'])[1]\n",
    "        #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "        \n",
    "        merge_out = torch.cat((\n",
    "                               gpt2_out[:, torch.randint(0, 768, (384,))],\n",
    "                               bert_out[:, torch.randint(0, 768, (384,))]\n",
    "        ), axis=1)\n",
    "        #[batch_size, embedding_size(channels)] = [*, 768]\n",
    "    \n",
    "        fc_layer_out = self.fc_layer(merge_out)\n",
    "        fc_layer_out = self.tanh(fc_layer_out)\n",
    "        ##[batch_size, embedding_size(channels)] = [*, 1152]\n",
    "    \n",
    "        logits = self.out_layer(fc_layer_out)\n",
    "        #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
    "        \n",
    "        loss = self.criterion(logits, labels)\n",
    "                                       \n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4_cQpe_c4BN"
   },
   "outputs": [],
   "source": [
    "def load_transformer(name, binary):\n",
    "    num_classes = 5\n",
    "    if binary:\n",
    "        num_classes = 2\n",
    "    model = BERTGPT2ForSequenceClassification(num_classes)\n",
    "    \n",
    "    return {'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQFaW79Rdi0R"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcSgyPvydj0s"
   },
   "outputs": [],
   "source": [
    "def train_step(model, inputs, labels, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits, loss = model(inputs, labels=labels)\n",
    "    #print(logits)\n",
    "    #print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7984ypaMdixv"
   },
   "outputs": [],
   "source": [
    "def eval_step(model, inputs, labels):\n",
    "    logits, loss = model(inputs, labels=labels)\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbHHlscCdivT"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataset, optimizer, batch_size):\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
    "        for text, sentiment in train_loader:\n",
    "            sentiment = sentiment.to(device)\n",
    "\n",
    "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
    "\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            correct_count += (preds == sentiment).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPxnxXajditk"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, eval_dataset, batch_size, split):\n",
    "    eval_loader = DataLoader(dataset=eval_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_loss = 0\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
    "            for text, sentiment in eval_loader:\n",
    "                sentiment = sentiment.to(device)\n",
    "\n",
    "                logits, loss = eval_step(model, text, sentiment)\n",
    "\n",
    "                preds = torch.argmax(logits, axis=1)\n",
    "                y_pred += preds.cpu().numpy().tolist()\n",
    "                y_true += sentiment.cpu().numpy().tolist()\n",
    "\n",
    "                correct_count += (preds == sentiment).sum().item()\n",
    "                total_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
    "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JQeDe5FdirO"
   },
   "outputs": [],
   "source": [
    "def train(name, root, binary, epochs=25, patience=3, save=False):\n",
    "\n",
    "    #load model and tokenizer..\n",
    "    try:\n",
    "        transformer_container = load_transformer(name, binary)\n",
    "    except ValueError:\n",
    "        logger.error(\"Invalid transformer name!\")\n",
    "        os._exit(0)\n",
    "    model = transformer_container['model']\n",
    "    model = model.to(device)\n",
    "\n",
    "    #load batch_size and learning rate..\n",
    "    params_container = transformer_params(name)\n",
    "    batch_size = params_container['batch_size']\n",
    "    learning_rate = params_container['learning_rate']\n",
    "\n",
    "    #load train, dev and test datasets..\n",
    "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
    "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
    "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
    "\n",
    "    #Intialize optimizer..\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Initialize training variables..\n",
    "    best_acc = 0.0\n",
    "    best_loss = np.inf\n",
    "    stopping_step = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    total_train_seconds = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        train_acc, train_loss = train_epoch(model, train_dataset, optimizer, batch_size)\n",
    "        end = time.time()\n",
    "        total_train_seconds += (end - start)\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
    "\n",
    "        dev_acc, dev_loss, _ = eval_epoch(model, dev_dataset, batch_size, 'dev')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
    "\n",
    "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, test_dataset,\n",
    "                                                                  batch_size, 'test')\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
    "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
    "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
    "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
    "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
    "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
    "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
    "\n",
    "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
    "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
    "\n",
    "        #save best model and delete previous ones...\n",
    "        if save:\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                phrase_type, label = root_and_binary_title(root, binary)\n",
    "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
    "                save_model(model, model_name, best_model_name)\n",
    "\n",
    "\n",
    "        # Implement early stopping here\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step += 1\n",
    "\n",
    "        if stopping_step >= patience:\n",
    "            logger.info(\"EarlyStopping!\")\n",
    "            os._exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "axYwav8wdiou",
    "outputId": "591a7591-fe8e-499e-8e6d-fc2d49b14b52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-09-02 11:24:49.075 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
      "2020-09-02 11:24:56.023 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
      "2020-09-02 11:25:01.036 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
      "train: 100%|██████████| 267/267 [01:37<00:00,  2.74batch/s]\n",
      "2020-09-02 11:26:38.996 | INFO     | __main__:train:38 - epoch: 1, transformer: gpt2, train_loss: 0.0508, train_acc: 21.48\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  8.97batch/s]\n",
      "2020-09-02 11:26:42.924 | INFO     | __main__:train:41 - epoch: 1, transformer: gpt2, dev_loss: 0.0518, dev_acc: 20.62\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.79batch/s]\n",
      "2020-09-02 11:26:50.903 | INFO     | __main__:train:45 - epoch: 1, transformer: gpt2, test_loss: 0.0516, test_acc: 19.10\n",
      "2020-09-02 11:26:50.904 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_precision: 19.47, test_recall: 19.61, test_f1_score: 18.70, test_accuracy_score: 19.10\n",
      "2020-09-02 11:26:50.905 | INFO     | __main__:train:51 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 48  53  70  74  34]\n",
      " [111  74 211 156  81]\n",
      " [ 81  53 107  82  66]\n",
      " [ 98  64 151 123  74]\n",
      " [ 71  64 104  90  70]]\n",
      "2020-09-02 11:26:50.906 | INFO     | __main__:train:54 - Total training time elapsed: 0:01:37.402247\n",
      "2020-09-02 11:26:50.907 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:37.402247\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:28:27.408 | INFO     | __main__:train:38 - epoch: 2, transformer: gpt2, train_loss: 0.0506, train_acc: 19.72\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.20batch/s]\n",
      "2020-09-02 11:28:31.224 | INFO     | __main__:train:41 - epoch: 2, transformer: gpt2, dev_loss: 0.0515, dev_acc: 21.16\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.93batch/s]\n",
      "2020-09-02 11:28:39.078 | INFO     | __main__:train:45 - epoch: 2, transformer: gpt2, test_loss: 0.0515, test_acc: 21.18\n",
      "2020-09-02 11:28:39.079 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_precision: 18.70, test_recall: 18.91, test_f1_score: 18.49, test_accuracy_score: 21.18\n",
      "2020-09-02 11:28:39.080 | INFO     | __main__:train:51 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 27  95  45  81  31]\n",
      " [ 92 192  91 192  66]\n",
      " [ 38 123  63 122  43]\n",
      " [ 63 161  80 152  54]\n",
      " [ 39 129  63 134  34]]\n",
      "2020-09-02 11:28:39.081 | INFO     | __main__:train:54 - Total training time elapsed: 0:03:13.901811\n",
      "2020-09-02 11:28:39.081 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.950905\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 11:30:15.748 | INFO     | __main__:train:38 - epoch: 3, transformer: gpt2, train_loss: 0.0500, train_acc: 23.44\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.09batch/s]\n",
      "2020-09-02 11:30:19.610 | INFO     | __main__:train:41 - epoch: 3, transformer: gpt2, dev_loss: 0.0509, dev_acc: 23.34\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.92batch/s]\n",
      "2020-09-02 11:30:27.475 | INFO     | __main__:train:45 - epoch: 3, transformer: gpt2, test_loss: 0.0508, test_acc: 23.44\n",
      "2020-09-02 11:30:27.476 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_precision: 20.53, test_recall: 20.40, test_f1_score: 19.51, test_accuracy_score: 23.44\n",
      "2020-09-02 11:30:27.477 | INFO     | __main__:train:51 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 20  78  42 110  29]\n",
      " [ 36 209  77 241  70]\n",
      " [ 22 135  46 151  35]\n",
      " [ 27 161  72 200  50]\n",
      " [ 29 126  56 145  43]]\n",
      "2020-09-02 11:30:27.478 | INFO     | __main__:train:54 - Total training time elapsed: 0:04:50.566598\n",
      "2020-09-02 11:30:27.479 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.855533\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 11:32:04.073 | INFO     | __main__:train:38 - epoch: 4, transformer: gpt2, train_loss: 0.0497, train_acc: 25.22\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.16batch/s]\n",
      "2020-09-02 11:32:07.907 | INFO     | __main__:train:41 - epoch: 4, transformer: gpt2, dev_loss: 0.0503, dev_acc: 25.52\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.97batch/s]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2020-09-02 11:32:15.727 | INFO     | __main__:train:45 - epoch: 4, transformer: gpt2, test_loss: 0.0503, test_acc: 25.16\n",
      "2020-09-02 11:32:15.727 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_precision: 14.84, test_recall: 19.90, test_f1_score: 14.62, test_accuracy_score: 25.16\n",
      "2020-09-02 11:32:15.728 | INFO     | __main__:train:51 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
      "[[  0 141   6 132   0]\n",
      " [  0 277  21 335   0]\n",
      " [  0 169  17 202   1]\n",
      " [  0 235  13 262   0]\n",
      " [  0 204  15 180   0]]\n",
      "2020-09-02 11:32:15.729 | INFO     | __main__:train:54 - Total training time elapsed: 0:06:27.159773\n",
      "2020-09-02 11:32:15.729 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.789943\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 11:33:51.935 | INFO     | __main__:train:38 - epoch: 5, transformer: gpt2, train_loss: 0.0492, train_acc: 26.09\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.13batch/s]\n",
      "2020-09-02 11:33:55.782 | INFO     | __main__:train:41 - epoch: 5, transformer: gpt2, dev_loss: 0.0503, dev_acc: 25.52\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.98batch/s]\n",
      "2020-09-02 11:34:03.590 | INFO     | __main__:train:45 - epoch: 5, transformer: gpt2, test_loss: 0.0504, test_acc: 25.16\n",
      "2020-09-02 11:34:03.591 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_precision: 15.07, test_recall: 20.36, test_f1_score: 14.20, test_accuracy_score: 25.16\n",
      "2020-09-02 11:34:03.592 | INFO     | __main__:train:51 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
      "[[  0  72   7 200   0]\n",
      " [  0 209  11 413   0]\n",
      " [  0 107  12 270   0]\n",
      " [  0 159  16 335   0]\n",
      " [  0 130   9 260   0]]\n",
      "2020-09-02 11:34:03.592 | INFO     | __main__:train:54 - Total training time elapsed: 0:08:03.364340\n",
      "2020-09-02 11:34:03.594 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.672868\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 11:35:39.759 | INFO     | __main__:train:38 - epoch: 6, transformer: gpt2, train_loss: 0.0492, train_acc: 27.02\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.23batch/s]\n",
      "2020-09-02 11:35:43.567 | INFO     | __main__:train:41 - epoch: 6, transformer: gpt2, dev_loss: 0.0502, dev_acc: 24.98\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.94batch/s]\n",
      "2020-09-02 11:35:51.411 | INFO     | __main__:train:45 - epoch: 6, transformer: gpt2, test_loss: 0.0504, test_acc: 25.75\n",
      "2020-09-02 11:35:51.412 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_precision: 11.55, test_recall: 20.25, test_f1_score: 13.75, test_accuracy_score: 25.75\n",
      "2020-09-02 11:35:51.413 | INFO     | __main__:train:51 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
      "[[  0 106   5 168   0]\n",
      " [  0 272   8 353   0]\n",
      " [  0 174   1 214   0]\n",
      " [  0 211   3 296   0]\n",
      " [  0 168   3 228   0]]\n",
      "2020-09-02 11:35:51.413 | INFO     | __main__:train:54 - Total training time elapsed: 0:09:39.529316\n",
      "2020-09-02 11:35:51.414 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.588219\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 11:37:28.036 | INFO     | __main__:train:38 - epoch: 7, transformer: gpt2, train_loss: 0.0493, train_acc: 26.24\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.21batch/s]\n",
      "2020-09-02 11:37:31.849 | INFO     | __main__:train:41 - epoch: 7, transformer: gpt2, dev_loss: 0.0501, dev_acc: 25.79\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.96batch/s]\n",
      "2020-09-02 11:37:39.678 | INFO     | __main__:train:45 - epoch: 7, transformer: gpt2, test_loss: 0.0505, test_acc: 25.11\n",
      "2020-09-02 11:37:39.679 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_precision: 16.63, test_recall: 20.06, test_f1_score: 14.39, test_accuracy_score: 25.11\n",
      "2020-09-02 11:37:39.680 | INFO     | __main__:train:51 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
      "[[  0 116   6 155   2]\n",
      " [  3 244  18 365   3]\n",
      " [  3 158  12 215   1]\n",
      " [  1 194  15 298   2]\n",
      " [  1 152   8 237   1]]\n",
      "2020-09-02 11:37:39.681 | INFO     | __main__:train:54 - Total training time elapsed: 0:11:16.149791\n",
      "2020-09-02 11:37:39.681 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.592827\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:39:16.028 | INFO     | __main__:train:38 - epoch: 8, transformer: gpt2, train_loss: 0.0492, train_acc: 26.01\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.14batch/s]\n",
      "2020-09-02 11:39:19.872 | INFO     | __main__:train:41 - epoch: 8, transformer: gpt2, dev_loss: 0.0502, dev_acc: 25.07\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.94batch/s]\n",
      "2020-09-02 11:39:27.722 | INFO     | __main__:train:45 - epoch: 8, transformer: gpt2, test_loss: 0.0502, test_acc: 22.94\n",
      "2020-09-02 11:39:27.723 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_precision: 14.83, test_recall: 19.07, test_f1_score: 11.49, test_accuracy_score: 22.94\n",
      "2020-09-02 11:39:27.724 | INFO     | __main__:train:51 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
      "[[  0  57   1 221   0]\n",
      " [  0 113   3 517   0]\n",
      " [  0  83   4 302   0]\n",
      " [  0 116   4 390   0]\n",
      " [  0  81   3 315   0]]\n",
      "2020-09-02 11:39:27.724 | INFO     | __main__:train:54 - Total training time elapsed: 0:12:52.495884\n",
      "2020-09-02 11:39:27.725 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.561986\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:41:03.961 | INFO     | __main__:train:38 - epoch: 9, transformer: gpt2, train_loss: 0.0492, train_acc: 26.53\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.22batch/s]\n",
      "2020-09-02 11:41:07.771 | INFO     | __main__:train:41 - epoch: 9, transformer: gpt2, dev_loss: 0.0504, dev_acc: 24.16\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.99batch/s]\n",
      "2020-09-02 11:41:15.575 | INFO     | __main__:train:45 - epoch: 9, transformer: gpt2, test_loss: 0.0502, test_acc: 23.80\n",
      "2020-09-02 11:41:15.576 | INFO     | __main__:train:46 - epoch: 9, transformer: gpt2, test_precision: 13.87, test_recall: 19.06, test_f1_score: 12.62, test_accuracy_score: 23.80\n",
      "2020-09-02 11:41:15.577 | INFO     | __main__:train:51 - epoch: 9, transformer: gpt2, test_confusion_matrix: \n",
      "[[  1  88   0 190   0]\n",
      " [  0 210   0 423   0]\n",
      " [  2 129   0 258   0]\n",
      " [  1 192   2 315   0]\n",
      " [  1 147   0 251   0]]\n",
      "2020-09-02 11:41:15.578 | INFO     | __main__:train:54 - Total training time elapsed: 0:14:28.730130\n",
      "2020-09-02 11:41:15.578 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.525570\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 11:42:52.202 | INFO     | __main__:train:38 - epoch: 10, transformer: gpt2, train_loss: 0.0490, train_acc: 27.45\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.09batch/s]\n",
      "2020-09-02 11:42:56.064 | INFO     | __main__:train:41 - epoch: 10, transformer: gpt2, dev_loss: 0.0501, dev_acc: 24.16\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.96batch/s]\n",
      "2020-09-02 11:43:03.889 | INFO     | __main__:train:45 - epoch: 10, transformer: gpt2, test_loss: 0.0502, test_acc: 25.79\n",
      "2020-09-02 11:43:03.890 | INFO     | __main__:train:46 - epoch: 10, transformer: gpt2, test_precision: 25.24, test_recall: 20.49, test_f1_score: 14.69, test_accuracy_score: 25.79\n",
      "2020-09-02 11:43:03.891 | INFO     | __main__:train:51 - epoch: 10, transformer: gpt2, test_confusion_matrix: \n",
      "[[  1 121   8 149   0]\n",
      " [  0 266   8 359   0]\n",
      " [  0 141  11 237   0]\n",
      " [  0 207  11 292   0]\n",
      " [  1 158   9 231   0]]\n",
      "2020-09-02 11:43:03.892 | INFO     | __main__:train:54 - Total training time elapsed: 0:16:05.352312\n",
      "2020-09-02 11:43:03.893 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.535231\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.79batch/s]\n",
      "2020-09-02 11:44:39.678 | INFO     | __main__:train:38 - epoch: 11, transformer: gpt2, train_loss: 0.0489, train_acc: 28.24\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.19batch/s]\n",
      "2020-09-02 11:44:43.501 | INFO     | __main__:train:41 - epoch: 11, transformer: gpt2, dev_loss: 0.0483, dev_acc: 33.70\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.91batch/s]\n",
      "2020-09-02 11:44:51.372 | INFO     | __main__:train:45 - epoch: 11, transformer: gpt2, test_loss: 0.0484, test_acc: 34.03\n",
      "2020-09-02 11:44:51.373 | INFO     | __main__:train:46 - epoch: 11, transformer: gpt2, test_precision: 29.57, test_recall: 28.04, test_f1_score: 21.89, test_accuracy_score: 34.03\n",
      "2020-09-02 11:44:51.374 | INFO     | __main__:train:51 - epoch: 11, transformer: gpt2, test_confusion_matrix: \n",
      "[[  8 139  28  97   7]\n",
      " [ 16 280  48 280   9]\n",
      " [  9 140  22 212   6]\n",
      " [  2  63   6 428  11]\n",
      " [  0  24   2 359  14]]\n",
      "2020-09-02 11:44:51.374 | INFO     | __main__:train:54 - Total training time elapsed: 0:17:41.137305\n",
      "2020-09-02 11:44:51.375 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.467028\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:46:27.626 | INFO     | __main__:train:38 - epoch: 12, transformer: gpt2, train_loss: 0.0399, train_acc: 44.11\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.21batch/s]\n",
      "2020-09-02 11:46:31.442 | INFO     | __main__:train:41 - epoch: 12, transformer: gpt2, dev_loss: 0.0381, dev_acc: 44.87\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.97batch/s]\n",
      "2020-09-02 11:46:39.264 | INFO     | __main__:train:45 - epoch: 12, transformer: gpt2, test_loss: 0.0367, test_acc: 45.93\n",
      "2020-09-02 11:46:39.265 | INFO     | __main__:train:46 - epoch: 12, transformer: gpt2, test_precision: 39.08, test_recall: 39.49, test_f1_score: 35.70, test_accuracy_score: 45.93\n",
      "2020-09-02 11:46:39.266 | INFO     | __main__:train:51 - epoch: 12, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 31 233   2  13   0]\n",
      " [ 53 515  13  42  10]\n",
      " [ 21 226  11 101  30]\n",
      " [  3  58  14 232 203]\n",
      " [  1  19   1 152 226]]\n",
      "2020-09-02 11:46:39.267 | INFO     | __main__:train:54 - Total training time elapsed: 0:19:17.387070\n",
      "2020-09-02 11:46:39.268 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.448923\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 11:48:15.455 | INFO     | __main__:train:38 - epoch: 13, transformer: gpt2, train_loss: 0.0327, train_acc: 50.99\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.14batch/s]\n",
      "2020-09-02 11:48:19.296 | INFO     | __main__:train:41 - epoch: 13, transformer: gpt2, dev_loss: 0.0384, dev_acc: 37.97\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.02batch/s]\n",
      "2020-09-02 11:48:27.078 | INFO     | __main__:train:45 - epoch: 13, transformer: gpt2, test_loss: 0.0363, test_acc: 43.67\n",
      "2020-09-02 11:48:27.079 | INFO     | __main__:train:46 - epoch: 13, transformer: gpt2, test_precision: 43.31, test_recall: 46.18, test_f1_score: 40.62, test_accuracy_score: 43.67\n",
      "2020-09-02 11:48:27.080 | INFO     | __main__:train:51 - epoch: 13, transformer: gpt2, test_confusion_matrix: \n",
      "[[185  81   8   5   0]\n",
      " [294 249  29  53   8]\n",
      " [ 77 128  47  92  45]\n",
      " [  6  37  22 149 296]\n",
      " [  3   9   5  47 335]]\n",
      "2020-09-02 11:48:27.081 | INFO     | __main__:train:54 - Total training time elapsed: 0:20:53.572537\n",
      "2020-09-02 11:48:27.081 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.428657\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.78batch/s]\n",
      "2020-09-02 11:50:03.054 | INFO     | __main__:train:38 - epoch: 14, transformer: gpt2, train_loss: 0.0285, train_acc: 57.92\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.12batch/s]\n",
      "2020-09-02 11:50:06.903 | INFO     | __main__:train:41 - epoch: 14, transformer: gpt2, dev_loss: 0.0389, dev_acc: 44.23\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.04batch/s]\n",
      "2020-09-02 11:50:14.664 | INFO     | __main__:train:45 - epoch: 14, transformer: gpt2, test_loss: 0.0367, test_acc: 47.78\n",
      "2020-09-02 11:50:14.665 | INFO     | __main__:train:46 - epoch: 14, transformer: gpt2, test_precision: 46.36, test_recall: 47.29, test_f1_score: 46.50, test_accuracy_score: 47.78\n",
      "2020-09-02 11:50:14.666 | INFO     | __main__:train:51 - epoch: 14, transformer: gpt2, test_confusion_matrix: \n",
      "[[139 108  24   8   0]\n",
      " [171 310  95  54   3]\n",
      " [ 36 129  99 103  22]\n",
      " [  0  24  57 277 152]\n",
      " [  1   9  10 148 231]]\n",
      "2020-09-02 11:50:14.667 | INFO     | __main__:train:54 - Total training time elapsed: 0:22:29.544048\n",
      "2020-09-02 11:50:14.668 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.396003\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.79batch/s]\n",
      "2020-09-02 11:51:50.424 | INFO     | __main__:train:38 - epoch: 15, transformer: gpt2, train_loss: 0.0248, train_acc: 63.34\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.06batch/s]\n",
      "2020-09-02 11:51:54.303 | INFO     | __main__:train:41 - epoch: 15, transformer: gpt2, dev_loss: 0.0422, dev_acc: 43.69\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.98batch/s]\n",
      "2020-09-02 11:52:02.114 | INFO     | __main__:train:45 - epoch: 15, transformer: gpt2, test_loss: 0.0407, test_acc: 46.20\n",
      "2020-09-02 11:52:02.115 | INFO     | __main__:train:46 - epoch: 15, transformer: gpt2, test_precision: 45.05, test_recall: 49.05, test_f1_score: 45.07, test_accuracy_score: 46.20\n",
      "2020-09-02 11:52:02.116 | INFO     | __main__:train:51 - epoch: 15, transformer: gpt2, test_confusion_matrix: \n",
      "[[184  56  28  10   1]\n",
      " [227 238  96  60  12]\n",
      " [ 44 103 103 101  38]\n",
      " [  0  18  61 167 264]\n",
      " [  1   5  10  54 329]]\n",
      "2020-09-02 11:52:02.117 | INFO     | __main__:train:54 - Total training time elapsed: 0:24:05.300170\n",
      "2020-09-02 11:52:02.117 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.353345\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.79batch/s]\n",
      "2020-09-02 11:53:37.961 | INFO     | __main__:train:38 - epoch: 16, transformer: gpt2, train_loss: 0.0215, train_acc: 69.60\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.14batch/s]\n",
      "2020-09-02 11:53:41.805 | INFO     | __main__:train:41 - epoch: 16, transformer: gpt2, dev_loss: 0.0417, dev_acc: 46.96\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.93batch/s]\n",
      "2020-09-02 11:53:49.660 | INFO     | __main__:train:45 - epoch: 16, transformer: gpt2, test_loss: 0.0392, test_acc: 50.77\n",
      "2020-09-02 11:53:49.660 | INFO     | __main__:train:46 - epoch: 16, transformer: gpt2, test_precision: 50.15, test_recall: 51.44, test_f1_score: 50.51, test_accuracy_score: 50.77\n",
      "2020-09-02 11:53:49.661 | INFO     | __main__:train:51 - epoch: 16, transformer: gpt2, test_confusion_matrix: \n",
      "[[154  91  31   2   1]\n",
      " [158 308 136  29   2]\n",
      " [ 37 106 152  78  16]\n",
      " [  0  23  97 239 151]\n",
      " [  1   6  19 104 269]]\n",
      "2020-09-02 11:53:49.662 | INFO     | __main__:train:54 - Total training time elapsed: 0:25:41.142804\n",
      "2020-09-02 11:53:49.662 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.321425\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:55:26.081 | INFO     | __main__:train:38 - epoch: 17, transformer: gpt2, train_loss: 0.0187, train_acc: 74.38\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.15batch/s]\n",
      "2020-09-02 11:55:29.920 | INFO     | __main__:train:41 - epoch: 17, transformer: gpt2, dev_loss: 0.0434, dev_acc: 49.68\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.94batch/s]\n",
      "2020-09-02 11:55:37.765 | INFO     | __main__:train:45 - epoch: 17, transformer: gpt2, test_loss: 0.0414, test_acc: 51.40\n",
      "2020-09-02 11:55:37.766 | INFO     | __main__:train:46 - epoch: 17, transformer: gpt2, test_precision: 52.15, test_recall: 50.03, test_f1_score: 50.61, test_accuracy_score: 51.40\n",
      "2020-09-02 11:55:37.767 | INFO     | __main__:train:51 - epoch: 17, transformer: gpt2, test_confusion_matrix: \n",
      "[[102 137  37   3   0]\n",
      " [ 76 349 174  32   2]\n",
      " [ 12 113 169  85  10]\n",
      " [  0  11 112 262 125]\n",
      " [  0   6  23 116 254]]\n",
      "2020-09-02 11:55:37.767 | INFO     | __main__:train:54 - Total training time elapsed: 0:27:17.560952\n",
      "2020-09-02 11:55:37.768 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.327115\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.79batch/s]\n",
      "2020-09-02 11:57:13.547 | INFO     | __main__:train:38 - epoch: 18, transformer: gpt2, train_loss: 0.0164, train_acc: 78.57\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.16batch/s]\n",
      "2020-09-02 11:57:17.382 | INFO     | __main__:train:41 - epoch: 18, transformer: gpt2, dev_loss: 0.0460, dev_acc: 48.50\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.92batch/s]\n",
      "2020-09-02 11:57:25.248 | INFO     | __main__:train:45 - epoch: 18, transformer: gpt2, test_loss: 0.0443, test_acc: 50.77\n",
      "2020-09-02 11:57:25.248 | INFO     | __main__:train:46 - epoch: 18, transformer: gpt2, test_precision: 51.65, test_recall: 50.61, test_f1_score: 50.71, test_accuracy_score: 50.77\n",
      "2020-09-02 11:57:25.249 | INFO     | __main__:train:51 - epoch: 18, transformer: gpt2, test_confusion_matrix: \n",
      "[[142 101  35   1   0]\n",
      " [134 307 164  27   1]\n",
      " [ 27 111 168  76   7]\n",
      " [  0  15 109 295  91]\n",
      " [  1   8  30 150 210]]\n",
      "2020-09-02 11:57:25.250 | INFO     | __main__:train:54 - Total training time elapsed: 0:28:53.339542\n",
      "2020-09-02 11:57:25.251 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.296641\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 11:59:01.584 | INFO     | __main__:train:38 - epoch: 19, transformer: gpt2, train_loss: 0.0144, train_acc: 81.78\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.25batch/s]\n",
      "2020-09-02 11:59:05.380 | INFO     | __main__:train:41 - epoch: 19, transformer: gpt2, dev_loss: 0.0501, dev_acc: 48.14\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.93batch/s]\n",
      "2020-09-02 11:59:13.238 | INFO     | __main__:train:45 - epoch: 19, transformer: gpt2, test_loss: 0.0474, test_acc: 51.40\n",
      "2020-09-02 11:59:13.238 | INFO     | __main__:train:46 - epoch: 19, transformer: gpt2, test_precision: 50.97, test_recall: 51.19, test_f1_score: 51.00, test_accuracy_score: 51.40\n",
      "2020-09-02 11:59:13.239 | INFO     | __main__:train:51 - epoch: 19, transformer: gpt2, test_confusion_matrix: \n",
      "[[137 106  33   3   0]\n",
      " [114 335 143  38   3]\n",
      " [ 16 123 151  88  11]\n",
      " [  0  16  88 247 159]\n",
      " [  1   5  20 107 266]]\n",
      "2020-09-02 11:59:13.240 | INFO     | __main__:train:54 - Total training time elapsed: 0:30:29.671457\n",
      "2020-09-02 11:59:13.240 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.298498\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 12:00:49.708 | INFO     | __main__:train:38 - epoch: 20, transformer: gpt2, train_loss: 0.0126, train_acc: 85.02\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.15batch/s]\n",
      "2020-09-02 12:00:53.545 | INFO     | __main__:train:41 - epoch: 20, transformer: gpt2, dev_loss: 0.0518, dev_acc: 49.05\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.04batch/s]\n",
      "2020-09-02 12:01:01.311 | INFO     | __main__:train:45 - epoch: 20, transformer: gpt2, test_loss: 0.0493, test_acc: 52.13\n",
      "2020-09-02 12:01:01.311 | INFO     | __main__:train:46 - epoch: 20, transformer: gpt2, test_precision: 52.11, test_recall: 52.57, test_f1_score: 51.99, test_accuracy_score: 52.13\n",
      "2020-09-02 12:01:01.312 | INFO     | __main__:train:51 - epoch: 20, transformer: gpt2, test_confusion_matrix: \n",
      "[[166  85  24   4   0]\n",
      " [162 310 123  36   2]\n",
      " [ 35 116 149  85   4]\n",
      " [  0  19  95 293 103]\n",
      " [  2   8  18 137 234]]\n",
      "2020-09-02 12:01:01.313 | INFO     | __main__:train:54 - Total training time elapsed: 0:32:06.138417\n",
      "2020-09-02 12:01:01.314 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.306921\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.78batch/s]\n",
      "2020-09-02 12:02:37.306 | INFO     | __main__:train:38 - epoch: 21, transformer: gpt2, train_loss: 0.0107, train_acc: 87.71\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.11batch/s]\n",
      "2020-09-02 12:02:41.166 | INFO     | __main__:train:41 - epoch: 21, transformer: gpt2, dev_loss: 0.0526, dev_acc: 48.14\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.92batch/s]\n",
      "2020-09-02 12:02:49.035 | INFO     | __main__:train:45 - epoch: 21, transformer: gpt2, test_loss: 0.0492, test_acc: 52.31\n",
      "2020-09-02 12:02:49.035 | INFO     | __main__:train:46 - epoch: 21, transformer: gpt2, test_precision: 52.61, test_recall: 52.05, test_f1_score: 52.19, test_accuracy_score: 52.31\n",
      "2020-09-02 12:02:49.036 | INFO     | __main__:train:51 - epoch: 21, transformer: gpt2, test_confusion_matrix: \n",
      "[[141 100  35   3   0]\n",
      " [110 323 155  44   1]\n",
      " [ 19 113 157  94   6]\n",
      " [  0  13  91 289 117]\n",
      " [  0   6  19 128 246]]\n",
      "2020-09-02 12:02:49.037 | INFO     | __main__:train:54 - Total training time elapsed: 0:33:42.129451\n",
      "2020-09-02 12:02:49.038 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.291879\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 12:04:25.373 | INFO     | __main__:train:38 - epoch: 22, transformer: gpt2, train_loss: 0.0089, train_acc: 90.20\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.34batch/s]\n",
      "2020-09-02 12:04:29.136 | INFO     | __main__:train:41 - epoch: 22, transformer: gpt2, dev_loss: 0.0546, dev_acc: 49.77\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.99batch/s]\n",
      "2020-09-02 12:04:36.942 | INFO     | __main__:train:45 - epoch: 22, transformer: gpt2, test_loss: 0.0508, test_acc: 52.26\n",
      "2020-09-02 12:04:36.943 | INFO     | __main__:train:46 - epoch: 22, transformer: gpt2, test_precision: 52.98, test_recall: 51.96, test_f1_score: 52.25, test_accuracy_score: 52.26\n",
      "2020-09-02 12:04:36.944 | INFO     | __main__:train:51 - epoch: 22, transformer: gpt2, test_confusion_matrix: \n",
      "[[138 107  31   3   0]\n",
      " [106 330 167  29   1]\n",
      " [ 19 109 173  82   6]\n",
      " [  0  14 107 277 112]\n",
      " [  0   5  27 130 237]]\n",
      "2020-09-02 12:04:36.945 | INFO     | __main__:train:54 - Total training time elapsed: 0:35:18.463278\n",
      "2020-09-02 12:04:36.945 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.293785\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 12:06:13.474 | INFO     | __main__:train:38 - epoch: 23, transformer: gpt2, train_loss: 0.0075, train_acc: 92.46\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.24batch/s]\n",
      "2020-09-02 12:06:17.275 | INFO     | __main__:train:41 - epoch: 23, transformer: gpt2, dev_loss: 0.0601, dev_acc: 48.50\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.93batch/s]\n",
      "2020-09-02 12:06:25.135 | INFO     | __main__:train:45 - epoch: 23, transformer: gpt2, test_loss: 0.0553, test_acc: 51.36\n",
      "2020-09-02 12:06:25.136 | INFO     | __main__:train:46 - epoch: 23, transformer: gpt2, test_precision: 51.54, test_recall: 50.76, test_f1_score: 50.98, test_accuracy_score: 51.36\n",
      "2020-09-02 12:06:25.137 | INFO     | __main__:train:51 - epoch: 23, transformer: gpt2, test_confusion_matrix: \n",
      "[[125 113  39   2   0]\n",
      " [100 321 163  46   3]\n",
      " [ 13 114 156  95  11]\n",
      " [  0   8  86 282 134]\n",
      " [  0   5  18 125 251]]\n",
      "2020-09-02 12:06:25.137 | INFO     | __main__:train:54 - Total training time elapsed: 0:36:54.991295\n",
      "2020-09-02 12:06:25.138 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.303969\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 12:08:01.352 | INFO     | __main__:train:38 - epoch: 24, transformer: gpt2, train_loss: 0.0064, train_acc: 93.60\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.13batch/s]\n",
      "2020-09-02 12:08:05.200 | INFO     | __main__:train:41 - epoch: 24, transformer: gpt2, dev_loss: 0.0630, dev_acc: 49.05\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.10batch/s]\n",
      "2020-09-02 12:08:12.906 | INFO     | __main__:train:45 - epoch: 24, transformer: gpt2, test_loss: 0.0588, test_acc: 51.67\n",
      "2020-09-02 12:08:12.906 | INFO     | __main__:train:46 - epoch: 24, transformer: gpt2, test_precision: 52.37, test_recall: 50.59, test_f1_score: 51.06, test_accuracy_score: 51.67\n",
      "2020-09-02 12:08:12.907 | INFO     | __main__:train:51 - epoch: 24, transformer: gpt2, test_confusion_matrix: \n",
      "[[110 128  35   6   0]\n",
      " [ 74 327 179  50   3]\n",
      " [ 13 104 160 101  11]\n",
      " [  0   8  83 291 128]\n",
      " [  0   6  17 122 254]]\n",
      "2020-09-02 12:08:12.908 | INFO     | __main__:train:54 - Total training time elapsed: 0:38:31.204453\n",
      "2020-09-02 12:08:12.908 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.300186\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 12:09:49.613 | INFO     | __main__:train:38 - epoch: 25, transformer: gpt2, train_loss: 0.0057, train_acc: 94.28\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.14batch/s]\n",
      "2020-09-02 12:09:53.454 | INFO     | __main__:train:41 - epoch: 25, transformer: gpt2, dev_loss: 0.0645, dev_acc: 49.14\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.95batch/s]\n",
      "2020-09-02 12:10:01.295 | INFO     | __main__:train:45 - epoch: 25, transformer: gpt2, test_loss: 0.0597, test_acc: 52.31\n",
      "2020-09-02 12:10:01.296 | INFO     | __main__:train:46 - epoch: 25, transformer: gpt2, test_precision: 52.38, test_recall: 51.18, test_f1_score: 51.51, test_accuracy_score: 52.31\n",
      "2020-09-02 12:10:01.297 | INFO     | __main__:train:51 - epoch: 25, transformer: gpt2, test_confusion_matrix: \n",
      "[[111 132  33   3   0]\n",
      " [ 83 342 164  43   1]\n",
      " [ 16 101 162 100  10]\n",
      " [  0   9  89 278 134]\n",
      " [  0   8  18 110 263]]\n",
      "2020-09-02 12:10:01.297 | INFO     | __main__:train:54 - Total training time elapsed: 0:40:07.907754\n",
      "2020-09-02 12:10:01.298 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.316310\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 12:11:37.460 | INFO     | __main__:train:38 - epoch: 26, transformer: gpt2, train_loss: 0.0050, train_acc: 94.98\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.23batch/s]\n",
      "2020-09-02 12:11:41.265 | INFO     | __main__:train:41 - epoch: 26, transformer: gpt2, dev_loss: 0.0657, dev_acc: 48.86\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.00batch/s]\n",
      "2020-09-02 12:11:49.061 | INFO     | __main__:train:45 - epoch: 26, transformer: gpt2, test_loss: 0.0620, test_acc: 52.53\n",
      "2020-09-02 12:11:49.062 | INFO     | __main__:train:46 - epoch: 26, transformer: gpt2, test_precision: 54.08, test_recall: 50.61, test_f1_score: 51.40, test_accuracy_score: 52.53\n",
      "2020-09-02 12:11:49.063 | INFO     | __main__:train:51 - epoch: 26, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 92 145  39   3   0]\n",
      " [ 50 357 188  36   2]\n",
      " [ 12 109 173  87   8]\n",
      " [  0   6  96 291 117]\n",
      " [  0   6  20 125 248]]\n",
      "2020-09-02 12:11:49.064 | INFO     | __main__:train:54 - Total training time elapsed: 0:41:44.068640\n",
      "2020-09-02 12:11:49.065 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.310332\n",
      "train: 100%|██████████| 267/267 [01:35<00:00,  2.78batch/s]\n",
      "2020-09-02 12:13:25.070 | INFO     | __main__:train:38 - epoch: 27, transformer: gpt2, train_loss: 0.0045, train_acc: 95.60\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.15batch/s]\n",
      "2020-09-02 12:13:28.906 | INFO     | __main__:train:41 - epoch: 27, transformer: gpt2, dev_loss: 0.0679, dev_acc: 48.50\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  9.00batch/s]\n",
      "2020-09-02 12:13:36.699 | INFO     | __main__:train:45 - epoch: 27, transformer: gpt2, test_loss: 0.0634, test_acc: 52.08\n",
      "2020-09-02 12:13:36.700 | INFO     | __main__:train:46 - epoch: 27, transformer: gpt2, test_precision: 53.71, test_recall: 50.87, test_f1_score: 51.71, test_accuracy_score: 52.08\n",
      "2020-09-02 12:13:36.701 | INFO     | __main__:train:51 - epoch: 27, transformer: gpt2, test_confusion_matrix: \n",
      "[[113 128  34   4   0]\n",
      " [ 68 339 182  44   0]\n",
      " [  9 109 168  97   6]\n",
      " [  0   9  97 293 111]\n",
      " [  0   5  19 137 238]]\n",
      "2020-09-02 12:13:36.702 | INFO     | __main__:train:54 - Total training time elapsed: 0:43:20.072335\n",
      "2020-09-02 12:13:36.702 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.298975\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.76batch/s]\n",
      "2020-09-02 12:15:13.432 | INFO     | __main__:train:38 - epoch: 28, transformer: gpt2, train_loss: 0.0038, train_acc: 96.21\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.23batch/s]\n",
      "2020-09-02 12:15:17.237 | INFO     | __main__:train:41 - epoch: 28, transformer: gpt2, dev_loss: 0.0695, dev_acc: 48.77\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.96batch/s]\n",
      "2020-09-02 12:15:25.062 | INFO     | __main__:train:45 - epoch: 28, transformer: gpt2, test_loss: 0.0662, test_acc: 51.22\n",
      "2020-09-02 12:15:25.063 | INFO     | __main__:train:46 - epoch: 28, transformer: gpt2, test_precision: 52.90, test_recall: 49.34, test_f1_score: 50.28, test_accuracy_score: 51.22\n",
      "2020-09-02 12:15:25.064 | INFO     | __main__:train:51 - epoch: 28, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 97 148  30   4   0]\n",
      " [ 66 341 184  42   0]\n",
      " [ 10 109 163 103   4]\n",
      " [  0  14  91 310  95]\n",
      " [  0   5  23 150 221]]\n",
      "2020-09-02 12:15:25.064 | INFO     | __main__:train:54 - Total training time elapsed: 0:44:56.801277\n",
      "2020-09-02 12:15:25.065 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.314331\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.77batch/s]\n",
      "2020-09-02 12:17:01.426 | INFO     | __main__:train:38 - epoch: 29, transformer: gpt2, train_loss: 0.0035, train_acc: 96.58\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.10batch/s]\n",
      "2020-09-02 12:17:05.286 | INFO     | __main__:train:41 - epoch: 29, transformer: gpt2, dev_loss: 0.0726, dev_acc: 48.32\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.88batch/s]\n",
      "2020-09-02 12:17:13.188 | INFO     | __main__:train:45 - epoch: 29, transformer: gpt2, test_loss: 0.0664, test_acc: 51.86\n",
      "2020-09-02 12:17:13.188 | INFO     | __main__:train:46 - epoch: 29, transformer: gpt2, test_precision: 53.08, test_recall: 50.82, test_f1_score: 51.54, test_accuracy_score: 51.86\n",
      "2020-09-02 12:17:13.189 | INFO     | __main__:train:51 - epoch: 29, transformer: gpt2, test_confusion_matrix: \n",
      "[[116 126  34   3   0]\n",
      " [ 79 337 182  35   0]\n",
      " [ 12 110 169  93   5]\n",
      " [  0  12 101 284 113]\n",
      " [  0   6  22 131 240]]\n",
      "2020-09-02 12:17:13.190 | INFO     | __main__:train:54 - Total training time elapsed: 0:46:33.161518\n",
      "2020-09-02 12:17:13.191 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.315914\n",
      "train: 100%|██████████| 267/267 [01:36<00:00,  2.78batch/s]\n",
      "2020-09-02 12:18:49.254 | INFO     | __main__:train:38 - epoch: 30, transformer: gpt2, train_loss: 0.0031, train_acc: 96.86\n",
      "dev: 100%|██████████| 35/35 [00:03<00:00,  9.15batch/s]\n",
      "2020-09-02 12:18:53.091 | INFO     | __main__:train:41 - epoch: 30, transformer: gpt2, dev_loss: 0.0757, dev_acc: 49.41\n",
      "test: 100%|██████████| 70/70 [00:07<00:00,  8.96batch/s]\n",
      "2020-09-02 12:19:00.917 | INFO     | __main__:train:45 - epoch: 30, transformer: gpt2, test_loss: 0.0717, test_acc: 52.13\n",
      "2020-09-02 12:19:00.918 | INFO     | __main__:train:46 - epoch: 30, transformer: gpt2, test_precision: 53.73, test_recall: 49.72, test_f1_score: 50.55, test_accuracy_score: 52.13\n",
      "2020-09-02 12:19:00.919 | INFO     | __main__:train:51 - epoch: 30, transformer: gpt2, test_confusion_matrix: \n",
      "[[ 84 155  36   4   0]\n",
      " [ 52 361 177  42   1]\n",
      " [  6 109 165 104   5]\n",
      " [  0   7  87 308 108]\n",
      " [  0   3  22 140 234]]\n",
      "2020-09-02 12:19:00.919 | INFO     | __main__:train:54 - Total training time elapsed: 0:48:09.223796\n",
      "2020-09-02 12:19:00.920 | INFO     | __main__:train:55 - Mean time per train epoch: 0:01:36.307460\n"
     ]
    }
   ],
   "source": [
    "train('gpt2', True, False, 30, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJ12BnAei0FS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRZpL_cidimc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iz3muFrUdikk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjd7B--JdiiN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXqhawGkdigP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "fPfTXAGIdjFj",
    "outputId": "30eae525-01ed-4098-f8ca-518a0cd99707"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2, 10, 20],\n",
       "        [ 5,  5, 40, 50]])"
      ]
     },
     "execution_count": 174,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "b = torch.tensor([[10, 20, 30],\n",
    "                 [40, 50, 60]])\n",
    "\n",
    "out = torch.cat((\n",
    "                 a[:, torch.randint(0, 2, (2,))],\n",
    "                 b[:, torch.randint(0, 2, (2,))]\n",
    "), axis = 1)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT Dropout GPT2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
