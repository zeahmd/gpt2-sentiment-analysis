{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna GPT2 (Conv Pool) .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b35f9155ae224ae8ac415729758858a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_822bb6ae5d5c467eae778840855f7cbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49e5d56158364596971964befbce4b39",
              "IPY_MODEL_56d85124349c46199df3adc46a59080a"
            ]
          }
        },
        "822bb6ae5d5c467eae778840855f7cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49e5d56158364596971964befbce4b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df01a9c9e09546aab550070a87ed63e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4097f2888a2c499a90b1be8c4c774eee"
          }
        },
        "56d85124349c46199df3adc46a59080a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cc1c8147b1747c7bd92ed9bc4af1994",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 637kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f94d2a0e3d34d70af47ca6f962bffdf"
          }
        },
        "df01a9c9e09546aab550070a87ed63e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4097f2888a2c499a90b1be8c4c774eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cc1c8147b1747c7bd92ed9bc4af1994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f94d2a0e3d34d70af47ca6f962bffdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "053b0798bd324804bade5067e01c1904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eaeb027ab3884308b3236c84b0af2c58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_910be4b46ce54f67b72ab9b7cee8c41a",
              "IPY_MODEL_8c275500fa8d4c0a931ed95ba5af1c0e"
            ]
          }
        },
        "eaeb027ab3884308b3236c84b0af2c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "910be4b46ce54f67b72ab9b7cee8c41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e479db6b4f7423ab448354efbe79c5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07217b45340c4985872bcb1c87d776b0"
          }
        },
        "8c275500fa8d4c0a931ed95ba5af1c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d275420fcd8a41458c9352fcf2f90dc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.10MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7445664cbc3a4f8e88437a62e52493cb"
          }
        },
        "7e479db6b4f7423ab448354efbe79c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07217b45340c4985872bcb1c87d776b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d275420fcd8a41458c9352fcf2f90dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7445664cbc3a4f8e88437a62e52493cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de3b05f40103403c80d59a745af3f1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95e61c858685426a8f676629abe32755",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8bfce19628b847e4b42b9794b3ff2672",
              "IPY_MODEL_c72fb0065b804e9ab6b92c45caa09658"
            ]
          }
        },
        "95e61c858685426a8f676629abe32755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bfce19628b847e4b42b9794b3ff2672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13c0bb60bab345f5af9f121fb6cd383e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea9233310410429d833082fe595051c1"
          }
        },
        "c72fb0065b804e9ab6b92c45caa09658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e9ea058fd4d41659b60d0693e58e638",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 4.44kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6443a0189bb4682b1b5c7038ecb501e"
          }
        },
        "13c0bb60bab345f5af9f121fb6cd383e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea9233310410429d833082fe595051c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e9ea058fd4d41659b60d0693e58e638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6443a0189bb4682b1b5c7038ecb501e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8dba53983ea45f7afbdb5d05348a4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1968e68903c84d67972536c9e75acccd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe7b393a60e34941bd13df09e5235165",
              "IPY_MODEL_c898868700ae4ba4aa8ee63d98063310"
            ]
          }
        },
        "1968e68903c84d67972536c9e75acccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe7b393a60e34941bd13df09e5235165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4e1044fc78345e1a00c4cce85a04c00",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a32f8b61a56440c8b73f9a3c25e4fa5"
          }
        },
        "c898868700ae4ba4aa8ee63d98063310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c545761bed2349659b50b75b517916f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:45&lt;00:00, 12.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c807b538fedb4551a7ae1e0f802cd1eb"
          }
        },
        "a4e1044fc78345e1a00c4cce85a04c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a32f8b61a56440c8b73f9a3c25e4fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c545761bed2349659b50b75b517916f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c807b538fedb4551a7ae1e0f802cd1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdHVQrqyDB50",
        "colab_type": "text"
      },
      "source": [
        "# Memory Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58HaeA6CsM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8e308a63-4660-456e-8c6a-ad40270ef5af"
      },
      "source": [
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================== Memory Information ========================================\n",
            "Total: 25.51GB\n",
            "Available: 24.60GB\n",
            "Used: 587.51MB\n",
            "Percentage: 3.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgVfBlvZDEja",
        "colab_type": "text"
      },
      "source": [
        "# GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxlkxvkrCyin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "5d99eb81-f3d7-447b-92a6-93f8e5ac1dbf"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 13:27:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6WR5Uaa6RQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "676e3053-0131-4858-f386-7dbbf57b6cb6"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
            "Collecting loguru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/f7/85704c74dd5b616a528aa724d359033f4dbec896b604cf12b65c4f9badb1/loguru-0.5.2-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/b1/a5f0574fa0d769bf0a5629722c84bb0af015967191a37401fe8508c5fb6a/optuna-2.1.0.tar.gz (232kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 18.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 23.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 43.4MB/s \n",
            "\u001b[?25hCollecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->-r requirements.txt (line 10)) (1.3.19)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/03/5d15a78ca92ac2bf09f466c54c48bb92979dfe19add2dfed415133ba9792/cmaes-0.6.1-py3-none-any.whl\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.9MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
            "Collecting contextvars==2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->-r requirements.txt (line 10)) (0.7.2)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/58/f80bdd6a86550e48d3766036ea77e5bc63a4b58bd581b8b8ceaa3111b901/stevedore-3.2.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->-r requirements.txt (line 10)) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/a3/d439f338aa90edd5ad9096cd56564b44882182150e92148eb14ceb7488ba/pbr-5.5.0-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 53.8MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/20/ca2ddf5bb14c460d1b103a75ce51fe9e27c380091a3d532f9adc73922d73/cmd2-1.3.9-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.8MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.3MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna->-r requirements.txt (line 10)) (2.8.1)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna->-r requirements.txt (line 10)) (1.7.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->-r requirements.txt (line 10)) (49.6.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->-r requirements.txt (line 10)) (20.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->-r requirements.txt (line 10)) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->-r requirements.txt (line 10)) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna->-r requirements.txt (line 10)) (3.1.0)\n",
            "Building wheels for collected packages: optuna, alembic\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.1.0-cp36-none-any.whl size=321090 sha256=7ddea0b0a52e9e95d59639cbc408e8b8b5f9e4d0aab66f4561f70c499418b8da\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/25/24/a165483933b5eefbf4f93c85f3188dc696cbb38620b73ad713\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159540 sha256=b6af3b7aeb11ff3fe103c059c70c0dc141f5b5ab90a84db132d6a2a5dd72aa10\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built optuna alembic\n",
            "Building wheels for collected packages: pytreebank, sacremoses, contextvars, pyperclip\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp36-none-any.whl size=37070 sha256=353d38bac4d842af7da289339a4c68f0f62fd368d7b3bb2bd8d84334827ef844\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e1d2ab9d2bad49b30b669eb8a23df404adb23d1c65fe920cac2c2d28c71a2551\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=a739123b69c9a5d95c640eda7d6ed6687b18e301a1c485a114095391aadca00a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=ccc6fd779eb4d07484da8b46defe57e862c075d081af07b2211bf2aea1b7c062\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built pytreebank sacremoses contextvars pyperclip\n",
            "Installing collected packages: pytreebank, sentencepiece, sacremoses, tokenizers, transformers, immutables, contextvars, aiocontextvars, loguru, colorlog, cmaes, pbr, stevedore, pyperclip, colorama, cmd2, cliff, Mako, python-editor, alembic, optuna\n",
            "Successfully installed Mako-1.1.3 aiocontextvars-0.2.2 alembic-1.4.2 cliff-3.4.0 cmaes-0.6.1 cmd2-1.3.9 colorama-0.4.3 colorlog-4.2.1 contextvars-2.4 immutables-0.14 loguru-0.5.2 optuna-2.1.0 pbr-5.5.0 pyperclip-1.8.0 python-editor-1.0.4 pytreebank-0.2.7 sacremoses-0.0.43 sentencepiece-0.1.91 stevedore-3.2.1 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDODoaWC6KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
        "import torch\n",
        "from dataset import SSTDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import transformer_params\n",
        "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
        "from math import ceil\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5IZjSzQNpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPT2ForSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, num_labels):\n",
        "    super(GPT2ForSequenceClassification, self).__init__()\n",
        "    self.model = GPT2Model.from_pretrained('gpt2',\n",
        "                                       config=GPT2Config.from_pretrained('gpt2'))\n",
        "    self.max_pool = torch.nn.MaxPool1d(3, 2)\n",
        "    self.dropout = torch.nn.Dropout(p=0.1)\n",
        "    self.layer_norm = torch.nn.LayerNorm(768)\n",
        "    self.conv1d_1 = torch.nn.Conv1d(in_channels=768, out_channels=768, kernel_size=1, stride=1)\n",
        "    self.fc_layer = torch.nn.Linear(in_features=768, out_features=768)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.out_layer = torch.nn.Linear(in_features=768, out_features=num_labels)\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
        "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
        "\n",
        "    gpt_last_layer = gpt_last_layer.permute(0, 2, 1)\n",
        "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
        "\n",
        "    max_pool_out = self.max_pool(gpt_last_layer)\n",
        "    #batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
        "\n",
        "    max_pool_out = self.dropout(max_pool_out)\n",
        "    max_pool_out = max_pool_out.permute(0, 2, 1)\n",
        "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
        "\n",
        "    layer_norm_out = self.layer_norm(max_pool_out)\n",
        "    layer_norm_out = layer_norm_out.permute(0, 2, 1)\n",
        "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
        "\n",
        "    conv1d_1_out = self.conv1d_1(layer_norm_out)\n",
        "    conv1d_1_out = self.tanh(conv1d_1_out)\n",
        "    #[batch_size, embedding_size(channels), seq_len] = [*, 768, *]\n",
        "\n",
        "    global_max_pooling_out, _ = torch.max(conv1d_1_out, axis=2)\n",
        "    global_max_pooling_out = self.dropout(global_max_pooling_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
        "\n",
        "    fc_layer_out = self.fc_layer(global_max_pooling_out)\n",
        "    fc_layer_out = self.tanh(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, 768]\n",
        "\n",
        "    fc_layer_out = self.dropout(fc_layer_out)\n",
        "    logits = self.out_layer(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
        "    \n",
        "    loss = self.criterion(logits, labels)\n",
        "                                   \n",
        "    return logits, loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlMNcjYekVMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "b35f9155ae224ae8ac415729758858a0",
            "822bb6ae5d5c467eae778840855f7cbd",
            "49e5d56158364596971964befbce4b39",
            "56d85124349c46199df3adc46a59080a",
            "df01a9c9e09546aab550070a87ed63e5",
            "4097f2888a2c499a90b1be8c4c774eee",
            "3cc1c8147b1747c7bd92ed9bc4af1994",
            "7f94d2a0e3d34d70af47ca6f962bffdf",
            "053b0798bd324804bade5067e01c1904",
            "eaeb027ab3884308b3236c84b0af2c58",
            "910be4b46ce54f67b72ab9b7cee8c41a",
            "8c275500fa8d4c0a931ed95ba5af1c0e",
            "7e479db6b4f7423ab448354efbe79c5c",
            "07217b45340c4985872bcb1c87d776b0",
            "d275420fcd8a41458c9352fcf2f90dc8",
            "7445664cbc3a4f8e88437a62e52493cb"
          ]
        },
        "outputId": "d74d2f01-7e9c-48bc-bc2d-abe5740fea2d"
      },
      "source": [
        "\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_tokenizer.add_special_tokens({'pad_token': '.'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b35f9155ae224ae8ac415729758858a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "053b0798bd324804bade5067e01c1904",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4_cQpe_c4BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_transformer(name, binary):\n",
        "  num_classes = 5\n",
        "  if binary:\n",
        "    num_classes = 2\n",
        "  model = GPT2ForSequenceClassification(num_classes)\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "  tokenizer.add_special_tokens({'pad_token': '.'})\n",
        "\n",
        "  return {'model': model,\n",
        "          'tokenizer': tokenizer}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFaW79Rdi0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSgyPvydj0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, inputs, labels, optimizer):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7984ypaMdixv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_step(model, inputs, labels):\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHHlscCdivT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, tokenizer, train_dataset, optimizer, batch_size):\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
        "        for text, sentiment in train_loader:\n",
        "            text = tokenizer(text, padding=True, return_tensors='pt').to(device)\n",
        "            sentiment = sentiment.to(device)\n",
        "\n",
        "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
        "\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "            correct_count += (preds == sentiment).sum().item()\n",
        "            total_loss += loss.item()\n",
        "            pbar.update(1)\n",
        "\n",
        "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPxnxXajditk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, tokenizer, eval_dataset, batch_size, split):\n",
        "    eval_loader = DataLoader(dataset=eval_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "    y_pred = list()\n",
        "    y_true = list()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
        "            for text, sentiment in eval_loader:\n",
        "                text = tokenizer(text, padding=True, return_tensors='pt').to(device)\n",
        "                sentiment = sentiment.to(device)\n",
        "\n",
        "                logits, loss = eval_step(model, text, sentiment)\n",
        "\n",
        "                preds = torch.argmax(logits, axis=1)\n",
        "                y_pred += preds.cpu().numpy().tolist()\n",
        "                y_true += sentiment.cpu().numpy().tolist()\n",
        "\n",
        "                correct_count += (preds == sentiment).sum().item()\n",
        "                total_loss += loss.item()\n",
        "                pbar.update(1)\n",
        "\n",
        "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
        "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JQeDe5FdirO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(name, root, binary, epochs=25, patience=3, save=False, trial=None):\n",
        "\n",
        "    #load model and tokenizer..\n",
        "    try:\n",
        "        transformer_container = load_transformer(name, binary)\n",
        "    except ValueError:\n",
        "        logger.error(\"Invalid transformer name!\")\n",
        "        os._exit(0)\n",
        "    model = transformer_container['model']\n",
        "    model = model.to(device)\n",
        "    tokenizer = transformer_container['tokenizer']\n",
        "\n",
        "    #load batch_size and learning rate..\n",
        "    params_container = transformer_params(name)\n",
        "    batch_size = params_container['batch_size']\n",
        "    learning_rate = params_container['learning_rate']\n",
        "\n",
        "    #Hyper-paramters\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-7, 1e-4, log=True)\n",
        "    epochs = trial.suggest_int(\"epochs\", 1, 5)\n",
        "\n",
        "\n",
        "    #load train, dev and test datasets..\n",
        "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
        "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
        "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
        "\n",
        "    #Intialize optimizer..\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    #Initialize training variables..\n",
        "    best_acc = 0.0\n",
        "    best_loss = np.inf\n",
        "    stopping_step = 0\n",
        "    best_model_name = None\n",
        "\n",
        "    #test_f1\n",
        "    test_f1 = 0.0\n",
        "\n",
        "\n",
        "\n",
        "    total_train_seconds = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        start = time.time()\n",
        "        train_acc, train_loss = train_epoch(model, tokenizer, train_dataset, optimizer, batch_size)\n",
        "        end = time.time()\n",
        "        total_train_seconds += (end - start)\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
        "\n",
        "        dev_acc, dev_loss, _ = eval_epoch(model, tokenizer, dev_dataset, batch_size, 'dev')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
        "\n",
        "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, tokenizer, test_dataset,\n",
        "                                                                  batch_size, 'test')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
        "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
        "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
        "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
        "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
        "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
        "\n",
        "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
        "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
        "\n",
        "        test_f1 = test_evaluation_metrics['test_f1_score']\n",
        "        #save best model and delete previous ones...\n",
        "        '''if save:\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                phrase_type, label = root_and_binary_title(root, binary)\n",
        "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
        "                save_model(model, model_name, best_model_name)\n",
        "\n",
        "\n",
        "        # Implement early stopping here\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            stopping_step = 0\n",
        "        else:\n",
        "            stopping_step += 1\n",
        "\n",
        "        if stopping_step >= patience:\n",
        "            logger.info(\"EarlyStopping!\")\n",
        "            os._exit(1)'''\n",
        "        trial.report(test_f1, epoch)\n",
        "        if trial.should_prune():\n",
        "          raise optuna.TrialPruned()\n",
        "\n",
        "    return test_f1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_4fZIS9h0eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hpoptimize_run(trial):\n",
        "  return train('gpt2', True, False, 100, 300, False, trial)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYwav8wdiou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de3b05f40103403c80d59a745af3f1bb",
            "95e61c858685426a8f676629abe32755",
            "8bfce19628b847e4b42b9794b3ff2672",
            "c72fb0065b804e9ab6b92c45caa09658",
            "13c0bb60bab345f5af9f121fb6cd383e",
            "ea9233310410429d833082fe595051c1",
            "8e9ea058fd4d41659b60d0693e58e638",
            "a6443a0189bb4682b1b5c7038ecb501e",
            "a8dba53983ea45f7afbdb5d05348a4ab",
            "1968e68903c84d67972536c9e75acccd",
            "fe7b393a60e34941bd13df09e5235165",
            "c898868700ae4ba4aa8ee63d98063310",
            "a4e1044fc78345e1a00c4cce85a04c00",
            "4a32f8b61a56440c8b73f9a3c25e4fa5",
            "c545761bed2349659b50b75b517916f8",
            "c807b538fedb4551a7ae1e0f802cd1eb"
          ]
        },
        "outputId": "58a18a21-a2f3-48ed-c561-c2cb84afe428"
      },
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(hpoptimize_run, timeout=1200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-09-08 13:28:59,245] A new study created in memory with name: no-name-20f8303e-89a6-4b17-ace5-e3d40591231a\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de3b05f40103403c80d59a745af3f1bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8dba53983ea45f7afbdb5d05348a4ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-08 13:29:50.402 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-09-08 13:30:01.292 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-08 13:30:06.949 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|██████████| 534/534 [01:01<00:00,  8.70batch/s]\n",
            "2020-09-08 13:31:09.033 | INFO     | __main__:train:50 - epoch: 1, transformer: gpt2, train_loss: 0.0991, train_acc: 25.81\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.01batch/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "2020-09-08 13:31:11.363 | INFO     | __main__:train:53 - epoch: 1, transformer: gpt2, dev_loss: 0.0986, dev_acc: 26.16\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 29.76batch/s]\n",
            "2020-09-08 13:31:16.057 | INFO     | __main__:train:57 - epoch: 1, transformer: gpt2, test_loss: 0.0991, test_acc: 28.64\n",
            "2020-09-08 13:31:16.058 | INFO     | __main__:train:58 - epoch: 1, transformer: gpt2, test_precision: 5.73, test_recall: 20.00, test_f1_score: 8.91, test_accuracy_score: 28.64\n",
            "2020-09-08 13:31:16.060 | INFO     | __main__:train:63 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 279   0   0   0]\n",
            " [  0 633   0   0   0]\n",
            " [  0 388   0   1   0]\n",
            " [  0 510   0   0   0]\n",
            " [  0 398   0   1   0]]\n",
            "2020-09-08 13:31:16.062 | INFO     | __main__:train:66 - Total training time elapsed: 0:01:01.380940\n",
            "2020-09-08 13:31:16.063 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:01.380940\n",
            "train: 100%|██████████| 534/534 [00:59<00:00,  8.91batch/s]\n",
            "2020-09-08 13:32:16.024 | INFO     | __main__:train:50 - epoch: 2, transformer: gpt2, train_loss: 0.0983, train_acc: 26.85\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 31.05batch/s]\n",
            "2020-09-08 13:32:18.265 | INFO     | __main__:train:53 - epoch: 2, transformer: gpt2, dev_loss: 0.0985, dev_acc: 26.25\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.83batch/s]\n",
            "2020-09-08 13:32:22.795 | INFO     | __main__:train:57 - epoch: 2, transformer: gpt2, test_loss: 0.0991, test_acc: 28.78\n",
            "2020-09-08 13:32:22.796 | INFO     | __main__:train:58 - epoch: 2, transformer: gpt2, test_precision: 14.63, test_recall: 20.13, test_f1_score: 9.23, test_accuracy_score: 28.78\n",
            "2020-09-08 13:32:22.798 | INFO     | __main__:train:63 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 278   0   1   0]\n",
            " [  0 632   0   1   0]\n",
            " [  0 387   0   2   0]\n",
            " [  0 506   0   4   0]\n",
            " [  0 398   0   1   0]]\n",
            "2020-09-08 13:32:22.800 | INFO     | __main__:train:66 - Total training time elapsed: 0:02:01.339738\n",
            "2020-09-08 13:32:22.801 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.669869\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.83batch/s]\n",
            "2020-09-08 13:33:23.269 | INFO     | __main__:train:50 - epoch: 3, transformer: gpt2, train_loss: 0.0982, train_acc: 26.32\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.97batch/s]\n",
            "2020-09-08 13:33:25.515 | INFO     | __main__:train:53 - epoch: 3, transformer: gpt2, dev_loss: 0.0984, dev_acc: 26.34\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.80batch/s]\n",
            "2020-09-08 13:33:30.050 | INFO     | __main__:train:57 - epoch: 3, transformer: gpt2, test_loss: 0.0991, test_acc: 28.91\n",
            "2020-09-08 13:33:30.052 | INFO     | __main__:train:58 - epoch: 3, transformer: gpt2, test_precision: 16.42, test_recall: 20.25, test_f1_score: 9.53, test_accuracy_score: 28.91\n",
            "2020-09-08 13:33:30.054 | INFO     | __main__:train:63 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 278   0   1   0]\n",
            " [  0 631   0   2   0]\n",
            " [  0 387   0   2   0]\n",
            " [  0 502   0   8   0]\n",
            " [  0 397   0   2   0]]\n",
            "2020-09-08 13:33:30.056 | INFO     | __main__:train:66 - Total training time elapsed: 0:03:01.805823\n",
            "2020-09-08 13:33:30.058 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.601941\n",
            "train: 100%|██████████| 534/534 [00:59<00:00,  8.91batch/s]\n",
            "2020-09-08 13:34:29.974 | INFO     | __main__:train:50 - epoch: 4, transformer: gpt2, train_loss: 0.0980, train_acc: 28.09\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.84batch/s]\n",
            "2020-09-08 13:34:32.229 | INFO     | __main__:train:53 - epoch: 4, transformer: gpt2, dev_loss: 0.0984, dev_acc: 28.79\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.47batch/s]\n",
            "2020-09-08 13:34:36.814 | INFO     | __main__:train:57 - epoch: 4, transformer: gpt2, test_loss: 0.0991, test_acc: 30.81\n",
            "2020-09-08 13:34:36.815 | INFO     | __main__:train:58 - epoch: 4, transformer: gpt2, test_precision: 13.23, test_recall: 21.97, test_f1_score: 12.83, test_accuracy_score: 30.81\n",
            "2020-09-08 13:34:36.817 | INFO     | __main__:train:63 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 273   0   6   0]\n",
            " [  0 621   0  12   0]\n",
            " [  0 374   0  15   0]\n",
            " [  0 450   0  60   0]\n",
            " [  0 324   0  75   0]]\n",
            "2020-09-08 13:34:36.818 | INFO     | __main__:train:66 - Total training time elapsed: 0:04:01.719356\n",
            "2020-09-08 13:34:36.820 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.429839\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.88batch/s]\n",
            "2020-09-08 13:35:36.979 | INFO     | __main__:train:50 - epoch: 5, transformer: gpt2, train_loss: 0.0976, train_acc: 28.79\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.84batch/s]\n",
            "2020-09-08 13:35:39.235 | INFO     | __main__:train:53 - epoch: 5, transformer: gpt2, dev_loss: 0.0969, dev_acc: 35.42\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.51batch/s]\n",
            "2020-09-08 13:35:43.813 | INFO     | __main__:train:57 - epoch: 5, transformer: gpt2, test_loss: 0.0977, test_acc: 35.02\n",
            "2020-09-08 13:35:43.815 | INFO     | __main__:train:58 - epoch: 5, transformer: gpt2, test_precision: 13.94, test_recall: 26.95, test_f1_score: 18.36, test_accuracy_score: 35.02\n",
            "2020-09-08 13:35:43.816 | INFO     | __main__:train:63 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 208   0  71   0]\n",
            " [  0 446   0 187   0]\n",
            " [  0 242   0 147   0]\n",
            " [  0 182   0 328   0]\n",
            " [  0  83   0 316   0]]\n",
            "2020-09-08 13:35:43.821 | INFO     | __main__:train:66 - Total training time elapsed: 0:05:01.876070\n",
            "2020-09-08 13:35:43.823 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.375214\n",
            "[I 2020-09-08 13:35:43,835] Trial 0 finished with value: 0.18359909698281568 and parameters: {'batch_size': 16, 'lr': 5.620296515951129e-07, 'epochs': 5}. Best is trial 0 with value: 0.18359909698281568.\n",
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-08 13:35:54.107 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
            "2020-09-08 13:36:02.329 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-08 13:36:08.061 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|██████████| 1068/1068 [01:26<00:00, 12.28batch/s]\n",
            "2020-09-08 13:37:35.752 | INFO     | __main__:train:50 - epoch: 1, transformer: gpt2, train_loss: 0.1989, train_acc: 26.95\n",
            "dev: 100%|██████████| 138/138 [00:02<00:00, 46.80batch/s]\n",
            "2020-09-08 13:37:38.719 | INFO     | __main__:train:53 - epoch: 1, transformer: gpt2, dev_loss: 0.1988, dev_acc: 25.34\n",
            "test: 100%|██████████| 277/277 [00:05<00:00, 47.01batch/s]\n",
            "2020-09-08 13:37:44.632 | INFO     | __main__:train:57 - epoch: 1, transformer: gpt2, test_loss: 0.1995, test_acc: 23.08\n",
            "2020-09-08 13:37:44.634 | INFO     | __main__:train:58 - epoch: 1, transformer: gpt2, test_precision: 4.62, test_recall: 20.00, test_f1_score: 7.50, test_accuracy_score: 23.08\n",
            "2020-09-08 13:37:44.635 | INFO     | __main__:train:63 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0   0   0 279   0]\n",
            " [  0   0   0 633   0]\n",
            " [  0   0   0 389   0]\n",
            " [  0   0   0 510   0]\n",
            " [  0   0   0 399   0]]\n",
            "2020-09-08 13:37:44.638 | INFO     | __main__:train:66 - Total training time elapsed: 0:01:26.990197\n",
            "2020-09-08 13:37:44.639 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:26.990197\n",
            "train: 100%|██████████| 1068/1068 [01:25<00:00, 12.42batch/s]\n",
            "2020-09-08 13:39:10.641 | INFO     | __main__:train:50 - epoch: 2, transformer: gpt2, train_loss: 0.1971, train_acc: 26.94\n",
            "dev: 100%|██████████| 138/138 [00:02<00:00, 47.61batch/s]\n",
            "2020-09-08 13:39:13.557 | INFO     | __main__:train:53 - epoch: 2, transformer: gpt2, dev_loss: 0.1980, dev_acc: 25.34\n",
            "test: 100%|██████████| 277/277 [00:06<00:00, 46.06batch/s]\n",
            "2020-09-08 13:39:19.593 | INFO     | __main__:train:57 - epoch: 2, transformer: gpt2, test_loss: 0.1984, test_acc: 23.08\n",
            "2020-09-08 13:39:19.595 | INFO     | __main__:train:58 - epoch: 2, transformer: gpt2, test_precision: 4.62, test_recall: 20.00, test_f1_score: 7.50, test_accuracy_score: 23.08\n",
            "2020-09-08 13:39:19.598 | INFO     | __main__:train:63 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0   0   0 279   0]\n",
            " [  0   0   0 633   0]\n",
            " [  0   1   0 388   0]\n",
            " [  0   0   0 510   0]\n",
            " [  0   0   0 399   0]]\n",
            "2020-09-08 13:39:19.599 | INFO     | __main__:train:66 - Total training time elapsed: 0:02:52.989476\n",
            "2020-09-08 13:39:19.601 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:26.494738\n",
            "train: 100%|██████████| 1068/1068 [01:25<00:00, 12.42batch/s]\n",
            "2020-09-08 13:40:45.582 | INFO     | __main__:train:50 - epoch: 3, transformer: gpt2, train_loss: 0.1966, train_acc: 27.31\n",
            "dev: 100%|██████████| 138/138 [00:02<00:00, 48.35batch/s]\n",
            "2020-09-08 13:40:48.455 | INFO     | __main__:train:53 - epoch: 3, transformer: gpt2, dev_loss: 0.1976, dev_acc: 26.16\n",
            "test: 100%|██████████| 277/277 [00:06<00:00, 44.98batch/s]\n",
            "2020-09-08 13:40:54.639 | INFO     | __main__:train:57 - epoch: 3, transformer: gpt2, test_loss: 0.1979, test_acc: 23.89\n",
            "2020-09-08 13:40:54.640 | INFO     | __main__:train:58 - epoch: 3, transformer: gpt2, test_precision: 10.89, test_recall: 20.36, test_f1_score: 9.85, test_accuracy_score: 23.89\n",
            "2020-09-08 13:40:54.642 | INFO     | __main__:train:63 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  18   0 261   0]\n",
            " [  0  46   0 587   0]\n",
            " [  0  37   0 352   0]\n",
            " [  0  28   0 482   0]\n",
            " [  0  19   0 380   0]]\n",
            "2020-09-08 13:40:54.644 | INFO     | __main__:train:66 - Total training time elapsed: 0:04:18.966058\n",
            "2020-09-08 13:40:54.646 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:26.322019\n",
            "train: 100%|██████████| 1068/1068 [01:25<00:00, 12.48batch/s]\n",
            "2020-09-08 13:42:20.214 | INFO     | __main__:train:50 - epoch: 4, transformer: gpt2, train_loss: 0.1965, train_acc: 26.56\n",
            "dev: 100%|██████████| 138/138 [00:02<00:00, 46.95batch/s]\n",
            "2020-09-08 13:42:23.172 | INFO     | __main__:train:53 - epoch: 4, transformer: gpt2, dev_loss: 0.1974, dev_acc: 26.61\n",
            "test: 100%|██████████| 277/277 [00:05<00:00, 46.93batch/s]\n",
            "2020-09-08 13:42:29.097 | INFO     | __main__:train:57 - epoch: 4, transformer: gpt2, test_loss: 0.1977, test_acc: 27.96\n",
            "2020-09-08 13:42:29.098 | INFO     | __main__:train:58 - epoch: 4, transformer: gpt2, test_precision: 11.39, test_recall: 21.96, test_f1_score: 14.77, test_accuracy_score: 27.96\n",
            "2020-09-08 13:42:29.100 | INFO     | __main__:train:63 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 126   0 153   0]\n",
            " [  0 298   0 335   0]\n",
            " [  0 179   0 210   0]\n",
            " [  0 190   0 320   0]\n",
            " [  0 142   0 257   0]]\n",
            "2020-09-08 13:42:29.102 | INFO     | __main__:train:66 - Total training time elapsed: 0:05:44.531791\n",
            "2020-09-08 13:42:29.103 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:26.132948\n",
            "[I 2020-09-08 13:42:29,114] Trial 1 finished with value: 0.14772909163665465 and parameters: {'batch_size': 8, 'lr': 2.017042190837889e-07, 'epochs': 4}. Best is trial 0 with value: 0.18359909698281568.\n",
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-08 13:42:39.409 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
            "2020-09-08 13:42:47.394 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-08 13:42:53.315 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|██████████| 534/534 [01:01<00:00,  8.73batch/s]\n",
            "2020-09-08 13:43:55.209 | INFO     | __main__:train:50 - epoch: 1, transformer: gpt2, train_loss: 0.1003, train_acc: 24.59\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.04batch/s]\n",
            "2020-09-08 13:43:57.525 | INFO     | __main__:train:53 - epoch: 1, transformer: gpt2, dev_loss: 0.1010, dev_acc: 25.25\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 29.64batch/s]\n",
            "2020-09-08 13:44:02.237 | INFO     | __main__:train:57 - epoch: 1, transformer: gpt2, test_loss: 0.1015, test_acc: 22.94\n",
            "2020-09-08 13:44:02.239 | INFO     | __main__:train:58 - epoch: 1, transformer: gpt2, test_precision: 7.60, test_recall: 19.92, test_f1_score: 7.75, test_accuracy_score: 22.94\n",
            "2020-09-08 13:44:02.241 | INFO     | __main__:train:63 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0   0   0 275   4]\n",
            " [  0   0   0 629   4]\n",
            " [  0   0   0 386   3]\n",
            " [  0   0   0 504   6]\n",
            " [  0   0   0 396   3]]\n",
            "2020-09-08 13:44:02.243 | INFO     | __main__:train:66 - Total training time elapsed: 0:01:01.175416\n",
            "2020-09-08 13:44:02.245 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:01.175416\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.88batch/s]\n",
            "2020-09-08 13:45:02.423 | INFO     | __main__:train:50 - epoch: 2, transformer: gpt2, train_loss: 0.0997, train_acc: 25.91\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 31.14batch/s]\n",
            "2020-09-08 13:45:04.657 | INFO     | __main__:train:53 - epoch: 2, transformer: gpt2, dev_loss: 0.1004, dev_acc: 25.34\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.57batch/s]\n",
            "2020-09-08 13:45:09.226 | INFO     | __main__:train:57 - epoch: 2, transformer: gpt2, test_loss: 0.1010, test_acc: 23.08\n",
            "2020-09-08 13:45:09.227 | INFO     | __main__:train:58 - epoch: 2, transformer: gpt2, test_precision: 4.62, test_recall: 20.00, test_f1_score: 7.50, test_accuracy_score: 23.08\n",
            "2020-09-08 13:45:09.229 | INFO     | __main__:train:63 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0   0   0 279   0]\n",
            " [  0   0   0 633   0]\n",
            " [  0   0   0 389   0]\n",
            " [  0   0   0 510   0]\n",
            " [  0   0   0 399   0]]\n",
            "2020-09-08 13:45:09.230 | INFO     | __main__:train:66 - Total training time elapsed: 0:02:01.351516\n",
            "2020-09-08 13:45:09.232 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.675758\n",
            "[I 2020-09-08 13:45:09,249] Trial 2 finished with value: 0.075 and parameters: {'batch_size': 16, 'lr': 1.0354470159355893e-07, 'epochs': 2}. Best is trial 0 with value: 0.18359909698281568.\n",
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-08 13:45:19.626 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
            "2020-09-08 13:45:27.654 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-08 13:45:33.623 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|██████████| 534/534 [01:01<00:00,  8.74batch/s]\n",
            "2020-09-08 13:46:35.412 | INFO     | __main__:train:50 - epoch: 1, transformer: gpt2, train_loss: 0.1012, train_acc: 21.77\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.22batch/s]\n",
            "2020-09-08 13:46:37.714 | INFO     | __main__:train:53 - epoch: 1, transformer: gpt2, dev_loss: 0.1009, dev_acc: 21.44\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 29.65batch/s]\n",
            "2020-09-08 13:46:42.426 | INFO     | __main__:train:57 - epoch: 1, transformer: gpt2, test_loss: 0.1013, test_acc: 18.87\n",
            "2020-09-08 13:46:42.427 | INFO     | __main__:train:58 - epoch: 1, transformer: gpt2, test_precision: 10.97, test_recall: 20.63, test_f1_score: 8.25, test_accuracy_score: 18.87\n",
            "2020-09-08 13:46:42.429 | INFO     | __main__:train:63 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  15 264   0   0]\n",
            " [  0  41 592   0   0]\n",
            " [  0  13 376   0   0]\n",
            " [  0  24 486   0   0]\n",
            " [  0  18 381   0   0]]\n",
            "2020-09-08 13:46:42.431 | INFO     | __main__:train:66 - Total training time elapsed: 0:01:01.079051\n",
            "2020-09-08 13:46:42.433 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:01.079051\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.87batch/s]\n",
            "2020-09-08 13:47:42.651 | INFO     | __main__:train:50 - epoch: 2, transformer: gpt2, train_loss: 0.0998, train_acc: 24.25\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.86batch/s]\n",
            "2020-09-08 13:47:44.906 | INFO     | __main__:train:53 - epoch: 2, transformer: gpt2, dev_loss: 0.1001, dev_acc: 26.43\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.40batch/s]\n",
            "2020-09-08 13:47:49.500 | INFO     | __main__:train:57 - epoch: 2, transformer: gpt2, test_loss: 0.1006, test_acc: 25.75\n",
            "2020-09-08 13:47:49.501 | INFO     | __main__:train:58 - epoch: 2, transformer: gpt2, test_precision: 22.89, test_recall: 20.73, test_f1_score: 13.21, test_accuracy_score: 25.75\n",
            "2020-09-08 13:47:49.504 | INFO     | __main__:train:63 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 200  79   0   0]\n",
            " [  0 429 203   1   0]\n",
            " [  0 251 138   0   0]\n",
            " [  0 312 196   2   0]\n",
            " [  0 251 148   0   0]]\n",
            "2020-09-08 13:47:49.506 | INFO     | __main__:train:66 - Total training time elapsed: 0:02:01.295181\n",
            "2020-09-08 13:47:49.507 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.647590\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.85batch/s]\n",
            "2020-09-08 13:48:49.836 | INFO     | __main__:train:50 - epoch: 3, transformer: gpt2, train_loss: 0.0991, train_acc: 25.84\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 31.24batch/s]\n",
            "2020-09-08 13:48:52.062 | INFO     | __main__:train:53 - epoch: 3, transformer: gpt2, dev_loss: 0.0996, dev_acc: 27.52\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.09batch/s]\n",
            "2020-09-08 13:48:56.703 | INFO     | __main__:train:57 - epoch: 3, transformer: gpt2, test_loss: 0.1002, test_acc: 27.33\n",
            "2020-09-08 13:48:56.704 | INFO     | __main__:train:58 - epoch: 3, transformer: gpt2, test_precision: 10.57, test_recall: 20.55, test_f1_score: 13.92, test_accuracy_score: 27.33\n",
            "2020-09-08 13:48:56.706 | INFO     | __main__:train:63 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 175   0 104   0]\n",
            " [  0 412   0 221   0]\n",
            " [  0 237   0 152   0]\n",
            " [  0 318   0 192   0]\n",
            " [  0 212   0 187   0]]\n",
            "2020-09-08 13:48:56.709 | INFO     | __main__:train:66 - Total training time elapsed: 0:03:01.621257\n",
            "2020-09-08 13:48:56.711 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.540419\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.83batch/s]\n",
            "2020-09-08 13:49:57.186 | INFO     | __main__:train:50 - epoch: 4, transformer: gpt2, train_loss: 0.0987, train_acc: 26.49\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 31.12batch/s]\n",
            "2020-09-08 13:49:59.421 | INFO     | __main__:train:53 - epoch: 4, transformer: gpt2, dev_loss: 0.0992, dev_acc: 25.79\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.68batch/s]\n",
            "2020-09-08 13:50:03.976 | INFO     | __main__:train:57 - epoch: 4, transformer: gpt2, test_loss: 0.0999, test_acc: 24.48\n",
            "2020-09-08 13:50:03.977 | INFO     | __main__:train:58 - epoch: 4, transformer: gpt2, test_precision: 11.17, test_recall: 20.39, test_f1_score: 11.73, test_accuracy_score: 24.48\n",
            "2020-09-08 13:50:03.979 | INFO     | __main__:train:63 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  40   0 239   0]\n",
            " [  0 108   0 525   0]\n",
            " [  0  54   0 335   0]\n",
            " [  0  77   0 433   0]\n",
            " [  0  50   0 349   0]]\n",
            "2020-09-08 13:50:03.980 | INFO     | __main__:train:66 - Total training time elapsed: 0:04:02.094669\n",
            "2020-09-08 13:50:03.982 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.523667\n",
            "train: 100%|██████████| 534/534 [01:00<00:00,  8.88batch/s]\n",
            "2020-09-08 13:51:04.093 | INFO     | __main__:train:50 - epoch: 5, transformer: gpt2, train_loss: 0.0984, train_acc: 26.70\n",
            "dev: 100%|██████████| 69/69 [00:02<00:00, 30.92batch/s]\n",
            "2020-09-08 13:51:06.344 | INFO     | __main__:train:53 - epoch: 5, transformer: gpt2, dev_loss: 0.0990, dev_acc: 25.98\n",
            "test: 100%|██████████| 139/139 [00:04<00:00, 30.80batch/s]\n",
            "2020-09-08 13:51:10.879 | INFO     | __main__:train:57 - epoch: 5, transformer: gpt2, test_loss: 0.0997, test_acc: 23.76\n",
            "2020-09-08 13:51:10.880 | INFO     | __main__:train:58 - epoch: 5, transformer: gpt2, test_precision: 11.59, test_recall: 20.33, test_f1_score: 9.35, test_accuracy_score: 23.76\n",
            "2020-09-08 13:51:10.882 | INFO     | __main__:train:63 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  10   0 269   0]\n",
            " [  0  34   0 599   0]\n",
            " [  0  19   0 370   0]\n",
            " [  0  19   0 491   0]\n",
            " [  0  16   0 383   0]]\n",
            "2020-09-08 13:51:10.885 | INFO     | __main__:train:66 - Total training time elapsed: 0:05:02.202836\n",
            "2020-09-08 13:51:10.886 | INFO     | __main__:train:67 - Mean time per train epoch: 0:01:00.440567\n",
            "[I 2020-09-08 13:51:10,906] Trial 3 finished with value: 0.09350930409948024 and parameters: {'batch_size': 16, 'lr': 1.6690207659436496e-07, 'epochs': 5}. Best is trial 0 with value: 0.18359909698281568.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kh6au3uieR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(study.best_trial)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ12BnAei0FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRZpL_cidimc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz3muFrUdikk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjd7B--JdiiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXqhawGkdigP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}