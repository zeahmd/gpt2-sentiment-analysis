{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Last Token GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdHVQrqyDB50",
        "colab_type": "text"
      },
      "source": [
        "# Memory Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58HaeA6CsM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "44770056-b585-4ebd-d03a-6ec6a1fec7fd"
      },
      "source": [
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================== Memory Information ========================================\n",
            "Total: 25.51GB\n",
            "Available: 24.60GB\n",
            "Used: 588.65MB\n",
            "Percentage: 3.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgVfBlvZDEja",
        "colab_type": "text"
      },
      "source": [
        "# GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxlkxvkrCyin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ece34295-1702-47c6-cde0-df49de745a6d"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep 15 08:10:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6WR5Uaa6RQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "outputId": "ace5c171-e62e-428e-8fd2-1a946333adeb"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
            "Collecting loguru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/f7/85704c74dd5b616a528aa724d359033f4dbec896b604cf12b65c4f9badb1/loguru-0.5.2-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 3)) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.3MB/s \n",
            "\u001b[?25hCollecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
            "Collecting contextvars==2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pytreebank, sacremoses, contextvars\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp36-none-any.whl size=37070 sha256=2d0a33537f49c2e205c0775be8a3f8de057931b3fe678324cf18fe8657857189\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=9ca26d5bc88e6a5c3d5ca6d31d8625145b50f0c3462e7fe52e75509896d014b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=0d572c7596b5815c5ab41af670e3ede9d4030ad977d459af0d820a90ea791b70\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built pytreebank sacremoses contextvars\n",
            "Installing collected packages: pytreebank, tokenizers, sentencepiece, sacremoses, transformers, immutables, contextvars, aiocontextvars, loguru\n",
            "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 immutables-0.14 loguru-0.5.2 pytreebank-0.2.7 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDODoaWC6KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
        "import torch\n",
        "from dataset import SSTDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import transformer_params\n",
        "from utils import evaluation_metrics, save_model, root_and_binary_title\n",
        "from math import ceil\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5IZjSzQNpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPT2ForSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, num_labels):\n",
        "    super(GPT2ForSequenceClassification, self).__init__()\n",
        "    self.model = GPT2Model.from_pretrained('gpt2',\n",
        "                                       config=GPT2Config.from_pretrained('gpt2'))\n",
        "    self.dropout = torch.nn.Dropout(p=0.1)\n",
        "    self.fc_layer = torch.nn.Linear(in_features=768, out_features=768)\n",
        "    self.tanh = torch.nn.GELU()\n",
        "    self.out_layer = torch.nn.Linear(in_features=768, out_features=num_labels)\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    gpt_last_layer = self.model(input_ids, attention_mask=attention_mask)[0]\n",
        "    #[batch_size, seq_len, embedding_size(channels)] = [*, *, 768]\n",
        "\n",
        "    gpt_first_token = gpt_last_layer[:, gpt_last_layer.shape[1]-1]\n",
        "    #gpt_first_token = gpt_last_layer[:, 0] #experiment failed for first token\n",
        "    #[batch_size, embedding_size(channels)] = [*, 1024]\n",
        "\n",
        "    fc_layer_out = self.fc_layer(gpt_first_token)\n",
        "    fc_layer_out = self.tanh(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, 1024]\n",
        "\n",
        "    fc_layer_out = self.dropout(fc_layer_out)\n",
        "    logits = self.out_layer(fc_layer_out)\n",
        "    #[batch_size, embedding_size(channels)] = [*, num_labels]\n",
        "    \n",
        "    loss = self.criterion(logits, labels)\n",
        "                                   \n",
        "    return logits, loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4_cQpe_c4BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_transformer(name, binary):\n",
        "  num_classes = 5\n",
        "  if binary:\n",
        "    num_classes = 2\n",
        "  model = GPT2ForSequenceClassification(num_classes)\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "  tokenizer.add_special_tokens({'pad_token': '.'})\n",
        "\n",
        "  return {'model': model,\n",
        "          'tokenizer': tokenizer}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq-C2k3kcylS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_special_tokens(text):\n",
        "  text = list(text)\n",
        "  for i in range(len(text)):\n",
        "    text[i] = '<|endoftext|> ' + text[i] + ' <|endoftext|>'\n",
        "  return tuple(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFaW79Rdi0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSgyPvydj0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, inputs, labels, optimizer):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7984ypaMdixv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_step(model, inputs, labels):\n",
        "    logits, loss = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
        "\n",
        "    return logits, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHHlscCdivT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, tokenizer, train_dataset, optimizer, batch_size):\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    with tqdm(total=ceil(len(train_dataset)/batch_size), desc='train', unit='batch') as pbar:\n",
        "        for text, sentiment in train_loader:\n",
        "            text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
        "            sentiment = sentiment.to(device)\n",
        "\n",
        "            logits, loss = train_step(model, text, sentiment, optimizer)\n",
        "\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "            correct_count += (preds == sentiment).sum().item()\n",
        "            total_loss += loss.item()\n",
        "            pbar.update(1)\n",
        "\n",
        "    return correct_count / len(train_dataset), total_loss / len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPxnxXajditk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, tokenizer, eval_dataset, batch_size, split):\n",
        "    eval_loader = DataLoader(dataset=eval_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "\n",
        "    correct_count = 0\n",
        "    total_loss = 0\n",
        "    y_pred = list()\n",
        "    y_true = list()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=ceil(len(eval_dataset)/batch_size), desc=split, unit='batch') as pbar:\n",
        "            for text, sentiment in eval_loader:\n",
        "                text = tokenizer(add_special_tokens(text), padding=True, return_tensors='pt').to(device)\n",
        "                sentiment = sentiment.to(device)\n",
        "\n",
        "                logits, loss = eval_step(model, text, sentiment)\n",
        "\n",
        "                preds = torch.argmax(logits, axis=1)\n",
        "                y_pred += preds.cpu().numpy().tolist()\n",
        "                y_true += sentiment.cpu().numpy().tolist()\n",
        "\n",
        "                correct_count += (preds == sentiment).sum().item()\n",
        "                total_loss += loss.item()\n",
        "                pbar.update(1)\n",
        "\n",
        "    metrics_score = evaluation_metrics(y_true, y_pred, split=split)\n",
        "    return correct_count / len(eval_dataset), total_loss / len(eval_dataset), metrics_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JQeDe5FdirO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(name, root, binary, epochs=25, patience=3, save=False):\n",
        "\n",
        "    #load model and tokenizer..\n",
        "    try:\n",
        "        transformer_container = load_transformer(name, binary)\n",
        "    except ValueError:\n",
        "        logger.error(\"Invalid transformer name!\")\n",
        "        os._exit(0)\n",
        "    model = transformer_container['model']\n",
        "    model = model.to(device)\n",
        "    tokenizer = transformer_container['tokenizer']\n",
        "\n",
        "    #load batch_size and learning rate..\n",
        "    params_container = transformer_params(name)\n",
        "    batch_size = params_container['batch_size']\n",
        "    learning_rate = params_container['learning_rate']\n",
        "\n",
        "    #load train, dev and test datasets..\n",
        "    train_dataset = SSTDataset(root=root, binary=binary, split='train')\n",
        "    dev_dataset = SSTDataset(root=root, binary=binary, split='dev')\n",
        "    test_dataset = SSTDataset(root=root, binary=binary, split='test')\n",
        "\n",
        "    #Intialize optimizer..\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    #Initialize training variables..\n",
        "    best_acc = 0.0\n",
        "    best_loss = np.inf\n",
        "    stopping_step = 0\n",
        "    best_model_name = None\n",
        "\n",
        "    total_train_seconds = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        start = time.time()\n",
        "        train_acc, train_loss = train_epoch(model, tokenizer, train_dataset, optimizer, batch_size)\n",
        "        end = time.time()\n",
        "        total_train_seconds += (end - start)\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, train_loss: {train_loss:.4f}, train_acc: {train_acc*100:.2f}\")\n",
        "\n",
        "        dev_acc, dev_loss, _ = eval_epoch(model, tokenizer, dev_dataset, batch_size, 'dev')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, dev_loss: {dev_loss:.4f}, dev_acc: {dev_acc*100:.2f}\")\n",
        "\n",
        "        test_acc, test_loss, test_evaluation_metrics = eval_epoch(model, tokenizer, test_dataset,\n",
        "                                                                  batch_size, 'test')\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_loss: {test_loss:.4f}, test_acc: {test_acc*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, \"\n",
        "                    f\"test_precision: {test_evaluation_metrics['test_precision']*100:.2f}, \"\n",
        "                    f\"test_recall: {test_evaluation_metrics['test_recall']*100:.2f}, \"\n",
        "                    f\"test_f1_score: {test_evaluation_metrics['test_f1_score']*100:.2f}, \"\n",
        "                    f\"test_accuracy_score: {test_evaluation_metrics['test_accuracy']*100:.2f}\")\n",
        "        logger.info(f\"epoch: {epoch+1}, transformer: {name}, test_confusion_matrix: \\n\"\n",
        "                    f\"{test_evaluation_metrics['test_confusion_matrix']}\")\n",
        "\n",
        "        logger.info(f\"Total training time elapsed: {timedelta(seconds=total_train_seconds)}\")\n",
        "        logger.info(f\"Mean time per train epoch: {timedelta(seconds=total_train_seconds/(epoch+1))}\")\n",
        "\n",
        "        #save best model and delete previous ones...\n",
        "        if save:\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                phrase_type, label = root_and_binary_title(root, binary)\n",
        "                model_name = \"{}_{}_{}_{}.pickle\".format(name, phrase_type, label, epoch)\n",
        "                save_model(model, model_name, best_model_name)\n",
        "\n",
        "\n",
        "        # Implement early stopping here\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            stopping_step = 0\n",
        "        else:\n",
        "            stopping_step += 1\n",
        "\n",
        "        if stopping_step >= patience:\n",
        "            logger.info(\"EarlyStopping!\")\n",
        "            os._exit(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYwav8wdiou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13384c81-57fa-47a1-bb2e-0e3c9332c688"
      },
      "source": [
        "train('gpt2', True, False, 30, 300, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2020-09-15 08:23:09.879 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: train!\n",
            "2020-09-15 08:23:16.210 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: dev!\n",
            "2020-09-15 08:23:20.845 | INFO     | dataset:__init__:17 - Preparing dataset config root: True, binary: False, split: test!\n",
            "train: 100%|██████████| 267/267 [00:52<00:00,  5.13batch/s]\n",
            "2020-09-15 08:24:13.462 | INFO     | __main__:train:39 - epoch: 1, transformer: gpt2, train_loss: 0.0506, train_acc: 26.03\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.63batch/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "2020-09-15 08:24:15.578 | INFO     | __main__:train:42 - epoch: 1, transformer: gpt2, dev_loss: 0.0501, dev_acc: 25.70\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 15.80batch/s]\n",
            "2020-09-15 08:24:20.027 | INFO     | __main__:train:46 - epoch: 1, transformer: gpt2, test_loss: 0.0499, test_acc: 23.35\n",
            "2020-09-15 08:24:20.028 | INFO     | __main__:train:47 - epoch: 1, transformer: gpt2, test_precision: 11.44, test_recall: 20.12, test_f1_score: 8.38, test_accuracy_score: 23.35\n",
            "2020-09-15 08:24:20.029 | INFO     | __main__:train:52 - epoch: 1, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0   7   0 272   0]\n",
            " [  0  15   0 618   0]\n",
            " [  0   8   0 381   0]\n",
            " [  0   9   0 501   0]\n",
            " [  0   5   0 394   0]]\n",
            "2020-09-15 08:24:20.030 | INFO     | __main__:train:55 - Total training time elapsed: 0:00:52.097423\n",
            "2020-09-15 08:24:20.030 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:52.097423\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.20batch/s]\n",
            "2020-09-15 08:25:11.383 | INFO     | __main__:train:39 - epoch: 2, transformer: gpt2, train_loss: 0.0490, train_acc: 28.42\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.77batch/s]\n",
            "2020-09-15 08:25:13.483 | INFO     | __main__:train:42 - epoch: 2, transformer: gpt2, dev_loss: 0.0492, dev_acc: 27.43\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.15batch/s]\n",
            "2020-09-15 08:25:17.836 | INFO     | __main__:train:46 - epoch: 2, transformer: gpt2, test_loss: 0.0494, test_acc: 26.65\n",
            "2020-09-15 08:25:17.837 | INFO     | __main__:train:47 - epoch: 2, transformer: gpt2, test_precision: 15.27, test_recall: 22.44, test_f1_score: 12.21, test_accuracy_score: 26.65\n",
            "2020-09-15 08:25:17.838 | INFO     | __main__:train:52 - epoch: 2, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0  42   0 237   0]\n",
            " [  0  87   0 546   0]\n",
            " [  0  25   0 364   0]\n",
            " [  0   8   0 502   0]\n",
            " [  0   6   0 393   0]]\n",
            "2020-09-15 08:25:17.839 | INFO     | __main__:train:55 - Total training time elapsed: 0:01:43.449089\n",
            "2020-09-15 08:25:17.840 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.724544\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.20batch/s]\n",
            "2020-09-15 08:26:09.233 | INFO     | __main__:train:39 - epoch: 3, transformer: gpt2, train_loss: 0.0424, train_acc: 40.62\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.81batch/s]\n",
            "2020-09-15 08:26:11.328 | INFO     | __main__:train:42 - epoch: 3, transformer: gpt2, dev_loss: 0.0376, dev_acc: 47.05\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.21batch/s]\n",
            "2020-09-15 08:26:15.665 | INFO     | __main__:train:46 - epoch: 3, transformer: gpt2, test_loss: 0.0360, test_acc: 49.91\n",
            "2020-09-15 08:26:15.666 | INFO     | __main__:train:47 - epoch: 3, transformer: gpt2, test_precision: 38.96, test_recall: 41.92, test_f1_score: 36.19, test_accuracy_score: 49.91\n",
            "2020-09-15 08:26:15.667 | INFO     | __main__:train:52 - epoch: 3, transformer: gpt2, test_confusion_matrix: \n",
            "[[  0 254   4  21   0]\n",
            " [  0 538   9  83   3]\n",
            " [  0 229  12 136  12]\n",
            " [  0  60   6 313 131]\n",
            " [  0  11   0 148 240]]\n",
            "2020-09-15 08:26:15.667 | INFO     | __main__:train:55 - Total training time elapsed: 0:02:34.841094\n",
            "2020-09-15 08:26:15.668 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.613698\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.20batch/s]\n",
            "2020-09-15 08:27:07.040 | INFO     | __main__:train:39 - epoch: 4, transformer: gpt2, train_loss: 0.0366, train_acc: 47.39\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.40batch/s]\n",
            "2020-09-15 08:27:09.186 | INFO     | __main__:train:42 - epoch: 4, transformer: gpt2, dev_loss: 0.0383, dev_acc: 47.14\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.28batch/s]\n",
            "2020-09-15 08:27:13.502 | INFO     | __main__:train:46 - epoch: 4, transformer: gpt2, test_loss: 0.0352, test_acc: 50.72\n",
            "2020-09-15 08:27:13.503 | INFO     | __main__:train:47 - epoch: 4, transformer: gpt2, test_precision: 55.95, test_recall: 44.39, test_f1_score: 42.39, test_accuracy_score: 50.72\n",
            "2020-09-15 08:27:13.504 | INFO     | __main__:train:52 - epoch: 4, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 20 214  18  27   0]\n",
            " [  6 431  78 115   3]\n",
            " [  0 137  64 180   8]\n",
            " [  0  17  21 397  75]\n",
            " [  0   2   7 181 209]]\n",
            "2020-09-15 08:27:13.504 | INFO     | __main__:train:55 - Total training time elapsed: 0:03:26.212850\n",
            "2020-09-15 08:27:13.505 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.553212\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.20batch/s]\n",
            "2020-09-15 08:28:04.891 | INFO     | __main__:train:39 - epoch: 5, transformer: gpt2, train_loss: 0.0340, train_acc: 51.26\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.71batch/s]\n",
            "2020-09-15 08:28:06.998 | INFO     | __main__:train:42 - epoch: 5, transformer: gpt2, dev_loss: 0.0359, dev_acc: 50.86\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 15.94batch/s]\n",
            "2020-09-15 08:28:11.406 | INFO     | __main__:train:46 - epoch: 5, transformer: gpt2, test_loss: 0.0331, test_acc: 54.16\n",
            "2020-09-15 08:28:11.407 | INFO     | __main__:train:47 - epoch: 5, transformer: gpt2, test_precision: 54.41, test_recall: 50.33, test_f1_score: 50.83, test_accuracy_score: 54.16\n",
            "2020-09-15 08:28:11.408 | INFO     | __main__:train:52 - epoch: 5, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 92 160  13  14   0]\n",
            " [ 58 440  73  58   4]\n",
            " [  4 170  99 106  10]\n",
            " [  0  29  42 333 106]\n",
            " [  0   4  15 147 233]]\n",
            "2020-09-15 08:28:11.409 | INFO     | __main__:train:55 - Total training time elapsed: 0:04:17.597445\n",
            "2020-09-15 08:28:11.409 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.519489\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.19batch/s]\n",
            "2020-09-15 08:29:02.877 | INFO     | __main__:train:39 - epoch: 6, transformer: gpt2, train_loss: 0.0319, train_acc: 54.44\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.59batch/s]\n",
            "2020-09-15 08:29:04.998 | INFO     | __main__:train:42 - epoch: 6, transformer: gpt2, dev_loss: 0.0366, dev_acc: 50.95\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.20batch/s]\n",
            "2020-09-15 08:29:09.339 | INFO     | __main__:train:46 - epoch: 6, transformer: gpt2, test_loss: 0.0333, test_acc: 53.98\n",
            "2020-09-15 08:29:09.340 | INFO     | __main__:train:47 - epoch: 6, transformer: gpt2, test_precision: 53.04, test_recall: 50.73, test_f1_score: 50.65, test_accuracy_score: 53.98\n",
            "2020-09-15 08:29:09.341 | INFO     | __main__:train:52 - epoch: 6, transformer: gpt2, test_confusion_matrix: \n",
            "[[105 146  15  12   1]\n",
            " [ 63 428  78  58   6]\n",
            " [  7 163  78 127  14]\n",
            " [  2  27  29 321 131]\n",
            " [  0   5  12 121 261]]\n",
            "2020-09-15 08:29:09.342 | INFO     | __main__:train:55 - Total training time elapsed: 0:05:09.064475\n",
            "2020-09-15 08:29:09.342 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.510746\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.22batch/s]\n",
            "2020-09-15 08:30:00.541 | INFO     | __main__:train:39 - epoch: 7, transformer: gpt2, train_loss: 0.0299, train_acc: 58.17\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.34batch/s]\n",
            "2020-09-15 08:30:02.697 | INFO     | __main__:train:42 - epoch: 7, transformer: gpt2, dev_loss: 0.0378, dev_acc: 50.05\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.06batch/s]\n",
            "2020-09-15 08:30:07.075 | INFO     | __main__:train:46 - epoch: 7, transformer: gpt2, test_loss: 0.0348, test_acc: 53.53\n",
            "2020-09-15 08:30:07.076 | INFO     | __main__:train:47 - epoch: 7, transformer: gpt2, test_precision: 53.28, test_recall: 51.56, test_f1_score: 51.88, test_accuracy_score: 53.53\n",
            "2020-09-15 08:30:07.076 | INFO     | __main__:train:52 - epoch: 7, transformer: gpt2, test_confusion_matrix: \n",
            "[[123 117  22  15   2]\n",
            " [ 76 377 109  63   8]\n",
            " [  8 130 109 129  13]\n",
            " [  1  18  45 325 121]\n",
            " [  0   3  11 136 249]]\n",
            "2020-09-15 08:30:07.077 | INFO     | __main__:train:55 - Total training time elapsed: 0:06:00.263033\n",
            "2020-09-15 08:30:07.078 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.466148\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.22batch/s]\n",
            "2020-09-15 08:30:58.239 | INFO     | __main__:train:39 - epoch: 8, transformer: gpt2, train_loss: 0.0282, train_acc: 60.00\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.67batch/s]\n",
            "2020-09-15 08:31:00.351 | INFO     | __main__:train:42 - epoch: 8, transformer: gpt2, dev_loss: 0.0363, dev_acc: 51.23\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.17batch/s]\n",
            "2020-09-15 08:31:04.696 | INFO     | __main__:train:46 - epoch: 8, transformer: gpt2, test_loss: 0.0341, test_acc: 53.57\n",
            "2020-09-15 08:31:04.697 | INFO     | __main__:train:47 - epoch: 8, transformer: gpt2, test_precision: 56.86, test_recall: 50.15, test_f1_score: 51.11, test_accuracy_score: 53.57\n",
            "2020-09-15 08:31:04.698 | INFO     | __main__:train:52 - epoch: 8, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 97 143  27  11   1]\n",
            " [ 47 391 139  54   2]\n",
            " [  4 122 141 118   4]\n",
            " [  0  16  55 387  52]\n",
            " [  0   2  15 214 168]]\n",
            "2020-09-15 08:31:04.698 | INFO     | __main__:train:55 - Total training time elapsed: 0:06:51.422705\n",
            "2020-09-15 08:31:04.699 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.427838\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.23batch/s]\n",
            "2020-09-15 08:31:55.740 | INFO     | __main__:train:39 - epoch: 9, transformer: gpt2, train_loss: 0.0263, train_acc: 62.94\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.44batch/s]\n",
            "2020-09-15 08:31:57.882 | INFO     | __main__:train:42 - epoch: 9, transformer: gpt2, dev_loss: 0.0400, dev_acc: 50.23\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.25batch/s]\n",
            "2020-09-15 08:32:02.207 | INFO     | __main__:train:46 - epoch: 9, transformer: gpt2, test_loss: 0.0352, test_acc: 53.71\n",
            "2020-09-15 08:32:02.208 | INFO     | __main__:train:47 - epoch: 9, transformer: gpt2, test_precision: 52.67, test_recall: 52.41, test_f1_score: 52.27, test_accuracy_score: 53.71\n",
            "2020-09-15 08:32:02.209 | INFO     | __main__:train:52 - epoch: 9, transformer: gpt2, test_confusion_matrix: \n",
            "[[148 108  14   8   1]\n",
            " [112 376  92  48   5]\n",
            " [ 19 149 100 113   8]\n",
            " [  2  25  63 315 105]\n",
            " [  0   6  16 129 248]]\n",
            "2020-09-15 08:32:02.209 | INFO     | __main__:train:55 - Total training time elapsed: 0:07:42.462790\n",
            "2020-09-15 08:32:02.210 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.384754\n",
            "train: 100%|██████████| 267/267 [00:50<00:00,  5.24batch/s]\n",
            "2020-09-15 08:32:53.197 | INFO     | __main__:train:39 - epoch: 10, transformer: gpt2, train_loss: 0.0252, train_acc: 64.69\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.55batch/s]\n",
            "2020-09-15 08:32:55.324 | INFO     | __main__:train:42 - epoch: 10, transformer: gpt2, dev_loss: 0.0380, dev_acc: 52.13\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.23batch/s]\n",
            "2020-09-15 08:32:59.654 | INFO     | __main__:train:46 - epoch: 10, transformer: gpt2, test_loss: 0.0350, test_acc: 53.57\n",
            "2020-09-15 08:32:59.654 | INFO     | __main__:train:47 - epoch: 10, transformer: gpt2, test_precision: 54.14, test_recall: 51.58, test_f1_score: 52.45, test_accuracy_score: 53.57\n",
            "2020-09-15 08:32:59.655 | INFO     | __main__:train:52 - epoch: 10, transformer: gpt2, test_confusion_matrix: \n",
            "[[117 127  26   8   1]\n",
            " [ 71 385 137  33   7]\n",
            " [  8 133 141 100   7]\n",
            " [  2  17  85 306 100]\n",
            " [  0   1  26 137 235]]\n",
            "2020-09-15 08:32:59.656 | INFO     | __main__:train:55 - Total training time elapsed: 0:08:33.449240\n",
            "2020-09-15 08:32:59.656 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.344924\n",
            "train: 100%|██████████| 267/267 [00:51<00:00,  5.20batch/s]\n",
            "2020-09-15 08:33:51.002 | INFO     | __main__:train:39 - epoch: 11, transformer: gpt2, train_loss: 0.0232, train_acc: 68.07\n",
            "dev: 100%|██████████| 35/35 [00:02<00:00, 16.39batch/s]\n",
            "2020-09-15 08:33:53.149 | INFO     | __main__:train:42 - epoch: 11, transformer: gpt2, dev_loss: 0.0433, dev_acc: 50.32\n",
            "test: 100%|██████████| 70/70 [00:04<00:00, 16.35batch/s]\n",
            "2020-09-15 08:33:57.448 | INFO     | __main__:train:46 - epoch: 11, transformer: gpt2, test_loss: 0.0387, test_acc: 53.21\n",
            "2020-09-15 08:33:57.449 | INFO     | __main__:train:47 - epoch: 11, transformer: gpt2, test_precision: 54.91, test_recall: 50.46, test_f1_score: 51.26, test_accuracy_score: 53.21\n",
            "2020-09-15 08:33:57.449 | INFO     | __main__:train:52 - epoch: 11, transformer: gpt2, test_confusion_matrix: \n",
            "[[ 93 139  33  12   2]\n",
            " [ 46 364 148  67   8]\n",
            " [  5 110 133 132   9]\n",
            " [  1  12  48 359  90]\n",
            " [  0   1  16 155 227]]\n",
            "2020-09-15 08:33:57.450 | INFO     | __main__:train:55 - Total training time elapsed: 0:09:24.792744\n",
            "2020-09-15 08:33:57.451 | INFO     | __main__:train:56 - Mean time per train epoch: 0:00:51.344795\n",
            "train:  24%|██▎       | 63/267 [00:12<00:39,  5.20batch/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d48248c16131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-6b9a2854405b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(name, root, binary, epochs, patience, save)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtotal_train_seconds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-55af4a5f1322>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, tokenizer, train_dataset, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-c54f6e7dca1d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, inputs, labels, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJveOtox3-6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMfA9mkm8dfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lEHpwIL8dcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-vTLCGL8daN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW8pv5w08dYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5uq4_AO8dVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtfwRrO8dSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}